{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pallavibekal/CodeRepository/blob/main/Image_Classification_MLP_M4_01_Pallavi.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "maritime-miami"
      },
      "source": [
        "##Objectives"
      ],
      "id": "maritime-miami"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nljJR6CwfZN_"
      },
      "source": [
        "\n",
        "* load and extract features of images\n",
        "\n",
        "* implement the Multi-Layer perceptron to classify images\n",
        "\n",
        "* implement simple neural network from keras"
      ],
      "id": "nljJR6CwfZN_"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "29152de7"
      },
      "source": [
        "## Introduction\n",
        "\n",
        "Traffic sign recognition is a challenging, real-world problem relevant for AI based transportation systems. Traffic signs show a wide range of variations between classes in terms of color, shape, and the presence of pictograms or text. However, there exist subsets of\n",
        "classes (e.g., speed limit signs) that are very similar to each other. Further, the classifier\n",
        "has to be robust against large variations in visual appearances due to changes in illumination, partial\n",
        "occlusions, rotations, weather conditions etc. Using a comprehensive traffic sign detection dataset, here we will perform classification of traffic signs, train and evaluate the different models and compare to the performance of MLPs."
      ],
      "id": "29152de7"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58facc94"
      },
      "source": [
        "![img](https://paperswithcode.com/media/datasets/GTSRB-0000000633-9ce3c5f6_Dki5Rsf.jpg)"
      ],
      "id": "58facc94"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "surprising-uruguay"
      },
      "source": [
        "## Dataset\n",
        "\n",
        "The data for this project is from the German Traffic Sign Detection Benchmark [GTSDB](https://benchmark.ini.rub.de/gtsdb_dataset.html). This archive contains the training set used during the IJCNN 2013 competition. \n",
        "\n",
        "The German Traffic Sign Detection Benchmark is a single-image detection assessment for researchers with interest in the field of computer vision, pattern recognition and image-based driver assistance. It is introduced on the IEEE International Joint Conference on Neural Networks 2013. \n",
        "\n",
        "It features ...\n",
        "\n",
        "* The main archive FullIJCNN2013.zip includes the images (1360 x 800 pixels) in PPM format, the image sections containing only the traffic signs\n",
        "* A file in CSV format with the ground truth\n",
        "* A ReadMe.txt with more details."
      ],
      "id": "surprising-uruguay"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ih-oasWmdZul"
      },
      "source": [
        "## Problem Statement"
      ],
      "id": "ih-oasWmdZul"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qfWGmjNHdZul"
      },
      "source": [
        "To build and improve upon a machine learning model for the classification of images and achieve a high accuracy final model."
      ],
      "id": "qfWGmjNHdZul"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4978243"
      },
      "source": [
        "Reference: J. Stallkamp, M. Schlipsing, J. Salmen, and C. Igel. The German Traffic Sign Recognition Benchmark: A multi-class classification competition. In Proceedings of the IEEE International Joint Conference on Neural Networks, pages 1453â€“1460. 2011."
      ],
      "id": "d4978243"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "812a816f"
      },
      "outputs": [],
      "source": [
        "#@title Download the data\n",
        "!wget -qq https://sid.erda.dk/public/archives/ff17dc924eba88d5d01a807357d6614c/FullIJCNN2013.zip\n",
        "!unzip -qq FullIJCNN2013.zip\n"
      ],
      "id": "812a816f"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "abstract-stocks"
      },
      "source": [
        "### Import Required packages"
      ],
      "id": "abstract-stocks"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "advisory-knowing"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import RandomizedSearchCV,train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from skimage.io import imread, imshow\n",
        "from sklearn import preprocessing\n",
        "import os, glob\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "# Keras\n",
        "import tensorflow as tf \n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, BatchNormalization\n",
        "\n",
        "from tensorflow.keras.optimizers import SGD      \n",
        "from keras.layers import Activation, Dense, Input, Flatten, Dropout, BatchNormalization   # using keras importing layers                                    \n",
        "from keras.callbacks import EarlyStopping         "
      ],
      "id": "advisory-knowing"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gp4bF_GJdZuo"
      },
      "source": [
        "### Data Loading and Feature Extraction \n",
        "\n",
        "#### Get the features and labels of data\n",
        "\n",
        "* Extract the features of the images\n",
        "* Extract labels of the images\n",
        "* Resize the images to (30, 30) and convert to numpy 1-D array\n",
        "\n",
        "   "
      ],
      "id": "gp4bF_GJdZuo"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V8zLt6CikVel",
        "outputId": "be3fa05b-a8e8-45ee-8b3a-d238c22eb172"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Pillow Version: 7.1.2\n"
          ]
        }
      ],
      "source": [
        "import PIL\n",
        "print('Pillow Version:', PIL.__version__)"
      ],
      "id": "V8zLt6CikVel"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "siN6rS_7kXG7",
        "outputId": "a086679a-b9cb-4fe0-9d21-411448bdac21"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PPM\n",
            "RGB\n",
            "(30, 30)\n"
          ]
        }
      ],
      "source": [
        "# load and show an image with Pillow\n",
        "from PIL import Image\n",
        "# load the image\n",
        "image = Image.open('/content/FullIJCNN2013/00/00000.ppm')\n",
        "# summarize some details about the image\n",
        "print(image.format)\n",
        "print(image.mode)\n",
        "print(image.size)\n",
        "# show the image\n",
        "image.show()"
      ],
      "id": "siN6rS_7kXG7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "89pkAKrvmAP7",
        "outputId": "dc01d466-dfa7-4fc0-b1ed-a4d39e399e12"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "uint8\n",
            "(30, 30, 3)\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# load and display an image with Matplotlib\n",
        "from matplotlib import image\n",
        "from matplotlib import pyplot\n",
        "# load image as pixel array\n",
        "data = image.imread('/content/FullIJCNN2013/00/00000.ppm')\n",
        "# summarize shape of the pixel array\n",
        "print(data.dtype)\n",
        "print(data.shape)\n",
        "# display the array of pixels as an image\n",
        "pyplot.imshow(data)\n",
        "pyplot.show()"
      ],
      "id": "89pkAKrvmAP7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vD9qxAQ4mO1s",
        "outputId": "e5b06e39-9ee8-4d2f-de73-750cc0102623"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(30, 30, 3)\n",
            "None\n",
            "RGB\n",
            "(30, 30)\n"
          ]
        }
      ],
      "source": [
        "# load image and convert to and from NumPy array\n",
        "from PIL import Image\n",
        "from numpy import asarray\n",
        "# load the image\n",
        "image = Image.open('/content/FullIJCNN2013/00/00000.ppm')\n",
        "# convert image to numpy array\n",
        "data = asarray(image)\n",
        "# summarize shape\n",
        "print(data.shape)\n",
        "# create Pillow image\n",
        "image2 = Image.fromarray(data)\n",
        "# summarize image details\n",
        "print(image2.format)\n",
        "print(image2.mode)\n",
        "print(image2.size)"
      ],
      "id": "vD9qxAQ4mO1s"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "id": "6n7RbF_bnx-M",
        "outputId": "1c149779-f461-44ee-95f6-a26ae907c7d8"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "pyplot.imshow(image2)\n",
        "pyplot.show()"
      ],
      "id": "6n7RbF_bnx-M"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j6eAXKwdsXsM"
      },
      "outputs": [],
      "source": [
        "#1. Extract the features of the images\n",
        "#2. Extract labels of the images\n",
        "#3. Resize the images to (30, 30) and convert to numpy 1-D array\n",
        "\n",
        "data = []\n",
        "flat_data = []\n",
        "labels = []\n",
        "classes = 43\n",
        "\n",
        "for i in range(classes):\n",
        "  if(i<=9):\n",
        "    path = os.path.join(os.getcwd(),'FullIJCNN2013',str('0' + str(i)))\n",
        "    images = os.listdir(path)\n",
        "  else:\n",
        "    path = os.path.join(os.getcwd(),'FullIJCNN2013',str(i))\n",
        "    images = os.listdir(path)\n",
        "\n",
        "  for j in images:\n",
        "    try:\n",
        "      image = Image.open(path + '/'+ j)\n",
        "      image = image.resize((30,30))\n",
        "      image = np.array(image)\n",
        "      data.append(image)\n",
        "      flat_data.append(image.flatten())\n",
        "      labels.append(i)\n",
        "    except:\n",
        "      print(\"Error loading image\")#Converting lists into numpy arrays bcoz its faster and takes lesser #memorydata = np.array(data)\n",
        "\n",
        "# Convert to numpy array\n",
        "data = np.array(data)\n",
        "flat_data = np.array(flat_data)\n",
        "labels = np.array(labels)\n"
      ],
      "id": "j6eAXKwdsXsM"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zTpOEKxGULmo",
        "outputId": "b72499a4-4e29-43a1-d8c8-039adcf01c93"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1213, 30, 30, 3) (1213, 2700)\n"
          ]
        }
      ],
      "source": [
        "print(data.shape,flat_data.shape)"
      ],
      "id": "zTpOEKxGULmo"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v73D7NUdLIMO",
        "outputId": "213e510f-7f70-45e6-944e-588f44ca535e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1213,)\n"
          ]
        }
      ],
      "source": [
        "print(labels.shape)"
      ],
      "id": "v73D7NUdLIMO"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37b23a0b"
      },
      "source": [
        "#### Normalize the features\n",
        "\n",
        "For most image data, the pixel values are integers with values between 0 and 255.\n",
        "\n",
        "Neural networks process inputs using small weight values, and inputs with large integer values can disrupt or slow down the learning process. As such it is good practice to normalize the pixel values.\n",
        "\n",
        "Hint: sklearn.preprocessing.normalize"
      ],
      "id": "37b23a0b"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "82239736"
      },
      "outputs": [],
      "source": [
        "data = np.array(data)/255\n",
        "flat_data = preprocessing.normalize(flat_data)\n"
      ],
      "id": "82239736"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aYdVBIyeMWi9",
        "outputId": "828fac93-747f-420e-a41c-c46b086a517e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1213, 2700)"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "flat_data.shape"
      ],
      "id": "aYdVBIyeMWi9"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28ea9c3a"
      },
      "source": [
        "### Train the MLP classifier on features \n",
        "\n",
        "* Split the data into train and test\n",
        "\n",
        "* Train the MLP classifier with different parameters\n",
        "\n",
        "* Get the accuracy score and performance metrics"
      ],
      "id": "28ea9c3a"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dfe1e294"
      },
      "source": [
        "### Tune the hyper-parameters \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "* Use the GridSearchCV or RandomizedSearchCV and select best parameters\n",
        "\n",
        "  Manually change and find the best parameters\n",
        "\n"
      ],
      "id": "dfe1e294"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kKD6cwjobCUt"
      },
      "outputs": [],
      "source": [
        "# Get two sets of trains and test for data plus flat data\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(data,labels,test_size=0.2,random_state=42, shuffle=True)\n",
        "\n",
        "\n",
        "X_train_flat, X_test_flat, Y_train_flat, Y_test_flat = train_test_split(flat_data,labels,test_size=0.2,random_state=42, shuffle=True)"
      ],
      "id": "kKD6cwjobCUt"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T6wNHJbLGaHm",
        "outputId": "b4323e00-46f5-439f-8512-a9ea479d60e2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n"
          ]
        }
      ],
      "source": [
        "# 1 MLP Classifier\n",
        "clf = MLPClassifier(random_state=1, max_iter=300).fit(X_train_flat, Y_train_flat)"
      ],
      "id": "T6wNHJbLGaHm"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c-TnJH0KbUa4"
      },
      "outputs": [],
      "source": [
        "Y_pred_MLP1 = clf.predict(X_test_flat)"
      ],
      "id": "c-TnJH0KbUa4"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UHhVVDAsbiAp",
        "outputId": "a4656fcb-0b59-4e80-b8b3-2c20c53bbdc9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy Score- 0.8641975308641975\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "print('Accuracy Score-',accuracy_score(Y_pred_MLP1,Y_test))"
      ],
      "id": "UHhVVDAsbiAp"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CXWWZJG_dZa5"
      },
      "outputs": [],
      "source": [
        "# 2 MLP Classifier\n",
        "clf_MLP2 = MLPClassifier(hidden_layer_sizes=(64,64,64),activation=\"relu\" ,random_state=1, max_iter=200)"
      ],
      "id": "CXWWZJG_dZa5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lA_iBxiddxRJ",
        "outputId": "03264bea-d776-4944-c5e9-0cf56df79509"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "MLPClassifier(hidden_layer_sizes=(64, 64, 64), random_state=1)"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "clf_MLP2.fit(X_train_flat,Y_train_flat)"
      ],
      "id": "lA_iBxiddxRJ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eu7_eueTd3dx",
        "outputId": "bc671190-b7b2-4ebc-9a6a-0bebf7a163c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy Score- 0.7983539094650206\n"
          ]
        }
      ],
      "source": [
        "Y_pred_MLP2=clf_MLP2.predict(X_test_flat)\n",
        "print('Accuracy Score-',accuracy_score(Y_pred_MLP2,Y_test))"
      ],
      "id": "eu7_eueTd3dx"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vi6qCctTd9Vf"
      },
      "outputs": [],
      "source": [
        "# 3 MLP Classifier with gridsearch\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "MLP_grid = MLPClassifier(max_iter=300)\n",
        "parameter_space = {\n",
        "    'hidden_layer_sizes': [(10,100)],\n",
        "    'activation': ['tanh', 'relu'],\n",
        "    'solver': ['sgd', 'adam'],\n",
        "    'alpha': [0.0001, 0.05],\n",
        "    'learning_rate': ['constant','adaptive'],\n",
        "}\n",
        "\n",
        "clf = GridSearchCV(MLP_grid, parameter_space, n_jobs=-1, cv=5)\n",
        "clf.fit(X_train_flat, Y_train_flat) "
      ],
      "id": "vi6qCctTd9Vf"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7p-DQNyRg8eZ"
      },
      "outputs": [],
      "source": [
        "def build_model(n_hidden=1, n_neurons=30, learning_rate=3e-3, input_shape=[2700]):\n",
        "    model = Sequential()\n",
        "    options = {\"input_shape\": input_shape}\n",
        "    for layer in range(n_hidden):\n",
        "        model.add(Dense(n_neurons, activation=\"softmax\", **options))\n",
        "        options = {}\n",
        "    model.add(Dense(1, **options))\n",
        "    optimizer = SGD(learning_rate)\n",
        "    model.compile(loss=\"mse\", optimizer=optimizer)\n",
        "    # YOUR CODE HERE to return 'model'\n",
        "    return model"
      ],
      "id": "7p-DQNyRg8eZ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jimUvjHnin_I",
        "outputId": "3f1a557b-b4b8-4cd3-884d-40795dd49208"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        }
      ],
      "source": [
        "keras_reg = keras.wrappers.scikit_learn.KerasRegressor(build_model)"
      ],
      "id": "jimUvjHnin_I"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QemOJbRUjFBl"
      },
      "outputs": [],
      "source": [
        "from scipy.stats import reciprocal \n",
        "param_distribs = {\n",
        "    \"n_hidden\": [2, 4],\n",
        "    \"n_neurons\": [10,100,300],\n",
        "    \"learning_rate\": [0.1, 0.01, 0.003],\n",
        "}"
      ],
      "id": "QemOJbRUjFBl"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uVq9nGSlo3qv"
      },
      "outputs": [],
      "source": [
        "X_train_flat_2, X_val_flat, Y_train_flat_2, Y_val_flat = train_test_split(X_train_flat,Y_train_flat,test_size=0.2,random_state=42, shuffle=True)"
      ],
      "id": "uVq9nGSlo3qv"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-txTNC75yAXc",
        "outputId": "b61962ed-8670-47ae-c182-84ab9b5b070f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(776, 2700)"
            ]
          },
          "execution_count": 90,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train_flat_2.shape"
      ],
      "id": "-txTNC75yAXc"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jm0jmriN64K7",
        "outputId": "351fff4a-d0c2-4fa0-c2f9-87e8ee571c20"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'learning_rate': 0.01, 'n_hidden': 2, 'n_neurons': 10}"
            ]
          },
          "execution_count": 92,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rnd_search_cv.best_params_"
      ],
      "id": "Jm0jmriN64K7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k_lJy91N69Nz",
        "outputId": "47f0cb48-ed11-4828-ce06-102c6c6e4bf9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<keras.wrappers.scikit_learn.KerasRegressor at 0x7f8a7a410050>"
            ]
          },
          "execution_count": 93,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rnd_search_cv.best_estimator_"
      ],
      "id": "k_lJy91N69Nz"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "mwoPp9G0j0ss",
        "outputId": "b965d49a-4281-440f-8b9e-3330cdba0977"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Epoch 205/300\n",
            "17/17 [==============================] - 0s 20ms/step - loss: 143.7912 - val_loss: 148.2197\n",
            "Epoch 206/300\n",
            "17/17 [==============================] - 0s 17ms/step - loss: 143.7872 - val_loss: 148.1839\n",
            "Epoch 207/300\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 143.7948 - val_loss: 148.0129\n",
            "Epoch 208/300\n",
            "17/17 [==============================] - 0s 16ms/step - loss: 143.7271 - val_loss: 147.9552\n",
            "Epoch 209/300\n",
            "17/17 [==============================] - 0s 17ms/step - loss: 143.7474 - val_loss: 147.9929\n",
            "Epoch 210/300\n",
            "17/17 [==============================] - 0s 16ms/step - loss: 143.7302 - val_loss: 147.9881\n",
            "Epoch 211/300\n",
            "17/17 [==============================] - 0s 16ms/step - loss: 143.7342 - val_loss: 147.9260\n",
            "Epoch 212/300\n",
            "17/17 [==============================] - 0s 20ms/step - loss: 143.7408 - val_loss: 147.9098\n",
            "Epoch 213/300\n",
            "17/17 [==============================] - 0s 20ms/step - loss: 143.7410 - val_loss: 147.9408\n",
            "Epoch 214/300\n",
            "17/17 [==============================] - 0s 19ms/step - loss: 143.7213 - val_loss: 147.9624\n",
            "Epoch 215/300\n",
            "17/17 [==============================] - 0s 21ms/step - loss: 143.7297 - val_loss: 147.9002\n",
            "Epoch 216/300\n",
            "17/17 [==============================] - 0s 16ms/step - loss: 143.7444 - val_loss: 147.8645\n",
            "Epoch 217/300\n",
            "17/17 [==============================] - 0s 18ms/step - loss: 143.9317 - val_loss: 147.9225\n",
            "Epoch 218/300\n",
            "17/17 [==============================] - 0s 19ms/step - loss: 143.6966 - val_loss: 147.9223\n",
            "Epoch 219/300\n",
            "17/17 [==============================] - 0s 20ms/step - loss: 143.7547 - val_loss: 147.9895\n",
            "Epoch 220/300\n",
            "17/17 [==============================] - 0s 19ms/step - loss: 143.6898 - val_loss: 148.0071\n",
            "Epoch 221/300\n",
            "17/17 [==============================] - 0s 20ms/step - loss: 143.7040 - val_loss: 147.9531\n",
            "Epoch 222/300\n",
            "17/17 [==============================] - 0s 16ms/step - loss: 143.7107 - val_loss: 148.0435\n",
            "Epoch 223/300\n",
            "17/17 [==============================] - 0s 18ms/step - loss: 143.7276 - val_loss: 148.0371\n",
            "Epoch 224/300\n",
            "17/17 [==============================] - 0s 19ms/step - loss: 143.7537 - val_loss: 148.0279\n",
            "Epoch 225/300\n",
            "17/17 [==============================] - 0s 20ms/step - loss: 143.6974 - val_loss: 148.2411\n",
            "Epoch 226/300\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 143.8193 - val_loss: 148.1819\n",
            "Epoch 227/300\n",
            "17/17 [==============================] - 0s 16ms/step - loss: 143.7740 - val_loss: 148.0707\n",
            "Epoch 228/300\n",
            "17/17 [==============================] - 0s 15ms/step - loss: 143.7279 - val_loss: 147.9167\n",
            "Epoch 229/300\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 143.7693 - val_loss: 148.0529\n",
            "Epoch 230/300\n",
            "17/17 [==============================] - 0s 17ms/step - loss: 143.7747 - val_loss: 148.0585\n",
            "Epoch 231/300\n",
            "17/17 [==============================] - 0s 19ms/step - loss: 143.7697 - val_loss: 148.1246\n",
            "Epoch 232/300\n",
            "17/17 [==============================] - 0s 19ms/step - loss: 143.7900 - val_loss: 148.1587\n",
            "Epoch 233/300\n",
            "17/17 [==============================] - 0s 19ms/step - loss: 143.8078 - val_loss: 148.1694\n",
            "Epoch 234/300\n",
            "17/17 [==============================] - 0s 18ms/step - loss: 143.7333 - val_loss: 148.0468\n",
            "Epoch 235/300\n",
            "17/17 [==============================] - 0s 19ms/step - loss: 143.7570 - val_loss: 148.2293\n",
            "Epoch 236/300\n",
            "17/17 [==============================] - 0s 20ms/step - loss: 143.8179 - val_loss: 148.4511\n",
            "Epoch 237/300\n",
            "17/17 [==============================] - 0s 19ms/step - loss: 143.8503 - val_loss: 148.3042\n",
            "Epoch 238/300\n",
            "17/17 [==============================] - 0s 19ms/step - loss: 143.8398 - val_loss: 148.1420\n",
            "Epoch 239/300\n",
            "17/17 [==============================] - 0s 17ms/step - loss: 143.7581 - val_loss: 148.0356\n",
            "Epoch 240/300\n",
            "17/17 [==============================] - 0s 16ms/step - loss: 143.8304 - val_loss: 148.1036\n",
            "Epoch 241/300\n",
            "17/17 [==============================] - 0s 20ms/step - loss: 143.7911 - val_loss: 148.0647\n",
            "Epoch 242/300\n",
            "17/17 [==============================] - 0s 16ms/step - loss: 143.7495 - val_loss: 147.9856\n",
            "Epoch 243/300\n",
            "17/17 [==============================] - 0s 16ms/step - loss: 143.7521 - val_loss: 147.9121\n",
            "Epoch 244/300\n",
            "17/17 [==============================] - 0s 15ms/step - loss: 143.7934 - val_loss: 147.8923\n",
            "Epoch 245/300\n",
            "17/17 [==============================] - 0s 15ms/step - loss: 143.7643 - val_loss: 147.9438\n",
            "Epoch 246/300\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 143.7164 - val_loss: 147.9056\n",
            "Epoch 247/300\n",
            "17/17 [==============================] - 0s 18ms/step - loss: 143.7329 - val_loss: 147.9633\n",
            "Epoch 248/300\n",
            "17/17 [==============================] - 0s 18ms/step - loss: 143.7189 - val_loss: 147.9278\n",
            "Epoch 249/300\n",
            "17/17 [==============================] - 0s 16ms/step - loss: 143.7716 - val_loss: 148.1185\n",
            "Epoch 250/300\n",
            "17/17 [==============================] - 0s 16ms/step - loss: 143.7719 - val_loss: 148.0983\n",
            "Epoch 251/300\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 143.7439 - val_loss: 148.0810\n",
            "Epoch 252/300\n",
            "17/17 [==============================] - 0s 15ms/step - loss: 143.7245 - val_loss: 148.0797\n",
            "Epoch 253/300\n",
            "17/17 [==============================] - 0s 15ms/step - loss: 143.7450 - val_loss: 148.0482\n",
            "Epoch 254/300\n",
            "17/17 [==============================] - 0s 15ms/step - loss: 143.7172 - val_loss: 147.9411\n",
            "Epoch 255/300\n",
            "17/17 [==============================] - 0s 16ms/step - loss: 143.7210 - val_loss: 147.9411\n",
            "Epoch 256/300\n",
            "17/17 [==============================] - 0s 17ms/step - loss: 143.7720 - val_loss: 147.9078\n",
            "Epoch 257/300\n",
            "17/17 [==============================] - 0s 16ms/step - loss: 143.7526 - val_loss: 147.8916\n",
            "Epoch 258/300\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 143.7836 - val_loss: 147.8880\n",
            "Epoch 259/300\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 143.7445 - val_loss: 147.9410\n",
            "Epoch 260/300\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 143.7495 - val_loss: 147.9175\n",
            "Epoch 261/300\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 143.7797 - val_loss: 147.9289\n",
            "Epoch 262/300\n",
            "17/17 [==============================] - 0s 16ms/step - loss: 143.7441 - val_loss: 147.9634\n",
            "Epoch 263/300\n",
            "17/17 [==============================] - 0s 16ms/step - loss: 143.7726 - val_loss: 147.9058\n",
            "Epoch 264/300\n",
            "17/17 [==============================] - 0s 15ms/step - loss: 143.7307 - val_loss: 148.0342\n",
            "Epoch 265/300\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 143.7788 - val_loss: 148.0489\n",
            "Epoch 266/300\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 143.7533 - val_loss: 148.1707\n",
            "Epoch 267/300\n",
            "17/17 [==============================] - 0s 16ms/step - loss: 143.7305 - val_loss: 148.0614\n",
            "Epoch 268/300\n",
            "17/17 [==============================] - 0s 16ms/step - loss: 143.7222 - val_loss: 148.1993\n",
            "Epoch 269/300\n",
            "17/17 [==============================] - 0s 15ms/step - loss: 143.7262 - val_loss: 148.0381\n",
            "Epoch 270/300\n",
            "17/17 [==============================] - 0s 19ms/step - loss: 143.7106 - val_loss: 148.2016\n",
            "Epoch 271/300\n",
            "17/17 [==============================] - 0s 18ms/step - loss: 143.7485 - val_loss: 148.0032\n",
            "Epoch 272/300\n",
            "17/17 [==============================] - 0s 20ms/step - loss: 143.7492 - val_loss: 147.9424\n",
            "Epoch 273/300\n",
            "17/17 [==============================] - 0s 15ms/step - loss: 143.7096 - val_loss: 147.9212\n",
            "Epoch 274/300\n",
            "17/17 [==============================] - 0s 17ms/step - loss: 143.7499 - val_loss: 147.9567\n",
            "Epoch 275/300\n",
            "17/17 [==============================] - 0s 16ms/step - loss: 143.7184 - val_loss: 147.9729\n",
            "Epoch 276/300\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 143.7340 - val_loss: 147.9355\n",
            "Epoch 277/300\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 143.7144 - val_loss: 147.9839\n",
            "Epoch 278/300\n",
            "17/17 [==============================] - 0s 15ms/step - loss: 143.7534 - val_loss: 148.0518\n",
            "Epoch 279/300\n",
            "17/17 [==============================] - 0s 16ms/step - loss: 143.7238 - val_loss: 147.9742\n",
            "Epoch 280/300\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 143.7586 - val_loss: 147.9983\n",
            "Epoch 281/300\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 143.7116 - val_loss: 148.0950\n",
            "Epoch 282/300\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 143.7534 - val_loss: 148.1996\n",
            "Epoch 283/300\n",
            "17/17 [==============================] - 0s 15ms/step - loss: 143.7604 - val_loss: 148.1147\n",
            "Epoch 284/300\n",
            "17/17 [==============================] - 0s 16ms/step - loss: 143.7385 - val_loss: 148.0947\n",
            "Epoch 285/300\n",
            "17/17 [==============================] - 0s 16ms/step - loss: 143.8596 - val_loss: 147.9967\n",
            "Epoch 286/300\n",
            "17/17 [==============================] - 0s 19ms/step - loss: 143.7765 - val_loss: 147.9008\n",
            "Epoch 287/300\n",
            "17/17 [==============================] - 0s 18ms/step - loss: 143.7621 - val_loss: 147.9184\n",
            "Epoch 288/300\n",
            "17/17 [==============================] - 0s 18ms/step - loss: 143.7673 - val_loss: 147.8865\n",
            "Epoch 289/300\n",
            "17/17 [==============================] - 0s 16ms/step - loss: 143.7359 - val_loss: 147.9352\n",
            "Epoch 290/300\n",
            "17/17 [==============================] - 0s 15ms/step - loss: 143.8047 - val_loss: 148.0615\n",
            "Epoch 291/300\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 143.7153 - val_loss: 148.1486\n",
            "Epoch 292/300\n",
            "17/17 [==============================] - 0s 16ms/step - loss: 143.7661 - val_loss: 148.1925\n",
            "Epoch 293/300\n",
            "17/17 [==============================] - 0s 16ms/step - loss: 143.7669 - val_loss: 147.9970\n",
            "Epoch 294/300\n",
            "17/17 [==============================] - 0s 17ms/step - loss: 143.7146 - val_loss: 148.1590\n",
            "Epoch 295/300\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 143.7233 - val_loss: 148.2453\n",
            "Epoch 296/300\n",
            "17/17 [==============================] - 0s 16ms/step - loss: 143.7649 - val_loss: 148.1879\n",
            "Epoch 297/300\n",
            "17/17 [==============================] - 0s 16ms/step - loss: 143.8000 - val_loss: 148.0230\n",
            "Epoch 298/300\n",
            "17/17 [==============================] - 0s 15ms/step - loss: 143.7351 - val_loss: 148.0831\n",
            "Epoch 299/300\n",
            "17/17 [==============================] - 0s 17ms/step - loss: 143.7079 - val_loss: 148.0212\n",
            "Epoch 300/300\n",
            "17/17 [==============================] - 0s 17ms/step - loss: 143.7122 - val_loss: 148.0765\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 148.8810\n",
            "Epoch 1/300\n",
            "17/17 [==============================] - 1s 21ms/step - loss: 314.9912 - val_loss: 260.0291\n",
            "Epoch 2/300\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 231.0549 - val_loss: 203.4795\n",
            "Epoch 3/300\n",
            "17/17 [==============================] - 0s 15ms/step - loss: 188.0447 - val_loss: 175.5228\n",
            "Epoch 4/300\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 166.4281 - val_loss: 161.8090\n",
            "Epoch 5/300\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 155.7699 - val_loss: 154.4680\n",
            "Epoch 6/300\n",
            "17/17 [==============================] - 0s 16ms/step - loss: 149.9963 - val_loss: 151.1684\n",
            "Epoch 7/300\n",
            "17/17 [==============================] - 0s 18ms/step - loss: 147.2529 - val_loss: 149.6690\n",
            "Epoch 8/300\n",
            "17/17 [==============================] - 0s 18ms/step - loss: 146.0203 - val_loss: 148.3860\n",
            "Epoch 9/300\n",
            "17/17 [==============================] - 0s 19ms/step - loss: 144.9070 - val_loss: 148.1524\n",
            "Epoch 10/300\n",
            "17/17 [==============================] - 0s 16ms/step - loss: 144.6700 - val_loss: 147.9471\n",
            "Epoch 11/300\n",
            "17/17 [==============================] - 0s 16ms/step - loss: 144.4678 - val_loss: 147.8994\n",
            "Epoch 12/300\n",
            "17/17 [==============================] - 0s 16ms/step - loss: 144.3648 - val_loss: 147.8669\n",
            "Epoch 13/300\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 144.3095 - val_loss: 147.8686\n",
            "Epoch 14/300\n",
            "17/17 [==============================] - 0s 15ms/step - loss: 144.2658 - val_loss: 147.8967\n",
            "Epoch 15/300\n",
            "17/17 [==============================] - 0s 15ms/step - loss: 144.2870 - val_loss: 147.9048\n",
            "Epoch 16/300\n",
            "17/17 [==============================] - 0s 17ms/step - loss: 144.2799 - val_loss: 147.8953\n",
            "Epoch 17/300\n",
            "17/17 [==============================] - 0s 16ms/step - loss: 144.2936 - val_loss: 147.8656\n",
            "Epoch 18/300\n",
            "17/17 [==============================] - 0s 15ms/step - loss: 144.3156 - val_loss: 147.8988\n",
            "Epoch 19/300\n",
            "17/17 [==============================] - 0s 17ms/step - loss: 144.2590 - val_loss: 147.8880\n",
            "Epoch 20/300\n",
            "17/17 [==============================] - 0s 20ms/step - loss: 144.2958 - val_loss: 147.8717\n",
            "Epoch 21/300\n",
            "17/17 [==============================] - 0s 20ms/step - loss: 144.2556 - val_loss: 147.8718\n",
            "Epoch 22/300\n",
            "17/17 [==============================] - 0s 20ms/step - loss: 144.3091 - val_loss: 147.9229\n",
            "Epoch 23/300\n",
            "17/17 [==============================] - 0s 20ms/step - loss: 144.3236 - val_loss: 147.8747\n",
            "Epoch 24/300\n",
            "17/17 [==============================] - 0s 19ms/step - loss: 144.3781 - val_loss: 147.8915\n",
            "Epoch 25/300\n",
            "17/17 [==============================] - 0s 16ms/step - loss: 144.3380 - val_loss: 147.8964\n",
            "Epoch 26/300\n",
            "17/17 [==============================] - 0s 18ms/step - loss: 144.3344 - val_loss: 147.9173\n",
            "Epoch 27/300\n",
            "17/17 [==============================] - 0s 16ms/step - loss: 144.2419 - val_loss: 147.9143\n",
            "Epoch 28/300\n",
            "17/17 [==============================] - 0s 16ms/step - loss: 144.2989 - val_loss: 147.9203\n",
            "Epoch 29/300\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 144.2901 - val_loss: 147.8727\n",
            "Epoch 30/300\n",
            "17/17 [==============================] - 0s 16ms/step - loss: 144.2498 - val_loss: 147.8746\n",
            "Epoch 31/300\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 144.2474 - val_loss: 147.8879\n",
            "Epoch 32/300\n",
            "17/17 [==============================] - 0s 18ms/step - loss: 144.2982 - val_loss: 147.9044\n",
            "Epoch 33/300\n",
            "17/17 [==============================] - 0s 20ms/step - loss: 144.2839 - val_loss: 147.9077\n",
            "Epoch 34/300\n",
            "17/17 [==============================] - 0s 17ms/step - loss: 144.3037 - val_loss: 147.9091\n",
            "Epoch 35/300\n",
            "17/17 [==============================] - 0s 19ms/step - loss: 144.2946 - val_loss: 147.8934\n",
            "Epoch 36/300\n",
            "17/17 [==============================] - 0s 20ms/step - loss: 144.2694 - val_loss: 147.9299\n",
            "Epoch 37/300\n",
            "17/17 [==============================] - 0s 18ms/step - loss: 144.2706 - val_loss: 147.8660\n",
            "Epoch 38/300\n",
            "17/17 [==============================] - 0s 20ms/step - loss: 144.2917 - val_loss: 147.8659\n",
            "Epoch 39/300\n",
            "17/17 [==============================] - 0s 20ms/step - loss: 144.3115 - val_loss: 147.8624\n",
            "Epoch 40/300\n",
            "17/17 [==============================] - 0s 20ms/step - loss: 144.2820 - val_loss: 147.9150\n",
            "Epoch 41/300\n",
            "17/17 [==============================] - 0s 17ms/step - loss: 144.2643 - val_loss: 147.9151\n",
            "Epoch 42/300\n",
            "17/17 [==============================] - 0s 20ms/step - loss: 144.2926 - val_loss: 147.9216\n",
            "Epoch 43/300\n",
            "17/17 [==============================] - 0s 19ms/step - loss: 144.3288 - val_loss: 147.9117\n",
            "Epoch 44/300\n",
            "17/17 [==============================] - 0s 21ms/step - loss: 144.3145 - val_loss: 147.9039\n",
            "Epoch 45/300\n",
            "17/17 [==============================] - 0s 16ms/step - loss: 144.3181 - val_loss: 148.0466\n",
            "Epoch 46/300\n",
            "17/17 [==============================] - 0s 15ms/step - loss: 144.3349 - val_loss: 147.9530\n",
            "Epoch 47/300\n",
            "17/17 [==============================] - 0s 15ms/step - loss: 144.3353 - val_loss: 147.9394\n",
            "Epoch 48/300\n",
            "17/17 [==============================] - 0s 18ms/step - loss: 144.3220 - val_loss: 147.9277\n",
            "Epoch 49/300\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 144.3079 - val_loss: 147.9484\n",
            "Epoch 50/300\n",
            "17/17 [==============================] - 0s 15ms/step - loss: 144.3237 - val_loss: 147.9474\n",
            "Epoch 51/300\n",
            "17/17 [==============================] - 0s 17ms/step - loss: 144.3131 - val_loss: 148.0043\n",
            "Epoch 52/300\n",
            "17/17 [==============================] - 0s 17ms/step - loss: 144.3276 - val_loss: 147.9739\n",
            "Epoch 53/300\n",
            "17/17 [==============================] - 0s 21ms/step - loss: 144.2502 - val_loss: 148.0430\n",
            "Epoch 54/300\n",
            "17/17 [==============================] - 0s 20ms/step - loss: 144.3164 - val_loss: 148.0009\n",
            "Epoch 55/300\n",
            "17/17 [==============================] - 0s 18ms/step - loss: 144.3078 - val_loss: 147.9355\n",
            "Epoch 56/300\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 144.2694 - val_loss: 147.9324\n",
            "Epoch 57/300\n",
            "17/17 [==============================] - 0s 16ms/step - loss: 144.2540 - val_loss: 147.9819\n",
            "Epoch 58/300\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 144.2988 - val_loss: 147.9578\n",
            "Epoch 59/300\n",
            "17/17 [==============================] - 0s 17ms/step - loss: 144.2578 - val_loss: 147.9498\n",
            "Epoch 60/300\n",
            "17/17 [==============================] - 0s 19ms/step - loss: 144.2804 - val_loss: 147.9403\n",
            "Epoch 61/300\n",
            "17/17 [==============================] - 0s 16ms/step - loss: 144.2903 - val_loss: 147.9054\n",
            "Epoch 62/300\n",
            "17/17 [==============================] - 0s 18ms/step - loss: 144.2934 - val_loss: 147.8749\n",
            "Epoch 63/300\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 144.2973 - val_loss: 147.9374\n",
            "Epoch 64/300\n",
            "17/17 [==============================] - 0s 17ms/step - loss: 144.2692 - val_loss: 147.9262\n",
            "Epoch 65/300\n",
            "17/17 [==============================] - 0s 16ms/step - loss: 144.2786 - val_loss: 147.9881\n",
            "Epoch 66/300\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 144.3245 - val_loss: 147.9027\n",
            "Epoch 67/300\n",
            "17/17 [==============================] - 0s 16ms/step - loss: 144.2574 - val_loss: 147.9823\n",
            "Epoch 68/300\n",
            "17/17 [==============================] - 0s 16ms/step - loss: 144.2415 - val_loss: 147.9092\n",
            "Epoch 69/300\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 144.2668 - val_loss: 147.8980\n",
            "Epoch 70/300\n",
            "17/17 [==============================] - 0s 15ms/step - loss: 144.2850 - val_loss: 147.8717\n",
            "Epoch 71/300\n",
            "17/17 [==============================] - 0s 17ms/step - loss: 144.3700 - val_loss: 147.8737\n",
            "Epoch 72/300\n",
            "17/17 [==============================] - 0s 16ms/step - loss: 144.3027 - val_loss: 147.8701\n",
            "Epoch 73/300\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 144.2824 - val_loss: 147.8619\n",
            "Epoch 74/300\n",
            "17/17 [==============================] - 0s 16ms/step - loss: 144.3060 - val_loss: 147.8631\n",
            "Epoch 75/300\n",
            "17/17 [==============================] - 0s 16ms/step - loss: 144.3067 - val_loss: 147.8889\n",
            "Epoch 76/300\n",
            "17/17 [==============================] - 0s 18ms/step - loss: 144.3112 - val_loss: 147.8883\n",
            "Epoch 77/300\n",
            "17/17 [==============================] - 0s 20ms/step - loss: 144.3529 - val_loss: 147.9025\n",
            "Epoch 78/300\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 144.2698 - val_loss: 147.9150\n",
            "Epoch 79/300\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 144.2732 - val_loss: 147.8727\n",
            "Epoch 80/300\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 144.3194 - val_loss: 147.8782\n",
            "Epoch 81/300\n",
            "17/17 [==============================] - 0s 16ms/step - loss: 144.2666 - val_loss: 147.9035\n",
            "Epoch 82/300\n",
            "17/17 [==============================] - 0s 16ms/step - loss: 144.3082 - val_loss: 147.8920\n",
            "Epoch 83/300\n",
            "17/17 [==============================] - 0s 16ms/step - loss: 144.2584 - val_loss: 147.9205\n",
            "Epoch 84/300\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 144.3376 - val_loss: 147.8914\n",
            "Epoch 85/300\n",
            "17/17 [==============================] - 0s 15ms/step - loss: 144.3109 - val_loss: 147.9311\n",
            "Epoch 86/300\n",
            "17/17 [==============================] - 0s 16ms/step - loss: 144.2602 - val_loss: 147.9524\n",
            "Epoch 87/300\n",
            "17/17 [==============================] - 0s 16ms/step - loss: 144.2947 - val_loss: 147.9261\n",
            "Epoch 88/300\n",
            "17/17 [==============================] - 0s 16ms/step - loss: 144.3069 - val_loss: 147.9237\n",
            "Epoch 89/300\n",
            "17/17 [==============================] - 0s 18ms/step - loss: 144.2894 - val_loss: 147.9406\n",
            "Epoch 90/300\n",
            "17/17 [==============================] - 0s 19ms/step - loss: 144.2726 - val_loss: 147.9144\n",
            "Epoch 91/300\n",
            "17/17 [==============================] - 0s 20ms/step - loss: 144.2711 - val_loss: 147.8676\n",
            "Epoch 92/300\n",
            "17/17 [==============================] - 0s 20ms/step - loss: 144.2805 - val_loss: 147.8712\n",
            "Epoch 93/300\n",
            "17/17 [==============================] - 0s 18ms/step - loss: 144.2517 - val_loss: 147.8637\n",
            "Epoch 94/300\n",
            "17/17 [==============================] - 0s 19ms/step - loss: 144.3340 - val_loss: 147.8619\n",
            "Epoch 95/300\n",
            "17/17 [==============================] - 0s 17ms/step - loss: 144.3194 - val_loss: 147.8810\n",
            "Epoch 96/300\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 144.2589 - val_loss: 147.8720\n",
            "Epoch 97/300\n",
            "17/17 [==============================] - 0s 15ms/step - loss: 144.2956 - val_loss: 147.8748\n",
            "Epoch 98/300\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 144.2430 - val_loss: 147.8883\n",
            "Epoch 99/300\n",
            "17/17 [==============================] - 0s 17ms/step - loss: 144.2641 - val_loss: 147.8920\n",
            "Epoch 100/300\n",
            "17/17 [==============================] - 0s 17ms/step - loss: 144.2800 - val_loss: 147.8811\n",
            "Epoch 101/300\n",
            "17/17 [==============================] - 0s 16ms/step - loss: 144.2679 - val_loss: 147.8687\n",
            "Epoch 102/300\n",
            "17/17 [==============================] - 0s 16ms/step - loss: 144.2581 - val_loss: 147.8796\n",
            "Epoch 103/300\n",
            "17/17 [==============================] - 0s 15ms/step - loss: 144.2443 - val_loss: 147.9189\n",
            "Epoch 104/300\n",
            "17/17 [==============================] - 0s 15ms/step - loss: 144.2931 - val_loss: 147.9120\n",
            "Epoch 105/300\n",
            "17/17 [==============================] - 0s 15ms/step - loss: 144.2671 - val_loss: 147.9026\n",
            "Epoch 106/300\n",
            "17/17 [==============================] - 0s 15ms/step - loss: 144.3202 - val_loss: 147.9042\n",
            "Epoch 107/300\n",
            "17/17 [==============================] - 0s 16ms/step - loss: 144.2654 - val_loss: 147.8869\n",
            "Epoch 108/300\n",
            "17/17 [==============================] - 0s 16ms/step - loss: 144.2620 - val_loss: 147.8922\n",
            "Epoch 109/300\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 144.2893 - val_loss: 147.8922\n",
            "Epoch 110/300\n",
            "17/17 [==============================] - 0s 16ms/step - loss: 144.2750 - val_loss: 147.9318\n",
            "Epoch 111/300\n",
            "17/17 [==============================] - 0s 15ms/step - loss: 144.2480 - val_loss: 147.9165\n",
            "Epoch 112/300\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 144.3217 - val_loss: 147.9036\n",
            "Epoch 113/300\n",
            "17/17 [==============================] - 0s 17ms/step - loss: 144.2715 - val_loss: 147.8796\n",
            "Epoch 114/300\n",
            "17/17 [==============================] - 0s 17ms/step - loss: 144.3279 - val_loss: 147.8670\n",
            "Epoch 115/300\n",
            "17/17 [==============================] - 0s 16ms/step - loss: 144.3964 - val_loss: 147.9184\n",
            "Epoch 116/300\n",
            "17/17 [==============================] - 0s 16ms/step - loss: 144.2395 - val_loss: 147.8958\n",
            "Epoch 117/300\n",
            "17/17 [==============================] - 0s 20ms/step - loss: 144.3034 - val_loss: 147.9106\n",
            "Epoch 118/300\n",
            "17/17 [==============================] - 0s 15ms/step - loss: 144.2425 - val_loss: 147.8775\n",
            "Epoch 119/300\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 144.2958 - val_loss: 147.8690\n",
            "Epoch 120/300\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 144.2974 - val_loss: 147.8985\n",
            "Epoch 121/300\n",
            "17/17 [==============================] - 0s 17ms/step - loss: 144.2965 - val_loss: 147.8746\n",
            "Epoch 122/300\n",
            "17/17 [==============================] - 0s 15ms/step - loss: 144.3173 - val_loss: 147.8808\n",
            "Epoch 123/300\n",
            "17/17 [==============================] - 0s 18ms/step - loss: 144.2576 - val_loss: 147.9063\n",
            "Epoch 124/300\n",
            "17/17 [==============================] - 0s 19ms/step - loss: 144.2751 - val_loss: 147.9261\n",
            "Epoch 125/300\n",
            "17/17 [==============================] - 0s 19ms/step - loss: 144.2588 - val_loss: 147.8832\n",
            "Epoch 126/300\n",
            "17/17 [==============================] - 0s 16ms/step - loss: 144.3304 - val_loss: 147.9001\n",
            "Epoch 127/300\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 144.3275 - val_loss: 147.9219\n",
            "Epoch 128/300\n",
            "17/17 [==============================] - 0s 15ms/step - loss: 144.3076 - val_loss: 147.8864\n",
            "Epoch 129/300\n",
            "17/17 [==============================] - 0s 18ms/step - loss: 144.2719 - val_loss: 147.8822\n",
            "Epoch 130/300\n",
            "17/17 [==============================] - 0s 19ms/step - loss: 144.2594 - val_loss: 147.8887\n",
            "Epoch 131/300\n",
            "17/17 [==============================] - 0s 16ms/step - loss: 144.2772 - val_loss: 148.0455\n",
            "Epoch 132/300\n",
            "17/17 [==============================] - 0s 20ms/step - loss: 144.2898 - val_loss: 148.0651\n",
            "Epoch 133/300\n",
            "17/17 [==============================] - 0s 16ms/step - loss: 144.3441 - val_loss: 147.9284\n",
            "Epoch 134/300\n",
            "17/17 [==============================] - 0s 16ms/step - loss: 144.2839 - val_loss: 147.8823\n",
            "Epoch 135/300\n",
            "17/17 [==============================] - 0s 16ms/step - loss: 144.2823 - val_loss: 147.8637\n",
            "Epoch 136/300\n",
            "17/17 [==============================] - 0s 15ms/step - loss: 144.2947 - val_loss: 147.8887\n",
            "Epoch 137/300\n",
            "17/17 [==============================] - 0s 17ms/step - loss: 144.2710 - val_loss: 147.8737\n",
            "Epoch 138/300\n",
            "17/17 [==============================] - 0s 19ms/step - loss: 144.2523 - val_loss: 147.8662\n",
            "Epoch 139/300\n",
            "17/17 [==============================] - 0s 19ms/step - loss: 144.3463 - val_loss: 147.8842\n",
            "Epoch 140/300\n",
            "17/17 [==============================] - 0s 19ms/step - loss: 144.3448 - val_loss: 147.9738\n",
            "Epoch 141/300\n",
            "17/17 [==============================] - 0s 20ms/step - loss: 144.3058 - val_loss: 148.0441\n",
            "Epoch 142/300\n",
            "17/17 [==============================] - 0s 18ms/step - loss: 144.3307 - val_loss: 148.0606\n",
            "Epoch 143/300\n",
            "17/17 [==============================] - 0s 15ms/step - loss: 144.3222 - val_loss: 148.0400\n",
            "Epoch 144/300\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 144.3396 - val_loss: 148.1860\n",
            "Epoch 145/300\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 144.3809 - val_loss: 148.2023\n",
            "Epoch 146/300\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 144.4125 - val_loss: 148.1055\n",
            "Epoch 147/300\n",
            "17/17 [==============================] - 0s 16ms/step - loss: 144.3462 - val_loss: 148.1647\n",
            "Epoch 148/300\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 144.3757 - val_loss: 148.0665\n",
            "Epoch 149/300\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 144.3485 - val_loss: 147.9259\n",
            "Epoch 150/300\n",
            "17/17 [==============================] - 0s 17ms/step - loss: 144.2693 - val_loss: 147.9782\n",
            "Epoch 151/300\n",
            "17/17 [==============================] - 0s 17ms/step - loss: 144.3826 - val_loss: 147.9863\n",
            "Epoch 152/300\n",
            "17/17 [==============================] - 0s 18ms/step - loss: 144.2829 - val_loss: 147.9013\n",
            "Epoch 153/300\n",
            "17/17 [==============================] - 0s 20ms/step - loss: 144.2580 - val_loss: 147.9238\n",
            "Epoch 154/300\n",
            "17/17 [==============================] - 0s 17ms/step - loss: 144.2636 - val_loss: 147.9275\n",
            "Epoch 155/300\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 144.2761 - val_loss: 147.8703\n",
            "Epoch 156/300\n",
            "17/17 [==============================] - 0s 17ms/step - loss: 144.2847 - val_loss: 147.8680\n",
            "Epoch 157/300\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 144.2321 - val_loss: 147.8724\n",
            "Epoch 158/300\n",
            "17/17 [==============================] - 0s 16ms/step - loss: 144.2737 - val_loss: 147.8768\n",
            "Epoch 159/300\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 144.2832 - val_loss: 147.8672\n",
            "Epoch 160/300\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 144.3124 - val_loss: 147.9008\n",
            "Epoch 161/300\n",
            "17/17 [==============================] - 0s 17ms/step - loss: 144.3206 - val_loss: 147.8901\n",
            "Epoch 162/300\n",
            "17/17 [==============================] - 0s 21ms/step - loss: 144.2894 - val_loss: 147.9366\n",
            "Epoch 163/300\n",
            "17/17 [==============================] - 0s 20ms/step - loss: 144.2850 - val_loss: 147.9094\n",
            "Epoch 164/300\n",
            "17/17 [==============================] - 0s 19ms/step - loss: 144.2582 - val_loss: 147.9760\n",
            "Epoch 165/300\n",
            "17/17 [==============================] - 0s 17ms/step - loss: 144.3388 - val_loss: 148.0176\n",
            "Epoch 166/300\n",
            "17/17 [==============================] - 0s 20ms/step - loss: 144.3682 - val_loss: 147.8952\n",
            "Epoch 167/300\n",
            "17/17 [==============================] - 0s 19ms/step - loss: 144.3092 - val_loss: 147.8836\n",
            "Epoch 168/300\n",
            "17/17 [==============================] - 0s 19ms/step - loss: 144.2873 - val_loss: 147.9580\n",
            "Epoch 169/300\n",
            "17/17 [==============================] - 0s 18ms/step - loss: 144.2558 - val_loss: 148.0014\n",
            "Epoch 170/300\n",
            "17/17 [==============================] - 0s 19ms/step - loss: 144.2819 - val_loss: 148.0132\n",
            "Epoch 171/300\n",
            "17/17 [==============================] - 0s 19ms/step - loss: 144.3093 - val_loss: 148.0827\n",
            "Epoch 172/300\n",
            "17/17 [==============================] - 0s 18ms/step - loss: 144.3599 - val_loss: 148.0211\n",
            "Epoch 173/300\n",
            "17/17 [==============================] - 0s 18ms/step - loss: 144.3296 - val_loss: 148.0492\n",
            "Epoch 174/300\n",
            "17/17 [==============================] - 0s 19ms/step - loss: 144.2857 - val_loss: 147.9180\n",
            "Epoch 175/300\n",
            "17/17 [==============================] - 0s 16ms/step - loss: 144.3707 - val_loss: 147.9061\n",
            "Epoch 176/300\n",
            "17/17 [==============================] - 0s 16ms/step - loss: 144.3342 - val_loss: 147.9699\n",
            "Epoch 177/300\n",
            "17/17 [==============================] - 0s 17ms/step - loss: 144.2673 - val_loss: 148.0387\n",
            "Epoch 178/300\n",
            "17/17 [==============================] - 0s 18ms/step - loss: 144.3027 - val_loss: 147.9728\n",
            "Epoch 179/300\n",
            "17/17 [==============================] - 0s 19ms/step - loss: 144.3088 - val_loss: 147.9926\n",
            "Epoch 180/300\n",
            "17/17 [==============================] - 0s 18ms/step - loss: 144.2806 - val_loss: 147.9153\n",
            "Epoch 181/300\n",
            "17/17 [==============================] - 0s 17ms/step - loss: 144.3082 - val_loss: 147.8743\n",
            "Epoch 182/300\n",
            "17/17 [==============================] - 0s 16ms/step - loss: 144.3211 - val_loss: 147.8646\n",
            "Epoch 183/300\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 144.3083 - val_loss: 147.8631\n",
            "Epoch 184/300\n",
            "17/17 [==============================] - 0s 17ms/step - loss: 144.3518 - val_loss: 147.8893\n",
            "Epoch 185/300\n",
            "17/17 [==============================] - 0s 16ms/step - loss: 144.2688 - val_loss: 147.8875\n",
            "Epoch 186/300\n",
            "17/17 [==============================] - 0s 15ms/step - loss: 144.2853 - val_loss: 147.8714\n",
            "Epoch 187/300\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 144.2822 - val_loss: 147.8904\n",
            "Epoch 188/300\n",
            "17/17 [==============================] - 0s 15ms/step - loss: 144.2919 - val_loss: 147.8933\n",
            "Epoch 189/300\n",
            "17/17 [==============================] - 0s 17ms/step - loss: 144.2986 - val_loss: 147.9138\n",
            "Epoch 190/300\n",
            "17/17 [==============================] - 0s 17ms/step - loss: 144.2871 - val_loss: 147.9846\n",
            "Epoch 191/300\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 144.3401 - val_loss: 148.0153\n",
            "Epoch 192/300\n",
            "17/17 [==============================] - 0s 18ms/step - loss: 144.2741 - val_loss: 147.9026\n",
            "Epoch 193/300\n",
            "17/17 [==============================] - 0s 17ms/step - loss: 144.2580 - val_loss: 147.9355\n",
            "Epoch 194/300\n",
            "17/17 [==============================] - 0s 18ms/step - loss: 144.2695 - val_loss: 147.9143\n",
            "Epoch 195/300\n",
            "17/17 [==============================] - 0s 17ms/step - loss: 144.2333 - val_loss: 147.9354\n",
            "Epoch 196/300\n",
            "17/17 [==============================] - 0s 17ms/step - loss: 144.3400 - val_loss: 147.8907\n",
            "Epoch 197/300\n",
            "17/17 [==============================] - 0s 16ms/step - loss: 144.2374 - val_loss: 147.8769\n",
            "Epoch 198/300\n",
            "17/17 [==============================] - 0s 16ms/step - loss: 144.2771 - val_loss: 147.9132\n",
            "Epoch 199/300\n",
            "17/17 [==============================] - 0s 15ms/step - loss: 144.3132 - val_loss: 147.8857\n",
            "Epoch 200/300\n",
            "17/17 [==============================] - 0s 15ms/step - loss: 144.2823 - val_loss: 147.8762\n",
            "Epoch 201/300\n",
            "17/17 [==============================] - 0s 15ms/step - loss: 144.2729 - val_loss: 147.8672\n",
            "Epoch 202/300\n",
            "17/17 [==============================] - 0s 16ms/step - loss: 144.2642 - val_loss: 147.8621\n",
            "Epoch 203/300\n",
            "17/17 [==============================] - 0s 17ms/step - loss: 144.2819 - val_loss: 147.8813\n",
            "Epoch 204/300\n",
            "17/17 [==============================] - 0s 16ms/step - loss: 144.3493 - val_loss: 147.9009\n",
            "Epoch 205/300\n",
            "17/17 [==============================] - 0s 16ms/step - loss: 144.2810 - val_loss: 147.8632\n",
            "Epoch 206/300\n",
            "17/17 [==============================] - 0s 16ms/step - loss: 144.2951 - val_loss: 147.8733\n",
            "Epoch 207/300\n",
            "17/17 [==============================] - 0s 18ms/step - loss: 144.3267 - val_loss: 147.8616\n",
            "Epoch 208/300\n",
            "17/17 [==============================] - 0s 17ms/step - loss: 144.3127 - val_loss: 147.8656\n",
            "Epoch 209/300\n",
            "17/17 [==============================] - 0s 20ms/step - loss: 144.3321 - val_loss: 147.8608\n",
            "Epoch 210/300\n",
            "17/17 [==============================] - 0s 19ms/step - loss: 144.2767 - val_loss: 147.8609\n",
            "Epoch 211/300\n",
            "17/17 [==============================] - 0s 19ms/step - loss: 144.3758 - val_loss: 147.8608\n",
            "Epoch 212/300\n",
            "17/17 [==============================] - 0s 17ms/step - loss: 144.3109 - val_loss: 147.9228\n",
            "Epoch 213/300\n",
            "17/17 [==============================] - 0s 18ms/step - loss: 144.3079 - val_loss: 147.9056\n",
            "Epoch 214/300\n",
            "17/17 [==============================] - 0s 16ms/step - loss: 144.2828 - val_loss: 147.8831\n",
            "Epoch 215/300\n",
            "17/17 [==============================] - 0s 16ms/step - loss: 144.2699 - val_loss: 147.8839\n",
            "Epoch 216/300\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 144.2672 - val_loss: 147.8877\n",
            "Epoch 217/300\n",
            "17/17 [==============================] - 0s 17ms/step - loss: 144.2461 - val_loss: 147.9457\n",
            "Epoch 218/300\n",
            "17/17 [==============================] - 0s 21ms/step - loss: 144.2620 - val_loss: 147.9431\n",
            "Epoch 219/300\n",
            "17/17 [==============================] - 0s 18ms/step - loss: 144.2549 - val_loss: 147.8897\n",
            "Epoch 220/300\n",
            "17/17 [==============================] - 0s 20ms/step - loss: 144.2836 - val_loss: 147.8842\n",
            "Epoch 221/300\n",
            "17/17 [==============================] - 0s 19ms/step - loss: 144.2512 - val_loss: 147.8739\n",
            "Epoch 222/300\n",
            "17/17 [==============================] - 0s 15ms/step - loss: 144.3273 - val_loss: 147.8805\n",
            "Epoch 223/300\n",
            "17/17 [==============================] - 0s 19ms/step - loss: 144.2744 - val_loss: 147.8872\n",
            "Epoch 224/300\n",
            "17/17 [==============================] - 0s 17ms/step - loss: 144.3059 - val_loss: 147.8772\n",
            "Epoch 225/300\n",
            "17/17 [==============================] - 0s 16ms/step - loss: 144.2698 - val_loss: 147.8985\n",
            "Epoch 226/300\n",
            "17/17 [==============================] - 0s 16ms/step - loss: 144.2408 - val_loss: 147.8780\n",
            "Epoch 227/300\n",
            "17/17 [==============================] - 0s 17ms/step - loss: 144.2780 - val_loss: 147.8679\n",
            "Epoch 228/300\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 144.2914 - val_loss: 147.9387\n",
            "Epoch 229/300\n",
            "17/17 [==============================] - 0s 16ms/step - loss: 144.2761 - val_loss: 147.9433\n",
            "Epoch 230/300\n",
            "17/17 [==============================] - 0s 16ms/step - loss: 144.2790 - val_loss: 147.8779\n",
            "Epoch 231/300\n",
            "17/17 [==============================] - 0s 16ms/step - loss: 144.3291 - val_loss: 147.8707\n",
            "Epoch 232/300\n",
            "17/17 [==============================] - 0s 16ms/step - loss: 144.3647 - val_loss: 147.8764\n",
            "Epoch 233/300\n",
            "17/17 [==============================] - 0s 17ms/step - loss: 144.3038 - val_loss: 147.9686\n",
            "Epoch 234/300\n",
            "17/17 [==============================] - 0s 15ms/step - loss: 144.2628 - val_loss: 147.8942\n",
            "Epoch 235/300\n",
            "17/17 [==============================] - 0s 18ms/step - loss: 144.2619 - val_loss: 147.8671\n",
            "Epoch 236/300\n",
            "17/17 [==============================] - 0s 17ms/step - loss: 144.2748 - val_loss: 147.8788\n",
            "Epoch 237/300\n",
            "17/17 [==============================] - 0s 16ms/step - loss: 144.2345 - val_loss: 147.8772\n",
            "Epoch 238/300\n",
            "17/17 [==============================] - 0s 17ms/step - loss: 144.2658 - val_loss: 147.8789\n",
            "Epoch 239/300\n",
            "17/17 [==============================] - 0s 19ms/step - loss: 144.2890 - val_loss: 147.8668\n",
            "Epoch 240/300\n",
            "17/17 [==============================] - 0s 19ms/step - loss: 144.2823 - val_loss: 147.8736\n",
            "Epoch 241/300\n",
            "17/17 [==============================] - 0s 17ms/step - loss: 144.2872 - val_loss: 147.8747\n",
            "Epoch 242/300\n",
            "17/17 [==============================] - 0s 20ms/step - loss: 144.2524 - val_loss: 147.9493\n",
            "Epoch 243/300\n",
            "17/17 [==============================] - 0s 19ms/step - loss: 144.2701 - val_loss: 147.9058\n",
            "Epoch 244/300\n",
            "17/17 [==============================] - 0s 20ms/step - loss: 144.2780 - val_loss: 147.8750\n",
            "Epoch 245/300\n",
            "17/17 [==============================] - 0s 18ms/step - loss: 144.2810 - val_loss: 147.8874\n",
            "Epoch 246/300\n",
            "17/17 [==============================] - 0s 18ms/step - loss: 144.2764 - val_loss: 147.9128\n",
            "Epoch 247/300\n",
            "17/17 [==============================] - 0s 19ms/step - loss: 144.2413 - val_loss: 147.8939\n",
            "Epoch 248/300\n",
            "17/17 [==============================] - 0s 17ms/step - loss: 144.3123 - val_loss: 147.8702\n",
            "Epoch 249/300\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 144.2915 - val_loss: 147.8666\n",
            "Epoch 250/300\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 144.2899 - val_loss: 147.8615\n",
            "Epoch 251/300\n",
            "17/17 [==============================] - 0s 16ms/step - loss: 144.3197 - val_loss: 147.8759\n",
            "Epoch 252/300\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 144.3267 - val_loss: 147.9332\n",
            "Epoch 253/300\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 144.2823 - val_loss: 147.9373\n",
            "Epoch 254/300\n",
            "17/17 [==============================] - 0s 16ms/step - loss: 144.2809 - val_loss: 147.9591\n",
            "Epoch 255/300\n",
            "17/17 [==============================] - 0s 15ms/step - loss: 144.2752 - val_loss: 147.9379\n",
            "Epoch 256/300\n",
            "17/17 [==============================] - 0s 18ms/step - loss: 144.3741 - val_loss: 147.9373\n",
            "Epoch 257/300\n",
            "17/17 [==============================] - 0s 18ms/step - loss: 144.3392 - val_loss: 147.9822\n",
            "Epoch 258/300\n",
            "17/17 [==============================] - 0s 19ms/step - loss: 144.2798 - val_loss: 147.9867\n",
            "Epoch 259/300\n",
            "17/17 [==============================] - 0s 19ms/step - loss: 144.2836 - val_loss: 147.9707\n",
            "Epoch 260/300\n",
            "17/17 [==============================] - 0s 19ms/step - loss: 144.3098 - val_loss: 147.8893\n",
            "Epoch 261/300\n",
            "17/17 [==============================] - 0s 17ms/step - loss: 144.2918 - val_loss: 147.8998\n",
            "Epoch 262/300\n",
            "17/17 [==============================] - 0s 19ms/step - loss: 144.2726 - val_loss: 147.8773\n",
            "Epoch 263/300\n",
            "17/17 [==============================] - 0s 16ms/step - loss: 144.2752 - val_loss: 147.8758\n",
            "Epoch 264/300\n",
            "17/17 [==============================] - 0s 20ms/step - loss: 144.3143 - val_loss: 147.8704\n",
            "Epoch 265/300\n",
            "17/17 [==============================] - 0s 20ms/step - loss: 144.2920 - val_loss: 147.8864\n",
            "Epoch 266/300\n",
            "17/17 [==============================] - 0s 16ms/step - loss: 144.3289 - val_loss: 147.9403\n",
            "Epoch 267/300\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 144.2514 - val_loss: 147.9232\n",
            "Epoch 268/300\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 144.3391 - val_loss: 147.9154\n",
            "Epoch 269/300\n",
            "17/17 [==============================] - 0s 17ms/step - loss: 144.2721 - val_loss: 147.9062\n",
            "Epoch 270/300\n",
            "17/17 [==============================] - 0s 16ms/step - loss: 144.2694 - val_loss: 147.8763\n",
            "Epoch 271/300\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 144.2580 - val_loss: 147.8664\n",
            "Epoch 272/300\n",
            "17/17 [==============================] - 0s 15ms/step - loss: 144.3295 - val_loss: 147.8745\n",
            "Epoch 273/300\n",
            "17/17 [==============================] - 0s 17ms/step - loss: 144.2457 - val_loss: 147.9122\n",
            "Epoch 274/300\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 144.2912 - val_loss: 148.0859\n",
            "Epoch 275/300\n",
            "17/17 [==============================] - 0s 16ms/step - loss: 144.3541 - val_loss: 148.0150\n",
            "Epoch 276/300\n",
            "17/17 [==============================] - 0s 15ms/step - loss: 144.3278 - val_loss: 147.9793\n",
            "Epoch 277/300\n",
            "17/17 [==============================] - 0s 15ms/step - loss: 144.3223 - val_loss: 147.9753\n",
            "Epoch 278/300\n",
            "17/17 [==============================] - 0s 17ms/step - loss: 144.2946 - val_loss: 147.9901\n",
            "Epoch 279/300\n",
            "17/17 [==============================] - 0s 19ms/step - loss: 144.3045 - val_loss: 147.9023\n",
            "Epoch 280/300\n",
            "17/17 [==============================] - 0s 19ms/step - loss: 144.2914 - val_loss: 147.9351\n",
            "Epoch 281/300\n",
            "17/17 [==============================] - 0s 16ms/step - loss: 144.4149 - val_loss: 147.9753\n",
            "Epoch 282/300\n",
            "17/17 [==============================] - 0s 17ms/step - loss: 144.2787 - val_loss: 147.9300\n",
            "Epoch 283/300\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 144.2756 - val_loss: 147.8844\n",
            "Epoch 284/300\n",
            "17/17 [==============================] - 0s 16ms/step - loss: 144.2774 - val_loss: 147.9066\n",
            "Epoch 285/300\n",
            "17/17 [==============================] - 0s 16ms/step - loss: 144.2932 - val_loss: 147.9175\n",
            "Epoch 286/300\n",
            "17/17 [==============================] - 0s 16ms/step - loss: 144.3381 - val_loss: 147.8746\n",
            "Epoch 287/300\n",
            "17/17 [==============================] - 0s 19ms/step - loss: 144.2822 - val_loss: 147.8714\n",
            "Epoch 288/300\n",
            "17/17 [==============================] - 0s 16ms/step - loss: 144.2655 - val_loss: 147.8629\n",
            "Epoch 289/300\n",
            "17/17 [==============================] - 0s 16ms/step - loss: 144.2743 - val_loss: 147.8819\n",
            "Epoch 290/300\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 144.2724 - val_loss: 147.8862\n",
            "Epoch 291/300\n",
            "17/17 [==============================] - 0s 17ms/step - loss: 144.3423 - val_loss: 147.8663\n",
            "Epoch 292/300\n",
            "17/17 [==============================] - 0s 16ms/step - loss: 144.2738 - val_loss: 147.9061\n",
            "Epoch 293/300\n",
            "17/17 [==============================] - 0s 16ms/step - loss: 144.3165 - val_loss: 147.9012\n",
            "Epoch 294/300\n",
            "17/17 [==============================] - 0s 17ms/step - loss: 144.2988 - val_loss: 147.9074\n",
            "Epoch 295/300\n",
            "17/17 [==============================] - 0s 17ms/step - loss: 144.3352 - val_loss: 147.9448\n",
            "Epoch 296/300\n",
            "17/17 [==============================] - 0s 15ms/step - loss: 144.3130 - val_loss: 147.9076\n",
            "Epoch 297/300\n",
            "17/17 [==============================] - 0s 16ms/step - loss: 144.3078 - val_loss: 148.0116\n",
            "Epoch 298/300\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 144.3233 - val_loss: 147.9412\n",
            "Epoch 299/300\n",
            "17/17 [==============================] - 0s 15ms/step - loss: 144.3117 - val_loss: 147.9355\n",
            "Epoch 300/300\n",
            "17/17 [==============================] - 0s 16ms/step - loss: 144.2974 - val_loss: 147.9866\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 147.7554\n",
            "Epoch 1/300\n",
            "17/17 [==============================] - 1s 15ms/step - loss: 328.7565 - val_loss: 249.1148\n",
            "Epoch 2/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 230.1745 - val_loss: 192.9009\n",
            "Epoch 3/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 185.9815 - val_loss: 166.3900\n",
            "Epoch 4/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 164.7411 - val_loss: 154.8619\n",
            "Epoch 5/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 155.1197 - val_loss: 149.8987\n",
            "Epoch 6/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 150.9950 - val_loss: 148.2642\n",
            "Epoch 7/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 149.2585 - val_loss: 147.8533\n",
            "Epoch 8/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 148.5873 - val_loss: 147.8564\n",
            "Epoch 9/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 148.5299 - val_loss: 147.8913\n",
            "Epoch 10/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 148.4729 - val_loss: 148.1818\n",
            "Epoch 11/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 148.4071 - val_loss: 148.0974\n",
            "Epoch 12/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 148.3704 - val_loss: 147.8917\n",
            "Epoch 13/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 148.4135 - val_loss: 147.8596\n",
            "Epoch 14/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 148.6066 - val_loss: 147.9138\n",
            "Epoch 15/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 148.4196 - val_loss: 148.1231\n",
            "Epoch 16/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 148.4218 - val_loss: 148.0797\n",
            "Epoch 17/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 148.4007 - val_loss: 148.0250\n",
            "Epoch 18/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 148.4474 - val_loss: 148.0247\n",
            "Epoch 19/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 148.3637 - val_loss: 148.2025\n",
            "Epoch 20/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 148.3198 - val_loss: 147.9685\n",
            "Epoch 21/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 148.4589 - val_loss: 148.2281\n",
            "Epoch 22/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 148.3528 - val_loss: 148.1582\n",
            "Epoch 23/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 148.3863 - val_loss: 148.0897\n",
            "Epoch 24/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 148.3502 - val_loss: 148.6922\n",
            "Epoch 25/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 148.5405 - val_loss: 148.8615\n",
            "Epoch 26/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 148.4048 - val_loss: 148.1796\n",
            "Epoch 27/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 148.3157 - val_loss: 148.5841\n",
            "Epoch 28/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 148.3792 - val_loss: 148.2007\n",
            "Epoch 29/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 148.2899 - val_loss: 148.0468\n",
            "Epoch 30/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 148.3455 - val_loss: 148.2461\n",
            "Epoch 31/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 148.2998 - val_loss: 148.2908\n",
            "Epoch 32/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 148.2557 - val_loss: 148.1188\n",
            "Epoch 33/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 148.2780 - val_loss: 147.9556\n",
            "Epoch 34/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 148.2767 - val_loss: 148.0900\n",
            "Epoch 35/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 148.2637 - val_loss: 147.9025\n",
            "Epoch 36/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 148.3382 - val_loss: 148.1882\n",
            "Epoch 37/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 148.2983 - val_loss: 148.2773\n",
            "Epoch 38/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 148.2284 - val_loss: 148.0481\n",
            "Epoch 39/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 148.2457 - val_loss: 147.7831\n",
            "Epoch 40/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 148.2421 - val_loss: 147.9939\n",
            "Epoch 41/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 148.1703 - val_loss: 148.5482\n",
            "Epoch 42/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 148.2274 - val_loss: 148.0105\n",
            "Epoch 43/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 148.1937 - val_loss: 148.0263\n",
            "Epoch 44/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 148.1390 - val_loss: 147.6402\n",
            "Epoch 45/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 148.2281 - val_loss: 147.6186\n",
            "Epoch 46/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 148.1297 - val_loss: 148.0343\n",
            "Epoch 47/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 148.0029 - val_loss: 147.6843\n",
            "Epoch 48/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 147.9799 - val_loss: 147.3873\n",
            "Epoch 49/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 148.0775 - val_loss: 148.0423\n",
            "Epoch 50/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 147.8725 - val_loss: 147.3983\n",
            "Epoch 51/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 147.8002 - val_loss: 147.1754\n",
            "Epoch 52/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 147.8551 - val_loss: 147.0648\n",
            "Epoch 53/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 147.6418 - val_loss: 147.1162\n",
            "Epoch 54/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 147.2871 - val_loss: 146.8197\n",
            "Epoch 55/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 147.3126 - val_loss: 146.5581\n",
            "Epoch 56/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 146.8354 - val_loss: 146.2042\n",
            "Epoch 57/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 146.5719 - val_loss: 145.9406\n",
            "Epoch 58/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 145.9423 - val_loss: 145.4406\n",
            "Epoch 59/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 145.1999 - val_loss: 145.0811\n",
            "Epoch 60/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 144.0159 - val_loss: 142.8034\n",
            "Epoch 61/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 142.1868 - val_loss: 142.1774\n",
            "Epoch 62/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 139.5417 - val_loss: 137.9044\n",
            "Epoch 63/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 135.6345 - val_loss: 133.2587\n",
            "Epoch 64/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 130.1944 - val_loss: 126.9928\n",
            "Epoch 65/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 123.6267 - val_loss: 123.6173\n",
            "Epoch 66/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 117.2247 - val_loss: 120.1361\n",
            "Epoch 67/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 109.8193 - val_loss: 106.6219\n",
            "Epoch 68/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 104.0096 - val_loss: 100.4835\n",
            "Epoch 69/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 98.5777 - val_loss: 102.9542\n",
            "Epoch 70/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 95.9587 - val_loss: 95.7313\n",
            "Epoch 71/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 86.4274 - val_loss: 131.9874\n",
            "Epoch 72/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 80.2310 - val_loss: 81.1938\n",
            "Epoch 73/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 72.2520 - val_loss: 79.5900\n",
            "Epoch 74/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 75.5564 - val_loss: 71.6248\n",
            "Epoch 75/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 90.2626 - val_loss: 132.5751\n",
            "Epoch 76/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 71.7465 - val_loss: 85.7534\n",
            "Epoch 77/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 73.2856 - val_loss: 70.0044\n",
            "Epoch 78/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 62.9741 - val_loss: 159.6765\n",
            "Epoch 79/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 87.8156 - val_loss: 66.0275\n",
            "Epoch 80/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 68.2592 - val_loss: 76.6375\n",
            "Epoch 81/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 71.1614 - val_loss: 64.0927\n",
            "Epoch 82/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 62.1352 - val_loss: 63.5714\n",
            "Epoch 83/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 56.6675 - val_loss: 91.6562\n",
            "Epoch 84/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 67.5400 - val_loss: 117.6103\n",
            "Epoch 85/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 64.6224 - val_loss: 74.5194\n",
            "Epoch 86/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 60.3905 - val_loss: 66.7756\n",
            "Epoch 87/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 70.6017 - val_loss: 127.4055\n",
            "Epoch 88/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 57.8734 - val_loss: 60.5641\n",
            "Epoch 89/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 57.2665 - val_loss: 66.3425\n",
            "Epoch 90/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 52.7605 - val_loss: 138.0090\n",
            "Epoch 91/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 67.7850 - val_loss: 84.6938\n",
            "Epoch 92/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 62.3066 - val_loss: 59.0325\n",
            "Epoch 93/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 46.9802 - val_loss: 80.2760\n",
            "Epoch 94/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 49.0234 - val_loss: 61.4209\n",
            "Epoch 95/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 44.6622 - val_loss: 65.5788\n",
            "Epoch 96/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 53.1694 - val_loss: 98.1128\n",
            "Epoch 97/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 61.7865 - val_loss: 307.9579\n",
            "Epoch 98/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 82.4551 - val_loss: 83.3274\n",
            "Epoch 99/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 52.4541 - val_loss: 344.5396\n",
            "Epoch 100/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 82.7290 - val_loss: 59.9191\n",
            "Epoch 101/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 44.2743 - val_loss: 57.9728\n",
            "Epoch 102/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 41.7933 - val_loss: 106.7218\n",
            "Epoch 103/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 48.7495 - val_loss: 56.5793\n",
            "Epoch 104/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 40.9282 - val_loss: 130.5303\n",
            "Epoch 105/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 55.1110 - val_loss: 52.9950\n",
            "Epoch 106/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 40.9282 - val_loss: 85.1625\n",
            "Epoch 107/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 43.2024 - val_loss: 54.9835\n",
            "Epoch 108/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 38.4418 - val_loss: 49.9179\n",
            "Epoch 109/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 36.5556 - val_loss: 56.9082\n",
            "Epoch 110/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 39.8692 - val_loss: 57.3184\n",
            "Epoch 111/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 36.7919 - val_loss: 59.8225\n",
            "Epoch 112/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 39.2392 - val_loss: 47.3715\n",
            "Epoch 113/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 47.6946 - val_loss: 51.5921\n",
            "Epoch 114/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 37.8834 - val_loss: 55.8511\n",
            "Epoch 115/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 47.6560 - val_loss: 44.7620\n",
            "Epoch 116/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 33.9876 - val_loss: 46.4051\n",
            "Epoch 117/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 34.3836 - val_loss: 46.3482\n",
            "Epoch 118/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 38.0230 - val_loss: 61.8835\n",
            "Epoch 119/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 43.1070 - val_loss: 43.8584\n",
            "Epoch 120/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 35.9071 - val_loss: 94.3382\n",
            "Epoch 121/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 39.4177 - val_loss: 45.2168\n",
            "Epoch 122/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 32.0898 - val_loss: 63.2988\n",
            "Epoch 123/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 31.0524 - val_loss: 54.7048\n",
            "Epoch 124/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 40.0226 - val_loss: 41.3733\n",
            "Epoch 125/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 30.2852 - val_loss: 80.7413\n",
            "Epoch 126/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 36.6217 - val_loss: 165.1220\n",
            "Epoch 127/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 35.5879 - val_loss: 63.3649\n",
            "Epoch 128/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 36.5803 - val_loss: 42.1354\n",
            "Epoch 129/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 26.4955 - val_loss: 40.8495\n",
            "Epoch 130/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 33.0970 - val_loss: 45.4116\n",
            "Epoch 131/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 27.8710 - val_loss: 42.1992\n",
            "Epoch 132/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 29.8651 - val_loss: 39.4909\n",
            "Epoch 133/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 39.2167 - val_loss: 44.9322\n",
            "Epoch 134/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 28.8555 - val_loss: 40.9277\n",
            "Epoch 135/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 24.9389 - val_loss: 38.7041\n",
            "Epoch 136/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 28.6049 - val_loss: 55.9031\n",
            "Epoch 137/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 26.1290 - val_loss: 44.9492\n",
            "Epoch 138/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 27.1073 - val_loss: 38.2114\n",
            "Epoch 139/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 23.4654 - val_loss: 56.4256\n",
            "Epoch 140/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 32.2018 - val_loss: 47.0259\n",
            "Epoch 141/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 37.2783 - val_loss: 37.1951\n",
            "Epoch 142/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 26.2960 - val_loss: 54.2281\n",
            "Epoch 143/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 28.8051 - val_loss: 44.1943\n",
            "Epoch 144/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 30.7094 - val_loss: 128.9314\n",
            "Epoch 145/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 37.9979 - val_loss: 37.6318\n",
            "Epoch 146/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 26.9491 - val_loss: 38.8953\n",
            "Epoch 147/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 32.8320 - val_loss: 36.9756\n",
            "Epoch 148/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 23.6305 - val_loss: 36.6406\n",
            "Epoch 149/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 32.4468 - val_loss: 41.7320\n",
            "Epoch 150/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 25.2949 - val_loss: 182.0550\n",
            "Epoch 151/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 41.6885 - val_loss: 47.2230\n",
            "Epoch 152/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 22.5675 - val_loss: 48.7746\n",
            "Epoch 153/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 22.8210 - val_loss: 83.3995\n",
            "Epoch 154/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 21.1532 - val_loss: 126.5022\n",
            "Epoch 155/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 35.5111 - val_loss: 35.1597\n",
            "Epoch 156/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 25.9318 - val_loss: 148.8332\n",
            "Epoch 157/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 35.4167 - val_loss: 38.2613\n",
            "Epoch 158/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 24.7253 - val_loss: 35.5814\n",
            "Epoch 159/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 22.0256 - val_loss: 148.0968\n",
            "Epoch 160/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 34.8494 - val_loss: 34.2763\n",
            "Epoch 161/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 23.5239 - val_loss: 59.4893\n",
            "Epoch 162/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 25.1771 - val_loss: 35.8973\n",
            "Epoch 163/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 22.8858 - val_loss: 58.1579\n",
            "Epoch 164/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 20.5100 - val_loss: 68.8216\n",
            "Epoch 165/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 27.3486 - val_loss: 49.4025\n",
            "Epoch 166/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 35.1711 - val_loss: 34.6954\n",
            "Epoch 167/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 24.1669 - val_loss: 40.9543\n",
            "Epoch 168/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 21.3356 - val_loss: 64.3337\n",
            "Epoch 169/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 22.2721 - val_loss: 33.4378\n",
            "Epoch 170/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 19.2455 - val_loss: 37.1611\n",
            "Epoch 171/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 28.0467 - val_loss: 33.3233\n",
            "Epoch 172/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 19.0453 - val_loss: 59.7218\n",
            "Epoch 173/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 19.3733 - val_loss: 39.2100\n",
            "Epoch 174/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 16.8716 - val_loss: 34.1531\n",
            "Epoch 175/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 26.3362 - val_loss: 35.1397\n",
            "Epoch 176/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 23.5687 - val_loss: 41.7216\n",
            "Epoch 177/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 18.0538 - val_loss: 34.0887\n",
            "Epoch 178/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 18.6713 - val_loss: 35.9010\n",
            "Epoch 179/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 29.8432 - val_loss: 33.8853\n",
            "Epoch 180/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 17.8999 - val_loss: 76.8320\n",
            "Epoch 181/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 40.8320 - val_loss: 33.3659\n",
            "Epoch 182/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 20.3670 - val_loss: 76.5506\n",
            "Epoch 183/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 23.1082 - val_loss: 33.2749\n",
            "Epoch 184/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 17.1366 - val_loss: 34.2538\n",
            "Epoch 185/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 19.4331 - val_loss: 35.3002\n",
            "Epoch 186/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 22.3174 - val_loss: 272.0872\n",
            "Epoch 187/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 34.9514 - val_loss: 34.0977\n",
            "Epoch 188/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 19.5677 - val_loss: 138.5578\n",
            "Epoch 189/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 24.2898 - val_loss: 32.9439\n",
            "Epoch 190/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 19.1238 - val_loss: 115.2640\n",
            "Epoch 191/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 23.1897 - val_loss: 523.4293\n",
            "Epoch 192/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 73.1665 - val_loss: 31.6846\n",
            "Epoch 193/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 16.8592 - val_loss: 42.1535\n",
            "Epoch 194/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 17.4454 - val_loss: 33.3881\n",
            "Epoch 195/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 16.1486 - val_loss: 31.2154\n",
            "Epoch 196/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 22.3603 - val_loss: 31.3273\n",
            "Epoch 197/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 16.9602 - val_loss: 34.8709\n",
            "Epoch 198/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 19.6031 - val_loss: 31.1011\n",
            "Epoch 199/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 20.5028 - val_loss: 35.5707\n",
            "Epoch 200/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 17.9448 - val_loss: 31.5260\n",
            "Epoch 201/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 17.3041 - val_loss: 30.8094\n",
            "Epoch 202/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 14.3912 - val_loss: 30.2995\n",
            "Epoch 203/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 14.6743 - val_loss: 33.4427\n",
            "Epoch 204/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 18.6519 - val_loss: 31.9551\n",
            "Epoch 205/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 14.0535 - val_loss: 41.4787\n",
            "Epoch 206/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 17.9168 - val_loss: 42.7784\n",
            "Epoch 207/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 15.3648 - val_loss: 31.3430\n",
            "Epoch 208/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 18.4086 - val_loss: 34.6079\n",
            "Epoch 209/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 19.0493 - val_loss: 30.7422\n",
            "Epoch 210/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 22.8087 - val_loss: 29.6447\n",
            "Epoch 211/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 12.5519 - val_loss: 32.2088\n",
            "Epoch 212/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 13.7875 - val_loss: 32.3330\n",
            "Epoch 213/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 14.2847 - val_loss: 32.7997\n",
            "Epoch 214/300\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 14.5207 - val_loss: 30.7652\n",
            "Epoch 215/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 17.6492 - val_loss: 35.0736\n",
            "Epoch 216/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 15.1594 - val_loss: 37.4530\n",
            "Epoch 217/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 19.8110 - val_loss: 34.2573\n",
            "Epoch 218/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 19.9297 - val_loss: 63.1334\n",
            "Epoch 219/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 21.9249 - val_loss: 29.7126\n",
            "Epoch 220/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 21.5870 - val_loss: 31.9107\n",
            "Epoch 221/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 16.3363 - val_loss: 30.6196\n",
            "Epoch 222/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 22.8969 - val_loss: 48.2129\n",
            "Epoch 223/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 14.7572 - val_loss: 29.7029\n",
            "Epoch 224/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 15.9453 - val_loss: 35.5811\n",
            "Epoch 225/300\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 15.5143 - val_loss: 28.8937\n",
            "Epoch 226/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 11.9986 - val_loss: 28.5982\n",
            "Epoch 227/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 12.3679 - val_loss: 28.3985\n",
            "Epoch 228/300\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 20.8506 - val_loss: 60.3521\n",
            "Epoch 229/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 22.7774 - val_loss: 31.0606\n",
            "Epoch 230/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 17.3970 - val_loss: 27.7939\n",
            "Epoch 231/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 12.9221 - val_loss: 28.1533\n",
            "Epoch 232/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 12.4502 - val_loss: 31.4920\n",
            "Epoch 233/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 11.9548 - val_loss: 27.8257\n",
            "Epoch 234/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 11.5824 - val_loss: 29.5144\n",
            "Epoch 235/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 14.5289 - val_loss: 30.4564\n",
            "Epoch 236/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 21.4055 - val_loss: 125.8678\n",
            "Epoch 237/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 20.3665 - val_loss: 27.1833\n",
            "Epoch 238/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 35.9006 - val_loss: 30.7429\n",
            "Epoch 239/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 14.2372 - val_loss: 46.6824\n",
            "Epoch 240/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 16.1538 - val_loss: 32.1498\n",
            "Epoch 241/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 12.9278 - val_loss: 31.2255\n",
            "Epoch 242/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 11.6551 - val_loss: 28.9077\n",
            "Epoch 243/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 11.4583 - val_loss: 28.2164\n",
            "Epoch 244/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 12.5275 - val_loss: 43.4508\n",
            "Epoch 245/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 24.1170 - val_loss: 27.9832\n",
            "Epoch 246/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 15.7355 - val_loss: 33.8942\n",
            "Epoch 247/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 10.9258 - val_loss: 35.1650\n",
            "Epoch 248/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 14.1444 - val_loss: 28.9465\n",
            "Epoch 249/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 12.5679 - val_loss: 29.6407\n",
            "Epoch 250/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 12.9297 - val_loss: 29.0801\n",
            "Epoch 251/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 12.1994 - val_loss: 30.6763\n",
            "Epoch 252/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 13.4320 - val_loss: 35.2883\n",
            "Epoch 253/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 12.7368 - val_loss: 170.0882\n",
            "Epoch 254/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 26.0007 - val_loss: 32.0384\n",
            "Epoch 255/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 11.1351 - val_loss: 31.2636\n",
            "Epoch 256/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 10.4975 - val_loss: 36.6118\n",
            "Epoch 257/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 13.1049 - val_loss: 32.1788\n",
            "Epoch 258/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 12.9233 - val_loss: 114.9594\n",
            "Epoch 259/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 29.3279 - val_loss: 28.2825\n",
            "Epoch 260/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 11.5883 - val_loss: 33.5694\n",
            "Epoch 261/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 13.9999 - val_loss: 36.6935\n",
            "Epoch 262/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 19.6790 - val_loss: 27.9276\n",
            "Epoch 263/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 12.0101 - val_loss: 27.9953\n",
            "Epoch 264/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 11.4031 - val_loss: 28.0702\n",
            "Epoch 265/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 19.8073 - val_loss: 31.0068\n",
            "Epoch 266/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 14.4697 - val_loss: 35.8162\n",
            "Epoch 267/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 9.9988 - val_loss: 28.9067\n",
            "Epoch 268/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 14.7765 - val_loss: 26.9439\n",
            "Epoch 269/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 13.9262 - val_loss: 26.8405\n",
            "Epoch 270/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 10.5733 - val_loss: 30.7350\n",
            "Epoch 271/300\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 12.6830 - val_loss: 27.7560\n",
            "Epoch 272/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 10.4355 - val_loss: 151.9376\n",
            "Epoch 273/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 36.4704 - val_loss: 32.9105\n",
            "Epoch 274/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 9.8845 - val_loss: 26.6262\n",
            "Epoch 275/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 13.4010 - val_loss: 28.2720\n",
            "Epoch 276/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 16.5150 - val_loss: 27.4148\n",
            "Epoch 277/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 10.7643 - val_loss: 26.4695\n",
            "Epoch 278/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 10.1528 - val_loss: 30.6696\n",
            "Epoch 279/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 9.6080 - val_loss: 26.8829\n",
            "Epoch 280/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 10.2007 - val_loss: 26.0010\n",
            "Epoch 281/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 33.2360 - val_loss: 54.8441\n",
            "Epoch 282/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 20.3488 - val_loss: 25.2414\n",
            "Epoch 283/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 10.3835 - val_loss: 27.0008\n",
            "Epoch 284/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 10.5575 - val_loss: 34.9984\n",
            "Epoch 285/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 13.0399 - val_loss: 28.6559\n",
            "Epoch 286/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 13.0287 - val_loss: 25.9195\n",
            "Epoch 287/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 9.5972 - val_loss: 25.6365\n",
            "Epoch 288/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 9.9724 - val_loss: 26.2581\n",
            "Epoch 289/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 9.4031 - val_loss: 25.7878\n",
            "Epoch 290/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 8.7077 - val_loss: 28.3587\n",
            "Epoch 291/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 10.2473 - val_loss: 28.3370\n",
            "Epoch 292/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 13.4990 - val_loss: 29.6196\n",
            "Epoch 293/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 11.1165 - val_loss: 28.3673\n",
            "Epoch 294/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 10.0681 - val_loss: 30.7227\n",
            "Epoch 295/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 9.7019 - val_loss: 26.5342\n",
            "Epoch 296/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 8.9685 - val_loss: 25.8973\n",
            "Epoch 297/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 10.2377 - val_loss: 52.1247\n",
            "Epoch 298/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 13.7781 - val_loss: 32.5784\n",
            "Epoch 299/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 10.8569 - val_loss: 27.4941\n",
            "Epoch 300/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 10.9393 - val_loss: 26.8382\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 29.0918\n",
            "Epoch 1/300\n",
            "17/17 [==============================] - 1s 13ms/step - loss: 308.4428 - val_loss: 244.3287\n",
            "Epoch 2/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 219.0136 - val_loss: 192.6083\n",
            "Epoch 3/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 179.4175 - val_loss: 167.3075\n",
            "Epoch 4/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 159.9013 - val_loss: 155.3638\n",
            "Epoch 5/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 150.2309 - val_loss: 150.0532\n",
            "Epoch 6/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 146.0751 - val_loss: 148.4384\n",
            "Epoch 7/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 144.6607 - val_loss: 147.8802\n",
            "Epoch 8/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 143.9922 - val_loss: 147.8433\n",
            "Epoch 9/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 143.8076 - val_loss: 148.2419\n",
            "Epoch 10/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 143.8633 - val_loss: 147.9553\n",
            "Epoch 11/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 143.7932 - val_loss: 147.8751\n",
            "Epoch 12/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 143.7840 - val_loss: 147.9933\n",
            "Epoch 13/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 143.8744 - val_loss: 147.9343\n",
            "Epoch 14/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 143.8274 - val_loss: 147.8974\n",
            "Epoch 15/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 143.7241 - val_loss: 147.8947\n",
            "Epoch 16/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 143.7186 - val_loss: 147.8997\n",
            "Epoch 17/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 143.8611 - val_loss: 147.9290\n",
            "Epoch 18/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 143.7114 - val_loss: 147.9059\n",
            "Epoch 19/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 143.7479 - val_loss: 147.9760\n",
            "Epoch 20/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 143.7309 - val_loss: 147.8998\n",
            "Epoch 21/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 143.6836 - val_loss: 147.9506\n",
            "Epoch 22/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 143.7784 - val_loss: 147.8338\n",
            "Epoch 23/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 143.6942 - val_loss: 148.1306\n",
            "Epoch 24/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 143.7617 - val_loss: 147.9695\n",
            "Epoch 25/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 143.7392 - val_loss: 147.7978\n",
            "Epoch 26/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 143.6720 - val_loss: 147.7988\n",
            "Epoch 27/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 143.6946 - val_loss: 147.9114\n",
            "Epoch 28/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 143.6374 - val_loss: 147.8195\n",
            "Epoch 29/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 143.6587 - val_loss: 147.7321\n",
            "Epoch 30/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 143.6355 - val_loss: 147.7096\n",
            "Epoch 31/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 143.8201 - val_loss: 147.7377\n",
            "Epoch 32/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 143.6048 - val_loss: 147.9644\n",
            "Epoch 33/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 143.5614 - val_loss: 148.0327\n",
            "Epoch 34/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 143.6696 - val_loss: 147.6768\n",
            "Epoch 35/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 143.5476 - val_loss: 147.6563\n",
            "Epoch 36/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 143.5344 - val_loss: 147.6198\n",
            "Epoch 37/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 143.5819 - val_loss: 147.7351\n",
            "Epoch 38/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 143.4981 - val_loss: 147.8160\n",
            "Epoch 39/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 143.5151 - val_loss: 147.6476\n",
            "Epoch 40/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 143.4162 - val_loss: 147.5134\n",
            "Epoch 41/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 143.4458 - val_loss: 147.5067\n",
            "Epoch 42/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 143.5253 - val_loss: 147.6999\n",
            "Epoch 43/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 143.4020 - val_loss: 147.4185\n",
            "Epoch 44/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 143.1724 - val_loss: 147.3438\n",
            "Epoch 45/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 143.1990 - val_loss: 147.2885\n",
            "Epoch 46/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 143.1014 - val_loss: 147.1218\n",
            "Epoch 47/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 142.9841 - val_loss: 146.9423\n",
            "Epoch 48/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 142.9053 - val_loss: 146.7626\n",
            "Epoch 49/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 142.5987 - val_loss: 146.5696\n",
            "Epoch 50/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 142.3064 - val_loss: 146.2144\n",
            "Epoch 51/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 141.9363 - val_loss: 145.8194\n",
            "Epoch 52/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 141.4588 - val_loss: 145.3670\n",
            "Epoch 53/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 140.7056 - val_loss: 144.9079\n",
            "Epoch 54/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 139.8621 - val_loss: 143.7045\n",
            "Epoch 55/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 138.8292 - val_loss: 142.6311\n",
            "Epoch 56/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 137.3495 - val_loss: 140.7972\n",
            "Epoch 57/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 135.1643 - val_loss: 138.8280\n",
            "Epoch 58/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 132.0176 - val_loss: 137.9594\n",
            "Epoch 59/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 128.1343 - val_loss: 134.0121\n",
            "Epoch 60/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 123.3061 - val_loss: 126.0910\n",
            "Epoch 61/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 117.5669 - val_loss: 127.0369\n",
            "Epoch 62/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 112.4137 - val_loss: 117.8094\n",
            "Epoch 63/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 105.7467 - val_loss: 115.1040\n",
            "Epoch 64/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 99.3871 - val_loss: 120.5449\n",
            "Epoch 65/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 93.3799 - val_loss: 95.8068\n",
            "Epoch 66/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 89.2811 - val_loss: 98.6383\n",
            "Epoch 67/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 83.3152 - val_loss: 88.1996\n",
            "Epoch 68/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 78.3109 - val_loss: 82.5995\n",
            "Epoch 69/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 71.8827 - val_loss: 215.1336\n",
            "Epoch 70/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 87.4900 - val_loss: 201.0140\n",
            "Epoch 71/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 74.7515 - val_loss: 79.2907\n",
            "Epoch 72/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 64.0168 - val_loss: 134.9186\n",
            "Epoch 73/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 69.2969 - val_loss: 87.6816\n",
            "Epoch 74/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 69.7894 - val_loss: 77.1852\n",
            "Epoch 75/300\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 63.7129 - val_loss: 66.5434\n",
            "Epoch 76/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 54.5274 - val_loss: 71.2973\n",
            "Epoch 77/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 60.0343 - val_loss: 74.5044\n",
            "Epoch 78/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 54.1667 - val_loss: 79.5108\n",
            "Epoch 79/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 64.2394 - val_loss: 108.0627\n",
            "Epoch 80/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 58.3206 - val_loss: 61.5449\n",
            "Epoch 81/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 51.4763 - val_loss: 60.8723\n",
            "Epoch 82/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 54.2416 - val_loss: 104.5372\n",
            "Epoch 83/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 54.8219 - val_loss: 66.5561\n",
            "Epoch 84/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 57.6629 - val_loss: 59.6562\n",
            "Epoch 85/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 47.3757 - val_loss: 60.6594\n",
            "Epoch 86/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 48.3892 - val_loss: 62.0058\n",
            "Epoch 87/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 59.0293 - val_loss: 129.4949\n",
            "Epoch 88/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 57.5732 - val_loss: 70.4037\n",
            "Epoch 89/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 47.9154 - val_loss: 62.6165\n",
            "Epoch 90/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 55.6213 - val_loss: 74.4796\n",
            "Epoch 91/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 56.9970 - val_loss: 92.2337\n",
            "Epoch 92/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 52.8220 - val_loss: 114.5814\n",
            "Epoch 93/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 49.6117 - val_loss: 58.4083\n",
            "Epoch 94/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 42.3577 - val_loss: 60.5084\n",
            "Epoch 95/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 46.9414 - val_loss: 57.2012\n",
            "Epoch 96/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 52.2001 - val_loss: 56.2827\n",
            "Epoch 97/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 44.0088 - val_loss: 337.7066\n",
            "Epoch 98/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 72.1645 - val_loss: 66.5328\n",
            "Epoch 99/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 42.7997 - val_loss: 54.3402\n",
            "Epoch 100/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 43.1593 - val_loss: 53.2111\n",
            "Epoch 101/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 42.7267 - val_loss: 52.8645\n",
            "Epoch 102/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 55.5071 - val_loss: 55.4786\n",
            "Epoch 103/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 40.7478 - val_loss: 52.6077\n",
            "Epoch 104/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 44.9379 - val_loss: 54.3319\n",
            "Epoch 105/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 40.8656 - val_loss: 108.1204\n",
            "Epoch 106/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 45.2547 - val_loss: 53.6850\n",
            "Epoch 107/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 42.3288 - val_loss: 112.5769\n",
            "Epoch 108/300\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 51.7731 - val_loss: 51.3136\n",
            "Epoch 109/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 37.6951 - val_loss: 51.4473\n",
            "Epoch 110/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 40.3498 - val_loss: 52.0562\n",
            "Epoch 111/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 38.9878 - val_loss: 289.0147\n",
            "Epoch 112/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 58.9662 - val_loss: 53.3199\n",
            "Epoch 113/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 35.0934 - val_loss: 80.3706\n",
            "Epoch 114/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 42.8679 - val_loss: 49.5933\n",
            "Epoch 115/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 32.9712 - val_loss: 48.0412\n",
            "Epoch 116/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 36.7056 - val_loss: 47.3953\n",
            "Epoch 117/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 31.2629 - val_loss: 109.4336\n",
            "Epoch 118/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 40.0345 - val_loss: 47.9462\n",
            "Epoch 119/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 32.9626 - val_loss: 103.9432\n",
            "Epoch 120/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 42.5356 - val_loss: 46.1909\n",
            "Epoch 121/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 38.9016 - val_loss: 105.0053\n",
            "Epoch 122/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 34.0467 - val_loss: 353.4084\n",
            "Epoch 123/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 60.7775 - val_loss: 62.9014\n",
            "Epoch 124/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 29.1479 - val_loss: 43.8823\n",
            "Epoch 125/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 33.1794 - val_loss: 45.4313\n",
            "Epoch 126/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 29.1290 - val_loss: 139.1132\n",
            "Epoch 127/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 43.7075 - val_loss: 59.9399\n",
            "Epoch 128/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 29.7976 - val_loss: 43.5387\n",
            "Epoch 129/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 37.2879 - val_loss: 49.4968\n",
            "Epoch 130/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 31.0715 - val_loss: 54.9898\n",
            "Epoch 131/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 34.8283 - val_loss: 42.0441\n",
            "Epoch 132/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 28.6636 - val_loss: 53.8095\n",
            "Epoch 133/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 26.8792 - val_loss: 42.8641\n",
            "Epoch 134/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 27.6529 - val_loss: 40.6813\n",
            "Epoch 135/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 24.7452 - val_loss: 239.5685\n",
            "Epoch 136/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 40.2009 - val_loss: 43.5976\n",
            "Epoch 137/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 25.0549 - val_loss: 40.3735\n",
            "Epoch 138/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 26.0154 - val_loss: 40.9873\n",
            "Epoch 139/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 29.4674 - val_loss: 43.9934\n",
            "Epoch 140/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 26.2324 - val_loss: 40.5150\n",
            "Epoch 141/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 23.1366 - val_loss: 41.7757\n",
            "Epoch 142/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 22.9854 - val_loss: 43.4670\n",
            "Epoch 143/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 31.5661 - val_loss: 39.4934\n",
            "Epoch 144/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 27.3568 - val_loss: 38.3501\n",
            "Epoch 145/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 21.3633 - val_loss: 44.4332\n",
            "Epoch 146/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 25.0108 - val_loss: 38.2210\n",
            "Epoch 147/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 20.8179 - val_loss: 37.2716\n",
            "Epoch 148/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 26.9025 - val_loss: 37.4778\n",
            "Epoch 149/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 20.3510 - val_loss: 63.6610\n",
            "Epoch 150/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 25.3814 - val_loss: 38.2821\n",
            "Epoch 151/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 20.7123 - val_loss: 36.4998\n",
            "Epoch 152/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 25.3747 - val_loss: 155.2278\n",
            "Epoch 153/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 35.1333 - val_loss: 42.9587\n",
            "Epoch 154/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 25.2147 - val_loss: 94.5435\n",
            "Epoch 155/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 26.4948 - val_loss: 52.4722\n",
            "Epoch 156/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 21.3767 - val_loss: 35.9616\n",
            "Epoch 157/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 20.0554 - val_loss: 41.9155\n",
            "Epoch 158/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 26.7102 - val_loss: 57.1293\n",
            "Epoch 159/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 22.4266 - val_loss: 35.5491\n",
            "Epoch 160/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 22.9617 - val_loss: 36.8945\n",
            "Epoch 161/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 24.7622 - val_loss: 35.9955\n",
            "Epoch 162/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 20.2305 - val_loss: 39.5460\n",
            "Epoch 163/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 20.8430 - val_loss: 34.9541\n",
            "Epoch 164/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 26.7325 - val_loss: 36.4307\n",
            "Epoch 165/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 21.0265 - val_loss: 38.5159\n",
            "Epoch 166/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 22.5542 - val_loss: 44.1943\n",
            "Epoch 167/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 19.5732 - val_loss: 37.1430\n",
            "Epoch 168/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 18.2668 - val_loss: 44.1557\n",
            "Epoch 169/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 29.0813 - val_loss: 48.6766\n",
            "Epoch 170/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 18.4601 - val_loss: 34.1414\n",
            "Epoch 171/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 18.7856 - val_loss: 106.6769\n",
            "Epoch 172/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 30.4847 - val_loss: 41.3987\n",
            "Epoch 173/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 19.2759 - val_loss: 34.3289\n",
            "Epoch 174/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 19.4641 - val_loss: 34.4123\n",
            "Epoch 175/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 18.3173 - val_loss: 35.1893\n",
            "Epoch 176/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 20.1697 - val_loss: 33.5356\n",
            "Epoch 177/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 25.8843 - val_loss: 41.9402\n",
            "Epoch 178/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 17.0095 - val_loss: 82.6049\n",
            "Epoch 179/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 21.8698 - val_loss: 34.4980\n",
            "Epoch 180/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 17.8470 - val_loss: 33.8423\n",
            "Epoch 181/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 17.8672 - val_loss: 57.0346\n",
            "Epoch 182/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 22.6200 - val_loss: 43.3032\n",
            "Epoch 183/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 26.7982 - val_loss: 36.3994\n",
            "Epoch 184/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 16.7499 - val_loss: 52.4482\n",
            "Epoch 185/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 18.7602 - val_loss: 42.7872\n",
            "Epoch 186/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 17.9848 - val_loss: 56.1673\n",
            "Epoch 187/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 19.0690 - val_loss: 32.4873\n",
            "Epoch 188/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 16.8703 - val_loss: 32.7820\n",
            "Epoch 189/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 16.5032 - val_loss: 59.4533\n",
            "Epoch 190/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 19.3857 - val_loss: 67.6183\n",
            "Epoch 191/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 19.3259 - val_loss: 35.7674\n",
            "Epoch 192/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 16.7886 - val_loss: 71.5290\n",
            "Epoch 193/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 32.1101 - val_loss: 49.7691\n",
            "Epoch 194/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 19.1098 - val_loss: 35.4472\n",
            "Epoch 195/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 18.6374 - val_loss: 43.5850\n",
            "Epoch 196/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 18.1784 - val_loss: 104.3808\n",
            "Epoch 197/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 22.1465 - val_loss: 42.0591\n",
            "Epoch 198/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 16.9792 - val_loss: 34.3493\n",
            "Epoch 199/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 19.2734 - val_loss: 31.9070\n",
            "Epoch 200/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 15.9919 - val_loss: 35.6862\n",
            "Epoch 201/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 15.8092 - val_loss: 38.3656\n",
            "Epoch 202/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 15.7051 - val_loss: 40.8160\n",
            "Epoch 203/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 19.6377 - val_loss: 39.3052\n",
            "Epoch 204/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 16.5048 - val_loss: 39.1105\n",
            "Epoch 205/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 18.8637 - val_loss: 59.5113\n",
            "Epoch 206/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 17.2170 - val_loss: 34.3559\n",
            "Epoch 207/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 15.8277 - val_loss: 32.4550\n",
            "Epoch 208/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 16.8241 - val_loss: 53.1537\n",
            "Epoch 209/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 17.2527 - val_loss: 31.5963\n",
            "Epoch 210/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 16.4357 - val_loss: 31.2953\n",
            "Epoch 211/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 14.7744 - val_loss: 52.5477\n",
            "Epoch 212/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 16.3030 - val_loss: 32.8538\n",
            "Epoch 213/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 15.6177 - val_loss: 82.0154\n",
            "Epoch 214/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 18.5602 - val_loss: 31.0184\n",
            "Epoch 215/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 14.3254 - val_loss: 78.4468\n",
            "Epoch 216/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 23.9886 - val_loss: 85.2713\n",
            "Epoch 217/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 19.2699 - val_loss: 31.9037\n",
            "Epoch 218/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 14.2683 - val_loss: 30.6595\n",
            "Epoch 219/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 15.3178 - val_loss: 35.9674\n",
            "Epoch 220/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 19.7146 - val_loss: 60.5082\n",
            "Epoch 221/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 17.1220 - val_loss: 52.5604\n",
            "Epoch 222/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 16.0216 - val_loss: 31.0671\n",
            "Epoch 223/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 14.0929 - val_loss: 31.1372\n",
            "Epoch 224/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 14.7477 - val_loss: 32.5707\n",
            "Epoch 225/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 13.5174 - val_loss: 68.8926\n",
            "Epoch 226/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 22.6562 - val_loss: 36.9379\n",
            "Epoch 227/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 18.0458 - val_loss: 31.8340\n",
            "Epoch 228/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 14.4753 - val_loss: 31.9371\n",
            "Epoch 229/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 13.2895 - val_loss: 114.8907\n",
            "Epoch 230/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 25.0421 - val_loss: 47.0435\n",
            "Epoch 231/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 15.5158 - val_loss: 35.1726\n",
            "Epoch 232/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 15.5803 - val_loss: 49.3381\n",
            "Epoch 233/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 14.1632 - val_loss: 35.2285\n",
            "Epoch 234/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 13.6445 - val_loss: 61.9786\n",
            "Epoch 235/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 23.7655 - val_loss: 31.7183\n",
            "Epoch 236/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 13.6094 - val_loss: 29.1365\n",
            "Epoch 237/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 15.7439 - val_loss: 33.6633\n",
            "Epoch 238/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 16.5966 - val_loss: 29.7612\n",
            "Epoch 239/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 13.7630 - val_loss: 30.8317\n",
            "Epoch 240/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 13.2205 - val_loss: 70.0833\n",
            "Epoch 241/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 30.0212 - val_loss: 28.5948\n",
            "Epoch 242/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 14.8414 - val_loss: 45.3476\n",
            "Epoch 243/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 14.6919 - val_loss: 27.8460\n",
            "Epoch 244/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 14.9797 - val_loss: 28.9782\n",
            "Epoch 245/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 13.0227 - val_loss: 27.7400\n",
            "Epoch 246/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 18.9892 - val_loss: 29.5558\n",
            "Epoch 247/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 12.2370 - val_loss: 28.9622\n",
            "Epoch 248/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 12.9191 - val_loss: 27.0287\n",
            "Epoch 249/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 13.3878 - val_loss: 80.3324\n",
            "Epoch 250/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 17.5888 - val_loss: 44.9758\n",
            "Epoch 251/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 22.4350 - val_loss: 30.1049\n",
            "Epoch 252/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 14.0341 - val_loss: 28.7161\n",
            "Epoch 253/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 12.8941 - val_loss: 42.3195\n",
            "Epoch 254/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 14.0688 - val_loss: 28.2318\n",
            "Epoch 255/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 15.3377 - val_loss: 37.4417\n",
            "Epoch 256/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 11.9324 - val_loss: 28.3170\n",
            "Epoch 257/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 13.8410 - val_loss: 30.8111\n",
            "Epoch 258/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 12.1674 - val_loss: 29.4646\n",
            "Epoch 259/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 18.2472 - val_loss: 42.3334\n",
            "Epoch 260/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 13.2941 - val_loss: 30.7442\n",
            "Epoch 261/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 13.2301 - val_loss: 59.5117\n",
            "Epoch 262/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 15.3009 - val_loss: 28.9305\n",
            "Epoch 263/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 11.8075 - val_loss: 70.4923\n",
            "Epoch 264/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 15.0661 - val_loss: 123.6162\n",
            "Epoch 265/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 25.4459 - val_loss: 33.7605\n",
            "Epoch 266/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 13.8161 - val_loss: 35.5609\n",
            "Epoch 267/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 10.9854 - val_loss: 27.8039\n",
            "Epoch 268/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 10.5487 - val_loss: 87.3692\n",
            "Epoch 269/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 14.4481 - val_loss: 32.5764\n",
            "Epoch 270/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 11.4798 - val_loss: 32.5993\n",
            "Epoch 271/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 13.1685 - val_loss: 25.0011\n",
            "Epoch 272/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 10.8754 - val_loss: 24.2634\n",
            "Epoch 273/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 10.1482 - val_loss: 23.8363\n",
            "Epoch 274/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 12.3053 - val_loss: 25.5310\n",
            "Epoch 275/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 10.0568 - val_loss: 26.3334\n",
            "Epoch 276/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 13.0059 - val_loss: 37.6358\n",
            "Epoch 277/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 15.0050 - val_loss: 31.3362\n",
            "Epoch 278/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 11.9248 - val_loss: 23.3887\n",
            "Epoch 279/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 10.5519 - val_loss: 23.8743\n",
            "Epoch 280/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 17.1018 - val_loss: 23.8151\n",
            "Epoch 281/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 10.6947 - val_loss: 60.5934\n",
            "Epoch 282/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 18.5825 - val_loss: 23.7635\n",
            "Epoch 283/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 11.0234 - val_loss: 28.1664\n",
            "Epoch 284/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 9.4878 - val_loss: 23.1044\n",
            "Epoch 285/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 13.5934 - val_loss: 27.5340\n",
            "Epoch 286/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 11.4384 - val_loss: 22.4897\n",
            "Epoch 287/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 9.5389 - val_loss: 22.8247\n",
            "Epoch 288/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 8.9827 - val_loss: 46.2882\n",
            "Epoch 289/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 10.2428 - val_loss: 24.4075\n",
            "Epoch 290/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 8.9694 - val_loss: 23.0149\n",
            "Epoch 291/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 8.8633 - val_loss: 22.0293\n",
            "Epoch 292/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 9.5145 - val_loss: 36.6999\n",
            "Epoch 293/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 9.6375 - val_loss: 24.0227\n",
            "Epoch 294/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 8.7925 - val_loss: 22.6255\n",
            "Epoch 295/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 9.9855 - val_loss: 36.1445\n",
            "Epoch 296/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 9.0945 - val_loss: 23.2518\n",
            "Epoch 297/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 10.0731 - val_loss: 30.5567\n",
            "Epoch 298/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 9.7220 - val_loss: 33.2063\n",
            "Epoch 299/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 9.2995 - val_loss: 32.6933\n",
            "Epoch 300/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 8.2088 - val_loss: 30.7684\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 33.8586\n",
            "Epoch 1/300\n",
            "17/17 [==============================] - 1s 14ms/step - loss: 308.9558 - val_loss: 249.1656\n",
            "Epoch 2/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 220.0436 - val_loss: 193.2264\n",
            "Epoch 3/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 178.7105 - val_loss: 167.0388\n",
            "Epoch 4/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 158.7438 - val_loss: 153.9832\n",
            "Epoch 5/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 149.2130 - val_loss: 150.2367\n",
            "Epoch 6/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 146.2555 - val_loss: 148.1582\n",
            "Epoch 7/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 144.7473 - val_loss: 147.9497\n",
            "Epoch 8/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 144.4858 - val_loss: 147.8532\n",
            "Epoch 9/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 144.4204 - val_loss: 148.0312\n",
            "Epoch 10/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 144.4473 - val_loss: 148.0115\n",
            "Epoch 11/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 144.2898 - val_loss: 148.0236\n",
            "Epoch 12/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 144.3609 - val_loss: 147.8798\n",
            "Epoch 13/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 144.3140 - val_loss: 147.8481\n",
            "Epoch 14/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 144.3225 - val_loss: 148.0072\n",
            "Epoch 15/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 144.4314 - val_loss: 147.8521\n",
            "Epoch 16/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 144.3945 - val_loss: 147.8323\n",
            "Epoch 17/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 144.3901 - val_loss: 147.8599\n",
            "Epoch 18/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 144.2913 - val_loss: 147.8206\n",
            "Epoch 19/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 144.2731 - val_loss: 147.8105\n",
            "Epoch 20/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 144.2200 - val_loss: 147.8163\n",
            "Epoch 21/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 144.2570 - val_loss: 147.8009\n",
            "Epoch 22/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 144.3815 - val_loss: 147.8249\n",
            "Epoch 23/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 144.2921 - val_loss: 147.7937\n",
            "Epoch 24/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 144.2769 - val_loss: 147.7861\n",
            "Epoch 25/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 144.3349 - val_loss: 147.8186\n",
            "Epoch 26/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 144.1959 - val_loss: 147.7830\n",
            "Epoch 27/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 144.3366 - val_loss: 147.7693\n",
            "Epoch 28/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 144.2191 - val_loss: 147.7741\n",
            "Epoch 29/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 144.3369 - val_loss: 147.7573\n",
            "Epoch 30/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 144.2435 - val_loss: 147.7543\n",
            "Epoch 31/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 144.2680 - val_loss: 147.7887\n",
            "Epoch 32/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 144.4362 - val_loss: 147.7515\n",
            "Epoch 33/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 144.1811 - val_loss: 147.7688\n",
            "Epoch 34/300\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 144.1930 - val_loss: 147.7169\n",
            "Epoch 35/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 144.2233 - val_loss: 147.7093\n",
            "Epoch 36/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 144.3404 - val_loss: 147.7627\n",
            "Epoch 37/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 144.1644 - val_loss: 147.7770\n",
            "Epoch 38/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 144.1553 - val_loss: 147.7955\n",
            "Epoch 39/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 144.1184 - val_loss: 147.8527\n",
            "Epoch 40/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 144.1826 - val_loss: 147.6491\n",
            "Epoch 41/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 144.1478 - val_loss: 147.8187\n",
            "Epoch 42/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 144.0128 - val_loss: 147.6239\n",
            "Epoch 43/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 144.0452 - val_loss: 147.7054\n",
            "Epoch 44/300\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 144.0576 - val_loss: 147.6056\n",
            "Epoch 45/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 143.9768 - val_loss: 147.5606\n",
            "Epoch 46/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 143.9851 - val_loss: 147.4911\n",
            "Epoch 47/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 143.9159 - val_loss: 147.4784\n",
            "Epoch 48/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 143.8714 - val_loss: 147.3963\n",
            "Epoch 49/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 143.8287 - val_loss: 147.3531\n",
            "Epoch 50/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 143.8182 - val_loss: 147.2727\n",
            "Epoch 51/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 143.6741 - val_loss: 147.1874\n",
            "Epoch 52/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 143.5812 - val_loss: 147.0900\n",
            "Epoch 53/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 143.5608 - val_loss: 146.9637\n",
            "Epoch 54/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 143.3617 - val_loss: 146.8442\n",
            "Epoch 55/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 143.1723 - val_loss: 146.7352\n",
            "Epoch 56/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 142.9372 - val_loss: 146.3547\n",
            "Epoch 57/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 142.5751 - val_loss: 145.9868\n",
            "Epoch 58/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 142.1855 - val_loss: 145.4880\n",
            "Epoch 59/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 141.8046 - val_loss: 144.8138\n",
            "Epoch 60/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 140.8842 - val_loss: 144.3777\n",
            "Epoch 61/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 139.6537 - val_loss: 142.6301\n",
            "Epoch 62/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 138.0631 - val_loss: 140.5403\n",
            "Epoch 63/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 135.6957 - val_loss: 139.1925\n",
            "Epoch 64/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 132.5761 - val_loss: 135.6160\n",
            "Epoch 65/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 127.6912 - val_loss: 128.7111\n",
            "Epoch 66/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 122.1165 - val_loss: 126.5588\n",
            "Epoch 67/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 115.2979 - val_loss: 117.1107\n",
            "Epoch 68/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 108.7223 - val_loss: 108.8958\n",
            "Epoch 69/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 101.9131 - val_loss: 104.3130\n",
            "Epoch 70/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 95.3616 - val_loss: 101.0779\n",
            "Epoch 71/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 90.9328 - val_loss: 105.2115\n",
            "Epoch 72/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 87.8634 - val_loss: 85.4825\n",
            "Epoch 73/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 84.1257 - val_loss: 81.5650\n",
            "Epoch 74/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 86.7980 - val_loss: 79.3181\n",
            "Epoch 75/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 75.3527 - val_loss: 73.8596\n",
            "Epoch 76/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 80.9795 - val_loss: 80.2223\n",
            "Epoch 77/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 65.2357 - val_loss: 131.0049\n",
            "Epoch 78/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 75.2753 - val_loss: 78.1195\n",
            "Epoch 79/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 77.7714 - val_loss: 188.4373\n",
            "Epoch 80/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 112.4740 - val_loss: 71.3493\n",
            "Epoch 81/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 60.9852 - val_loss: 67.6435\n",
            "Epoch 82/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 68.1815 - val_loss: 66.2511\n",
            "Epoch 83/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 59.8919 - val_loss: 108.1016\n",
            "Epoch 84/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 65.0190 - val_loss: 65.2460\n",
            "Epoch 85/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 61.3109 - val_loss: 64.8020\n",
            "Epoch 86/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 56.9347 - val_loss: 74.5162\n",
            "Epoch 87/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 53.7361 - val_loss: 141.7506\n",
            "Epoch 88/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 72.0716 - val_loss: 67.7083\n",
            "Epoch 89/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 53.5139 - val_loss: 71.1606\n",
            "Epoch 90/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 53.2844 - val_loss: 65.7866\n",
            "Epoch 91/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 53.1958 - val_loss: 88.4897\n",
            "Epoch 92/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 53.5452 - val_loss: 88.7726\n",
            "Epoch 93/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 57.9408 - val_loss: 66.1509\n",
            "Epoch 94/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 53.0408 - val_loss: 61.4545\n",
            "Epoch 95/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 49.5973 - val_loss: 154.1401\n",
            "Epoch 96/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 73.9946 - val_loss: 60.2893\n",
            "Epoch 97/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 65.4115 - val_loss: 68.3903\n",
            "Epoch 98/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 57.6767 - val_loss: 64.6419\n",
            "Epoch 99/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 45.7223 - val_loss: 63.2941\n",
            "Epoch 100/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 48.6805 - val_loss: 70.6833\n",
            "Epoch 101/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 52.0138 - val_loss: 59.3447\n",
            "Epoch 102/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 44.3550 - val_loss: 379.6039\n",
            "Epoch 103/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 274.7331 - val_loss: 210.0396\n",
            "Epoch 104/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 178.1970 - val_loss: 163.3576\n",
            "Epoch 105/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 151.4904 - val_loss: 150.3633\n",
            "Epoch 106/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 116.3999 - val_loss: 91.2830\n",
            "Epoch 107/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 83.5353 - val_loss: 77.4351\n",
            "Epoch 108/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 67.7308 - val_loss: 78.7932\n",
            "Epoch 109/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 60.7872 - val_loss: 65.2386\n",
            "Epoch 110/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 54.0276 - val_loss: 100.9235\n",
            "Epoch 111/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 52.5170 - val_loss: 61.6852\n",
            "Epoch 112/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 47.2756 - val_loss: 75.1469\n",
            "Epoch 113/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 49.6685 - val_loss: 61.0104\n",
            "Epoch 114/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 44.0433 - val_loss: 79.9918\n",
            "Epoch 115/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 42.3451 - val_loss: 57.2181\n",
            "Epoch 116/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 40.3823 - val_loss: 58.1181\n",
            "Epoch 117/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 44.3848 - val_loss: 61.6802\n",
            "Epoch 118/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 53.9640 - val_loss: 59.4371\n",
            "Epoch 119/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 38.4422 - val_loss: 54.9178\n",
            "Epoch 120/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 53.6964 - val_loss: 54.6109\n",
            "Epoch 121/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 46.1976 - val_loss: 54.8784\n",
            "Epoch 122/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 43.5782 - val_loss: 120.7862\n",
            "Epoch 123/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 44.6086 - val_loss: 53.1137\n",
            "Epoch 124/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 37.6497 - val_loss: 58.5135\n",
            "Epoch 125/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 46.9817 - val_loss: 57.2114\n",
            "Epoch 126/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 49.1328 - val_loss: 51.8220\n",
            "Epoch 127/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 34.6306 - val_loss: 59.6255\n",
            "Epoch 128/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 45.0177 - val_loss: 49.8335\n",
            "Epoch 129/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 37.4635 - val_loss: 180.8212\n",
            "Epoch 130/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 43.7778 - val_loss: 49.2051\n",
            "Epoch 131/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 43.2432 - val_loss: 56.8066\n",
            "Epoch 132/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 35.6530 - val_loss: 62.2478\n",
            "Epoch 133/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 31.7565 - val_loss: 53.2368\n",
            "Epoch 134/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 42.1470 - val_loss: 47.0007\n",
            "Epoch 135/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 36.5835 - val_loss: 48.3321\n",
            "Epoch 136/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 37.0538 - val_loss: 45.9851\n",
            "Epoch 137/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 29.5769 - val_loss: 45.8085\n",
            "Epoch 138/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 40.9499 - val_loss: 52.1272\n",
            "Epoch 139/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 30.5369 - val_loss: 54.7430\n",
            "Epoch 140/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 32.1863 - val_loss: 129.4063\n",
            "Epoch 141/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 39.6646 - val_loss: 43.7682\n",
            "Epoch 142/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 33.2412 - val_loss: 44.3954\n",
            "Epoch 143/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 31.8551 - val_loss: 55.6355\n",
            "Epoch 144/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 34.3736 - val_loss: 42.3053\n",
            "Epoch 145/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 31.1166 - val_loss: 64.8903\n",
            "Epoch 146/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 39.9223 - val_loss: 57.7486\n",
            "Epoch 147/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 29.7091 - val_loss: 44.9610\n",
            "Epoch 148/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 32.3832 - val_loss: 43.4886\n",
            "Epoch 149/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 28.6353 - val_loss: 41.3893\n",
            "Epoch 150/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 30.2456 - val_loss: 39.8810\n",
            "Epoch 151/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 27.3452 - val_loss: 41.0460\n",
            "Epoch 152/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 34.4415 - val_loss: 44.7078\n",
            "Epoch 153/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 25.7180 - val_loss: 65.2080\n",
            "Epoch 154/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 33.3783 - val_loss: 44.6952\n",
            "Epoch 155/300\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 29.8642 - val_loss: 48.6607\n",
            "Epoch 156/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 25.3624 - val_loss: 59.7657\n",
            "Epoch 157/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 30.8162 - val_loss: 68.4974\n",
            "Epoch 158/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 26.9021 - val_loss: 39.4130\n",
            "Epoch 159/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 28.3042 - val_loss: 43.0075\n",
            "Epoch 160/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 24.1013 - val_loss: 38.2869\n",
            "Epoch 161/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 22.1246 - val_loss: 117.1244\n",
            "Epoch 162/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 30.7727 - val_loss: 97.6436\n",
            "Epoch 163/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 26.4883 - val_loss: 49.7885\n",
            "Epoch 164/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 27.9963 - val_loss: 120.5954\n",
            "Epoch 165/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 34.3814 - val_loss: 43.2508\n",
            "Epoch 166/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 26.3189 - val_loss: 52.0352\n",
            "Epoch 167/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 23.7313 - val_loss: 37.0855\n",
            "Epoch 168/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 26.3846 - val_loss: 60.0994\n",
            "Epoch 169/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 24.0602 - val_loss: 37.0133\n",
            "Epoch 170/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 21.7652 - val_loss: 120.1375\n",
            "Epoch 171/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 38.9984 - val_loss: 41.0962\n",
            "Epoch 172/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 21.2580 - val_loss: 38.5931\n",
            "Epoch 173/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 21.4306 - val_loss: 44.8904\n",
            "Epoch 174/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 25.7987 - val_loss: 40.1469\n",
            "Epoch 175/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 30.4507 - val_loss: 35.2857\n",
            "Epoch 176/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 21.9810 - val_loss: 36.5053\n",
            "Epoch 177/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 19.2310 - val_loss: 35.4636\n",
            "Epoch 178/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 22.6164 - val_loss: 45.1076\n",
            "Epoch 179/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 25.7250 - val_loss: 51.1206\n",
            "Epoch 180/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 21.5375 - val_loss: 188.6506\n",
            "Epoch 181/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 30.4367 - val_loss: 46.1185\n",
            "Epoch 182/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 24.7716 - val_loss: 36.7320\n",
            "Epoch 183/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 20.1248 - val_loss: 34.4638\n",
            "Epoch 184/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 19.3012 - val_loss: 75.7390\n",
            "Epoch 185/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 26.2799 - val_loss: 44.5635\n",
            "Epoch 186/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 21.5458 - val_loss: 37.6748\n",
            "Epoch 187/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 20.9726 - val_loss: 46.7474\n",
            "Epoch 188/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 20.8979 - val_loss: 33.7724\n",
            "Epoch 189/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 23.3365 - val_loss: 44.6442\n",
            "Epoch 190/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 21.9881 - val_loss: 34.0757\n",
            "Epoch 191/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 19.7054 - val_loss: 124.8056\n",
            "Epoch 192/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 27.0376 - val_loss: 39.3076\n",
            "Epoch 193/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 22.0080 - val_loss: 33.2260\n",
            "Epoch 194/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 19.2784 - val_loss: 48.0971\n",
            "Epoch 195/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 28.9449 - val_loss: 74.4977\n",
            "Epoch 196/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 23.6224 - val_loss: 48.1795\n",
            "Epoch 197/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 21.1811 - val_loss: 119.1564\n",
            "Epoch 198/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 24.4912 - val_loss: 36.7627\n",
            "Epoch 199/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 23.7653 - val_loss: 34.5274\n",
            "Epoch 200/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 22.1892 - val_loss: 65.8172\n",
            "Epoch 201/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 21.7776 - val_loss: 35.5692\n",
            "Epoch 202/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 20.0275 - val_loss: 33.6198\n",
            "Epoch 203/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 16.8165 - val_loss: 33.0346\n",
            "Epoch 204/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 17.6597 - val_loss: 31.7589\n",
            "Epoch 205/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 17.0650 - val_loss: 33.6404\n",
            "Epoch 206/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 16.0455 - val_loss: 32.8775\n",
            "Epoch 207/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 16.0244 - val_loss: 32.3160\n",
            "Epoch 208/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 22.1291 - val_loss: 31.5941\n",
            "Epoch 209/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 17.0621 - val_loss: 43.9095\n",
            "Epoch 210/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 17.0905 - val_loss: 31.5718\n",
            "Epoch 211/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 21.6038 - val_loss: 39.4174\n",
            "Epoch 212/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 21.1403 - val_loss: 56.2833\n",
            "Epoch 213/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 22.4131 - val_loss: 31.8323\n",
            "Epoch 214/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 17.3954 - val_loss: 32.9882\n",
            "Epoch 215/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 14.3736 - val_loss: 32.7758\n",
            "Epoch 216/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 24.1464 - val_loss: 60.3682\n",
            "Epoch 217/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 21.4743 - val_loss: 33.2022\n",
            "Epoch 218/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 15.9713 - val_loss: 52.8295\n",
            "Epoch 219/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 29.1802 - val_loss: 32.2357\n",
            "Epoch 220/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 14.5969 - val_loss: 58.0172\n",
            "Epoch 221/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 23.2354 - val_loss: 31.2292\n",
            "Epoch 222/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 17.6486 - val_loss: 37.3298\n",
            "Epoch 223/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 15.8558 - val_loss: 30.5298\n",
            "Epoch 224/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 16.4686 - val_loss: 39.9255\n",
            "Epoch 225/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 15.1157 - val_loss: 38.0666\n",
            "Epoch 226/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 35.1304 - val_loss: 33.7890\n",
            "Epoch 227/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 18.6885 - val_loss: 32.8186\n",
            "Epoch 228/300\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 16.0778 - val_loss: 61.7222\n",
            "Epoch 229/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 13.9410 - val_loss: 30.9516\n",
            "Epoch 230/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 17.7690 - val_loss: 39.7544\n",
            "Epoch 231/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 19.0169 - val_loss: 37.1078\n",
            "Epoch 232/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 13.7683 - val_loss: 37.9034\n",
            "Epoch 233/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 14.1617 - val_loss: 30.7170\n",
            "Epoch 234/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 17.0581 - val_loss: 31.0154\n",
            "Epoch 235/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 21.0762 - val_loss: 31.5460\n",
            "Epoch 236/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 17.1097 - val_loss: 30.5520\n",
            "Epoch 237/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 13.4140 - val_loss: 34.1237\n",
            "Epoch 238/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 27.3094 - val_loss: 36.1469\n",
            "Epoch 239/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 14.8794 - val_loss: 60.1810\n",
            "Epoch 240/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 17.3870 - val_loss: 33.8811\n",
            "Epoch 241/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 19.0626 - val_loss: 32.2973\n",
            "Epoch 242/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 12.4008 - val_loss: 49.1318\n",
            "Epoch 243/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 22.2691 - val_loss: 34.3056\n",
            "Epoch 244/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 25.2729 - val_loss: 29.2213\n",
            "Epoch 245/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 13.8939 - val_loss: 30.8445\n",
            "Epoch 246/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 18.5569 - val_loss: 30.2868\n",
            "Epoch 247/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 15.4990 - val_loss: 39.5720\n",
            "Epoch 248/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 14.7431 - val_loss: 35.8666\n",
            "Epoch 249/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 21.7023 - val_loss: 31.1908\n",
            "Epoch 250/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 14.0661 - val_loss: 28.5855\n",
            "Epoch 251/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 17.1645 - val_loss: 30.5269\n",
            "Epoch 252/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 13.4673 - val_loss: 37.2805\n",
            "Epoch 253/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 13.6348 - val_loss: 47.3809\n",
            "Epoch 254/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 15.7504 - val_loss: 231.8154\n",
            "Epoch 255/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 35.3534 - val_loss: 53.2456\n",
            "Epoch 256/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 13.8278 - val_loss: 30.0443\n",
            "Epoch 257/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 16.8396 - val_loss: 32.2701\n",
            "Epoch 258/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 13.5350 - val_loss: 32.7878\n",
            "Epoch 259/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 13.7577 - val_loss: 31.2117\n",
            "Epoch 260/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 21.9617 - val_loss: 28.8892\n",
            "Epoch 261/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 11.2132 - val_loss: 77.5397\n",
            "Epoch 262/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 14.7607 - val_loss: 29.5541\n",
            "Epoch 263/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 17.5758 - val_loss: 35.3473\n",
            "Epoch 264/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 13.8492 - val_loss: 28.8252\n",
            "Epoch 265/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 11.9052 - val_loss: 28.5107\n",
            "Epoch 266/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 11.6764 - val_loss: 37.8651\n",
            "Epoch 267/300\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 16.0533 - val_loss: 31.8186\n",
            "Epoch 268/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 11.7729 - val_loss: 42.8530\n",
            "Epoch 269/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 16.7425 - val_loss: 67.0416\n",
            "Epoch 270/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 16.5017 - val_loss: 29.6312\n",
            "Epoch 271/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 12.6058 - val_loss: 29.0499\n",
            "Epoch 272/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 16.7866 - val_loss: 33.2270\n",
            "Epoch 273/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 10.7641 - val_loss: 29.4892\n",
            "Epoch 274/300\n",
            "17/17 [==============================] - 0s 6ms/step - loss: 10.4351 - val_loss: 32.0627\n",
            "Epoch 275/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 15.9752 - val_loss: 32.1777\n",
            "Epoch 276/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 12.6904 - val_loss: 30.4346\n",
            "Epoch 277/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 13.9087 - val_loss: 28.6219\n",
            "Epoch 278/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 12.7111 - val_loss: 29.2993\n",
            "Epoch 279/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 11.3228 - val_loss: 59.0819\n",
            "Epoch 280/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 28.0897 - val_loss: 30.0399\n",
            "Epoch 281/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 10.3916 - val_loss: 28.2517\n",
            "Epoch 282/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 9.5046 - val_loss: 28.8029\n",
            "Epoch 283/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 13.7859 - val_loss: 28.7017\n",
            "Epoch 284/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 12.1348 - val_loss: 35.3186\n",
            "Epoch 285/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 17.4242 - val_loss: 28.0087\n",
            "Epoch 286/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 15.2952 - val_loss: 34.8137\n",
            "Epoch 287/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 20.1951 - val_loss: 37.3012\n",
            "Epoch 288/300\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 11.8109 - val_loss: 32.2217\n",
            "Epoch 289/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 9.6722 - val_loss: 108.5215\n",
            "Epoch 290/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 24.0701 - val_loss: 28.3695\n",
            "Epoch 291/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 14.6239 - val_loss: 41.2672\n",
            "Epoch 292/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 11.6055 - val_loss: 28.3667\n",
            "Epoch 293/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 13.3068 - val_loss: 49.3784\n",
            "Epoch 294/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 10.2485 - val_loss: 28.4015\n",
            "Epoch 295/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 10.2341 - val_loss: 43.7358\n",
            "Epoch 296/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 18.3650 - val_loss: 74.9352\n",
            "Epoch 297/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 14.3378 - val_loss: 29.2869\n",
            "Epoch 298/300\n",
            "17/17 [==============================] - 0s 7ms/step - loss: 9.7113 - val_loss: 37.3242\n",
            "Epoch 299/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 11.1112 - val_loss: 30.0844\n",
            "Epoch 300/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 10.1872 - val_loss: 39.3802\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 43.0017\n",
            "Epoch 1/300\n",
            "17/17 [==============================] - 1s 21ms/step - loss: 189.2938 - val_loss: 148.6462\n",
            "Epoch 2/300\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 149.5164 - val_loss: 148.1712\n",
            "Epoch 3/300\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 148.9258 - val_loss: 147.9079\n",
            "Epoch 4/300\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 148.9541 - val_loss: 147.8721\n",
            "Epoch 5/300\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 149.1540 - val_loss: 149.1625\n",
            "Epoch 6/300\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 148.7305 - val_loss: 148.2382\n",
            "Epoch 7/300\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 149.3546 - val_loss: 148.1009\n",
            "Epoch 8/300\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 148.9941 - val_loss: 148.8845\n",
            "Epoch 9/300\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 148.6976 - val_loss: 148.3886\n",
            "Epoch 10/300\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 148.6945 - val_loss: 149.8950\n",
            "Epoch 11/300\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 149.5775 - val_loss: 148.3721\n",
            "Epoch 12/300\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 149.6646 - val_loss: 148.1514\n",
            "Epoch 13/300\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 149.1236 - val_loss: 148.0643\n",
            "Epoch 14/300\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 149.0089 - val_loss: 147.8688\n",
            "Epoch 15/300\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 149.3963 - val_loss: 148.1119\n",
            "Epoch 16/300\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 148.8171 - val_loss: 147.8817\n",
            "Epoch 17/300\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 149.0480 - val_loss: 148.3245\n",
            "Epoch 18/300\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 148.6132 - val_loss: 149.9976\n",
            "Epoch 19/300\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 148.9034 - val_loss: 147.9674\n",
            "Epoch 20/300\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 149.1605 - val_loss: 154.0152\n",
            "Epoch 21/300\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 149.7298 - val_loss: 148.2471\n",
            "Epoch 22/300\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 149.5211 - val_loss: 148.2433\n",
            "Epoch 23/300\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 148.8905 - val_loss: 150.6283\n",
            "Epoch 24/300\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 148.7914 - val_loss: 148.0157\n",
            "Epoch 25/300\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 149.1137 - val_loss: 147.9229\n",
            "Epoch 26/300\n",
            "17/17 [==============================] - 0s 15ms/step - loss: 148.6691 - val_loss: 149.7993\n",
            "Epoch 27/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 149.4671 - val_loss: 152.6727\n",
            "Epoch 28/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 149.3477 - val_loss: 147.8973\n",
            "Epoch 29/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 149.7726 - val_loss: 148.2719\n",
            "Epoch 30/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 148.4377 - val_loss: 156.7927\n",
            "Epoch 31/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 150.2517 - val_loss: 151.3141\n",
            "Epoch 32/300\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 149.5444 - val_loss: 151.0978\n",
            "Epoch 33/300\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 148.9517 - val_loss: 148.2539\n",
            "Epoch 34/300\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 149.3083 - val_loss: 152.5581\n",
            "Epoch 35/300\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 149.0751 - val_loss: 147.9344\n",
            "Epoch 36/300\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 149.2424 - val_loss: 148.4638\n",
            "Epoch 37/300\n",
            "17/17 [==============================] - 0s 16ms/step - loss: 150.0813 - val_loss: 148.8543\n",
            "Epoch 38/300\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 149.2510 - val_loss: 148.1336\n",
            "Epoch 39/300\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 148.9586 - val_loss: 148.6217\n",
            "Epoch 40/300\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 150.1395 - val_loss: 154.5142\n",
            "Epoch 41/300\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 149.2967 - val_loss: 147.9343\n",
            "Epoch 42/300\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 148.7992 - val_loss: 148.0532\n",
            "Epoch 43/300\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 149.0771 - val_loss: 148.6294\n",
            "Epoch 44/300\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 149.2695 - val_loss: 148.0546\n",
            "Epoch 45/300\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 150.2764 - val_loss: 148.2224\n",
            "Epoch 46/300\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 148.6787 - val_loss: 148.3634\n",
            "Epoch 47/300\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 148.8017 - val_loss: 147.8608\n",
            "Epoch 48/300\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 148.9801 - val_loss: 148.6807\n",
            "Epoch 49/300\n",
            "17/17 [==============================] - 0s 15ms/step - loss: 148.9613 - val_loss: 148.2043\n",
            "Epoch 50/300\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 149.7672 - val_loss: 147.9097\n",
            "Epoch 51/300\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 148.5752 - val_loss: 154.5294\n",
            "Epoch 52/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 149.3245 - val_loss: 149.2804\n",
            "Epoch 53/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 149.0546 - val_loss: 147.8878\n",
            "Epoch 54/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 148.9955 - val_loss: 148.5265\n",
            "Epoch 55/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 148.9620 - val_loss: 148.0319\n",
            "Epoch 56/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 148.8877 - val_loss: 148.2256\n",
            "Epoch 57/300\n",
            "17/17 [==============================] - 0s 15ms/step - loss: 149.3294 - val_loss: 147.9936\n",
            "Epoch 58/300\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 149.0677 - val_loss: 148.4755\n",
            "Epoch 59/300\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 149.1844 - val_loss: 151.7598\n",
            "Epoch 60/300\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 149.0861 - val_loss: 152.2873\n",
            "Epoch 61/300\n",
            "17/17 [==============================] - 0s 16ms/step - loss: 149.1663 - val_loss: 152.9187\n",
            "Epoch 62/300\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 149.3079 - val_loss: 148.5184\n",
            "Epoch 63/300\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 148.7800 - val_loss: 148.9567\n",
            "Epoch 64/300\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 148.5921 - val_loss: 148.1606\n",
            "Epoch 65/300\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 148.9982 - val_loss: 155.4012\n",
            "Epoch 66/300\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 149.5588 - val_loss: 150.2689\n",
            "Epoch 67/300\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 148.8604 - val_loss: 148.1663\n",
            "Epoch 68/300\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 149.2948 - val_loss: 148.3318\n",
            "Epoch 69/300\n",
            "17/17 [==============================] - 0s 15ms/step - loss: 148.5036 - val_loss: 147.9770\n",
            "Epoch 70/300\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 149.1144 - val_loss: 147.9389\n",
            "Epoch 71/300\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 148.8556 - val_loss: 155.7918\n",
            "Epoch 72/300\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 149.4455 - val_loss: 147.9214\n",
            "Epoch 73/300\n",
            "17/17 [==============================] - 0s 15ms/step - loss: 148.9732 - val_loss: 147.8633\n",
            "Epoch 74/300\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 148.7978 - val_loss: 160.8286\n",
            "Epoch 75/300\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 148.9979 - val_loss: 149.9307\n",
            "Epoch 76/300\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 149.1831 - val_loss: 148.5301\n",
            "Epoch 77/300\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 148.7352 - val_loss: 148.8476\n",
            "Epoch 78/300\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 148.5480 - val_loss: 149.9780\n",
            "Epoch 79/300\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 148.6522 - val_loss: 149.0781\n",
            "Epoch 80/300\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 149.6722 - val_loss: 147.9123\n",
            "Epoch 81/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 148.6343 - val_loss: 148.7206\n",
            "Epoch 82/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 149.1494 - val_loss: 147.8909\n",
            "Epoch 83/300\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 148.8767 - val_loss: 147.8912\n",
            "Epoch 84/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 149.1091 - val_loss: 148.3036\n",
            "Epoch 85/300\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 148.6667 - val_loss: 152.2903\n",
            "Epoch 86/300\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 150.4871 - val_loss: 148.0604\n",
            "Epoch 87/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 148.8306 - val_loss: 147.8909\n",
            "Epoch 88/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 148.7963 - val_loss: 147.9473\n",
            "Epoch 89/300\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 148.9267 - val_loss: 148.0068\n",
            "Epoch 90/300\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 148.7127 - val_loss: 148.2587\n",
            "Epoch 91/300\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 149.1069 - val_loss: 148.9734\n",
            "Epoch 92/300\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 149.0853 - val_loss: 147.8919\n",
            "Epoch 93/300\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 148.7053 - val_loss: 148.2808\n",
            "Epoch 94/300\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 148.9545 - val_loss: 147.9737\n",
            "Epoch 95/300\n",
            "17/17 [==============================] - 0s 16ms/step - loss: 148.4299 - val_loss: 148.4019\n",
            "Epoch 96/300\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 148.8642 - val_loss: 147.8895\n",
            "Epoch 97/300\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 148.5045 - val_loss: 154.6981\n",
            "Epoch 98/300\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 149.1198 - val_loss: 148.6708\n",
            "Epoch 99/300\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 148.6412 - val_loss: 148.5600\n",
            "Epoch 100/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 149.5189 - val_loss: 156.3331\n",
            "Epoch 101/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 149.9041 - val_loss: 148.1917\n",
            "Epoch 102/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 148.9146 - val_loss: 158.6507\n",
            "Epoch 103/300\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 150.3119 - val_loss: 148.6858\n",
            "Epoch 104/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 148.6902 - val_loss: 148.4292\n",
            "Epoch 105/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 149.0861 - val_loss: 150.0248\n",
            "Epoch 106/300\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 148.2054 - val_loss: 151.3053\n",
            "Epoch 107/300\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 150.0198 - val_loss: 150.1558\n",
            "Epoch 108/300\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 148.9928 - val_loss: 150.3479\n",
            "Epoch 109/300\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 149.1347 - val_loss: 147.9904\n",
            "Epoch 110/300\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 149.4065 - val_loss: 148.5894\n",
            "Epoch 111/300\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 148.8775 - val_loss: 148.2222\n",
            "Epoch 112/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 148.9604 - val_loss: 150.4613\n",
            "Epoch 113/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 149.9421 - val_loss: 149.2861\n",
            "Epoch 114/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 149.5519 - val_loss: 148.5995\n",
            "Epoch 115/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 149.4661 - val_loss: 147.8712\n",
            "Epoch 116/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 148.7206 - val_loss: 165.0393\n",
            "Epoch 117/300\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 150.0698 - val_loss: 148.6812\n",
            "Epoch 118/300\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 148.9749 - val_loss: 151.4523\n",
            "Epoch 119/300\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 148.4719 - val_loss: 148.1165\n",
            "Epoch 120/300\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 149.8174 - val_loss: 148.2124\n",
            "Epoch 121/300\n",
            "17/17 [==============================] - 0s 15ms/step - loss: 148.8433 - val_loss: 150.7478\n",
            "Epoch 122/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 149.6390 - val_loss: 147.8923\n",
            "Epoch 123/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 149.2486 - val_loss: 153.1546\n",
            "Epoch 124/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 149.5566 - val_loss: 147.9548\n",
            "Epoch 125/300\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 148.8787 - val_loss: 149.4246\n",
            "Epoch 126/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 150.0403 - val_loss: 148.9399\n",
            "Epoch 127/300\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 149.0886 - val_loss: 149.4960\n",
            "Epoch 128/300\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 148.9436 - val_loss: 155.8948\n",
            "Epoch 129/300\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 149.5071 - val_loss: 147.8671\n",
            "Epoch 130/300\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 148.9301 - val_loss: 148.2397\n",
            "Epoch 131/300\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 149.2023 - val_loss: 149.5561\n",
            "Epoch 132/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 149.2819 - val_loss: 148.4075\n",
            "Epoch 133/300\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 148.9086 - val_loss: 147.8619\n",
            "Epoch 134/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 149.3246 - val_loss: 148.3275\n",
            "Epoch 135/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 148.7062 - val_loss: 149.6332\n",
            "Epoch 136/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 149.9549 - val_loss: 149.5626\n",
            "Epoch 137/300\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 149.2260 - val_loss: 147.9664\n",
            "Epoch 138/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 149.1868 - val_loss: 147.8653\n",
            "Epoch 139/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 148.9042 - val_loss: 149.7120\n",
            "Epoch 140/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 149.2583 - val_loss: 149.5308\n",
            "Epoch 141/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 149.2021 - val_loss: 149.2240\n",
            "Epoch 142/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 149.0709 - val_loss: 148.3811\n",
            "Epoch 143/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 149.6714 - val_loss: 147.9179\n",
            "Epoch 144/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 148.5799 - val_loss: 150.2898\n",
            "Epoch 145/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 148.7444 - val_loss: 149.1336\n",
            "Epoch 146/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 148.7844 - val_loss: 150.8213\n",
            "Epoch 147/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 148.8013 - val_loss: 148.0051\n",
            "Epoch 148/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 149.1443 - val_loss: 149.4112\n",
            "Epoch 149/300\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 149.1120 - val_loss: 147.9962\n",
            "Epoch 150/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 148.6879 - val_loss: 148.4511\n",
            "Epoch 151/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 149.0910 - val_loss: 147.9688\n",
            "Epoch 152/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 148.6947 - val_loss: 147.8703\n",
            "Epoch 153/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 149.4574 - val_loss: 150.8385\n",
            "Epoch 154/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 149.6336 - val_loss: 149.6098\n",
            "Epoch 155/300\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 149.3432 - val_loss: 148.3037\n",
            "Epoch 156/300\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 149.6968 - val_loss: 150.2566\n",
            "Epoch 157/300\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 149.0016 - val_loss: 148.0237\n",
            "Epoch 158/300\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 148.5939 - val_loss: 155.8883\n",
            "Epoch 159/300\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 149.7894 - val_loss: 147.9247\n",
            "Epoch 160/300\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 149.3709 - val_loss: 147.8686\n",
            "Epoch 161/300\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 149.1680 - val_loss: 147.9725\n",
            "Epoch 162/300\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 149.1502 - val_loss: 149.9838\n",
            "Epoch 163/300\n",
            "17/17 [==============================] - 0s 17ms/step - loss: 149.2110 - val_loss: 148.6870\n",
            "Epoch 164/300\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 148.8636 - val_loss: 147.8794\n",
            "Epoch 165/300\n",
            "17/17 [==============================] - 0s 15ms/step - loss: 149.3256 - val_loss: 148.3364\n",
            "Epoch 166/300\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 149.7760 - val_loss: 148.9061\n",
            "Epoch 167/300\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 148.8470 - val_loss: 148.4090\n",
            "Epoch 168/300\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 149.3432 - val_loss: 148.0413\n",
            "Epoch 169/300\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 149.2989 - val_loss: 148.6946\n",
            "Epoch 170/300\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 149.5627 - val_loss: 149.6648\n",
            "Epoch 171/300\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 148.9736 - val_loss: 147.9820\n",
            "Epoch 172/300\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 149.1092 - val_loss: 150.4002\n",
            "Epoch 173/300\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 149.2047 - val_loss: 152.3368\n",
            "Epoch 174/300\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 149.0547 - val_loss: 147.9165\n",
            "Epoch 175/300\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 149.4401 - val_loss: 147.8627\n",
            "Epoch 176/300\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 149.0685 - val_loss: 149.2970\n",
            "Epoch 177/300\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 149.3381 - val_loss: 148.2326\n",
            "Epoch 178/300\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 148.4916 - val_loss: 153.0775\n",
            "Epoch 179/300\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 148.5179 - val_loss: 148.7658\n",
            "Epoch 180/300\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 149.1177 - val_loss: 148.3555\n",
            "Epoch 181/300\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 148.9604 - val_loss: 148.7530\n",
            "Epoch 182/300\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 148.7636 - val_loss: 147.8751\n",
            "Epoch 183/300\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 149.1905 - val_loss: 148.6917\n",
            "Epoch 184/300\n",
            "17/17 [==============================] - 0s 15ms/step - loss: 148.8025 - val_loss: 147.8844\n",
            "Epoch 185/300\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 148.6697 - val_loss: 148.5668\n",
            "Epoch 186/300\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 148.5578 - val_loss: 150.7971\n",
            "Epoch 187/300\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 148.2551 - val_loss: 147.8621\n",
            "Epoch 188/300\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 149.0027 - val_loss: 149.3330\n",
            "Epoch 189/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 148.9628 - val_loss: 157.1593\n",
            "Epoch 190/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 149.3214 - val_loss: 149.5957\n",
            "Epoch 191/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 149.1597 - val_loss: 148.9984\n",
            "Epoch 192/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 149.1820 - val_loss: 148.3148\n",
            "Epoch 193/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 148.8971 - val_loss: 148.1337\n",
            "Epoch 194/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 149.2601 - val_loss: 147.8615\n",
            "Epoch 195/300\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 148.8576 - val_loss: 148.3141\n",
            "Epoch 196/300\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 148.4417 - val_loss: 152.8696\n",
            "Epoch 197/300\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 150.2137 - val_loss: 147.8638\n",
            "Epoch 198/300\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 148.3043 - val_loss: 149.1655\n",
            "Epoch 199/300\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 148.8763 - val_loss: 147.9076\n",
            "Epoch 200/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 148.9035 - val_loss: 149.1815\n",
            "Epoch 201/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 149.2513 - val_loss: 147.8729\n",
            "Epoch 202/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 149.4265 - val_loss: 150.1756\n",
            "Epoch 203/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 148.9772 - val_loss: 147.8829\n",
            "Epoch 204/300\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 149.1117 - val_loss: 148.7363\n",
            "Epoch 205/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 150.4582 - val_loss: 147.8641\n",
            "Epoch 206/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 148.7113 - val_loss: 149.0905\n",
            "Epoch 207/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 148.5951 - val_loss: 148.0654\n",
            "Epoch 208/300\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 148.5672 - val_loss: 148.5186\n",
            "Epoch 209/300\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 148.7676 - val_loss: 148.1110\n",
            "Epoch 210/300\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 148.7889 - val_loss: 150.4687\n",
            "Epoch 211/300\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 149.5089 - val_loss: 148.2280\n",
            "Epoch 212/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 148.7448 - val_loss: 149.2950\n",
            "Epoch 213/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 149.3270 - val_loss: 148.1262\n",
            "Epoch 214/300\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 148.8880 - val_loss: 150.9135\n",
            "Epoch 215/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 149.6512 - val_loss: 149.1815\n",
            "Epoch 216/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 148.5605 - val_loss: 148.3909\n",
            "Epoch 217/300\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 149.0661 - val_loss: 150.8689\n",
            "Epoch 218/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 149.0771 - val_loss: 148.3823\n",
            "Epoch 219/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 148.9244 - val_loss: 150.3312\n",
            "Epoch 220/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 150.3073 - val_loss: 149.9829\n",
            "Epoch 221/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 150.0975 - val_loss: 147.8820\n",
            "Epoch 222/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 148.8644 - val_loss: 148.0998\n",
            "Epoch 223/300\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 148.4483 - val_loss: 150.8025\n",
            "Epoch 224/300\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 149.2004 - val_loss: 147.8921\n",
            "Epoch 225/300\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 149.1528 - val_loss: 147.8742\n",
            "Epoch 226/300\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 148.9988 - val_loss: 148.2114\n",
            "Epoch 227/300\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 149.2599 - val_loss: 149.3848\n",
            "Epoch 228/300\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 149.9087 - val_loss: 148.9948\n",
            "Epoch 229/300\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 148.8616 - val_loss: 148.8765\n",
            "Epoch 230/300\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 149.0105 - val_loss: 150.7032\n",
            "Epoch 231/300\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 149.0946 - val_loss: 153.6776\n",
            "Epoch 232/300\n",
            "17/17 [==============================] - 0s 15ms/step - loss: 149.2598 - val_loss: 147.8665\n",
            "Epoch 233/300\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 148.7838 - val_loss: 150.5738\n",
            "Epoch 234/300\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 150.0953 - val_loss: 148.6550\n",
            "Epoch 235/300\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 149.8319 - val_loss: 148.7804\n",
            "Epoch 236/300\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 148.8128 - val_loss: 153.3568\n",
            "Epoch 237/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 149.8100 - val_loss: 148.1796\n",
            "Epoch 238/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 148.6813 - val_loss: 152.2736\n",
            "Epoch 239/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 149.8009 - val_loss: 148.2451\n",
            "Epoch 240/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 148.6162 - val_loss: 150.2972\n",
            "Epoch 241/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 149.6018 - val_loss: 148.3820\n",
            "Epoch 242/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 148.6917 - val_loss: 149.1855\n",
            "Epoch 243/300\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 148.0890 - val_loss: 151.3742\n",
            "Epoch 244/300\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 149.7386 - val_loss: 149.8466\n",
            "Epoch 245/300\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 149.0465 - val_loss: 147.9106\n",
            "Epoch 246/300\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 149.5435 - val_loss: 148.4818\n",
            "Epoch 247/300\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 149.3587 - val_loss: 150.6787\n",
            "Epoch 248/300\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 149.5313 - val_loss: 151.6412\n",
            "Epoch 249/300\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 149.3809 - val_loss: 148.4298\n",
            "Epoch 250/300\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 148.9242 - val_loss: 147.8694\n",
            "Epoch 251/300\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 149.4120 - val_loss: 161.2485\n",
            "Epoch 252/300\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 150.8988 - val_loss: 148.0246\n",
            "Epoch 253/300\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 148.8441 - val_loss: 147.8659\n",
            "Epoch 254/300\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 149.1163 - val_loss: 147.8608\n",
            "Epoch 255/300\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 149.0242 - val_loss: 149.0350\n",
            "Epoch 256/300\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 149.8732 - val_loss: 148.4293\n",
            "Epoch 257/300\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 149.0921 - val_loss: 147.9003\n",
            "Epoch 258/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 149.7345 - val_loss: 148.7301\n",
            "Epoch 259/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 148.9744 - val_loss: 150.0357\n",
            "Epoch 260/300\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 148.8940 - val_loss: 147.9051\n",
            "Epoch 261/300\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 148.7172 - val_loss: 147.8663\n",
            "Epoch 262/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 148.7269 - val_loss: 148.9530\n",
            "Epoch 263/300\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 149.4374 - val_loss: 147.8934\n",
            "Epoch 264/300\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 148.8276 - val_loss: 147.9449\n",
            "Epoch 265/300\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 149.6200 - val_loss: 148.5763\n",
            "Epoch 266/300\n",
            "17/17 [==============================] - 0s 15ms/step - loss: 149.2671 - val_loss: 147.8649\n",
            "Epoch 267/300\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 149.2444 - val_loss: 147.9482\n",
            "Epoch 268/300\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 149.0407 - val_loss: 148.7248\n",
            "Epoch 269/300\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 148.2670 - val_loss: 150.8269\n",
            "Epoch 270/300\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 149.3301 - val_loss: 148.4782\n",
            "Epoch 271/300\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 149.0812 - val_loss: 148.2774\n",
            "Epoch 272/300\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 148.5809 - val_loss: 149.6741\n",
            "Epoch 273/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 148.8849 - val_loss: 147.8960\n",
            "Epoch 274/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 148.9568 - val_loss: 150.2845\n",
            "Epoch 275/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 149.0886 - val_loss: 148.1541\n",
            "Epoch 276/300\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 148.4318 - val_loss: 147.8657\n",
            "Epoch 277/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 149.3575 - val_loss: 148.9305\n",
            "Epoch 278/300\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 149.1238 - val_loss: 147.9699\n",
            "Epoch 279/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 149.1699 - val_loss: 151.1610\n",
            "Epoch 280/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 148.9217 - val_loss: 148.0863\n",
            "Epoch 281/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 149.1324 - val_loss: 148.1329\n",
            "Epoch 282/300\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 149.1236 - val_loss: 147.8610\n",
            "Epoch 283/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 148.4473 - val_loss: 148.1745\n",
            "Epoch 284/300\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 148.8834 - val_loss: 148.8615\n",
            "Epoch 285/300\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 148.6431 - val_loss: 148.3109\n",
            "Epoch 286/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 149.1797 - val_loss: 147.8609\n",
            "Epoch 287/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 148.7988 - val_loss: 148.4228\n",
            "Epoch 288/300\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 148.5682 - val_loss: 147.8686\n",
            "Epoch 289/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 148.8578 - val_loss: 147.8802\n",
            "Epoch 290/300\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 148.6992 - val_loss: 147.9454\n",
            "Epoch 291/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 148.7413 - val_loss: 148.7497\n",
            "Epoch 292/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 150.2117 - val_loss: 148.9698\n",
            "Epoch 293/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 149.0609 - val_loss: 149.3816\n",
            "Epoch 294/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 148.7798 - val_loss: 150.5527\n",
            "Epoch 295/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 148.9442 - val_loss: 148.5021\n",
            "Epoch 296/300\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 148.9404 - val_loss: 151.1355\n",
            "Epoch 297/300\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 149.1492 - val_loss: 149.8171\n",
            "Epoch 298/300\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 149.6269 - val_loss: 147.9137\n",
            "Epoch 299/300\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 149.2437 - val_loss: 149.4939\n",
            "Epoch 300/300\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 149.6231 - val_loss: 148.7466\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 140.3602\n",
            "Epoch 1/300\n",
            "17/17 [==============================] - 1s 15ms/step - loss: 182.6520 - val_loss: 147.9038\n",
            "Epoch 2/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 143.8728 - val_loss: 148.5061\n",
            "Epoch 3/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 143.9743 - val_loss: 148.0709\n",
            "Epoch 4/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 143.8375 - val_loss: 148.3848\n",
            "Epoch 5/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 144.8542 - val_loss: 149.7578\n",
            "Epoch 6/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 143.9851 - val_loss: 153.3588\n",
            "Epoch 7/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 145.5660 - val_loss: 149.0560\n",
            "Epoch 8/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 145.0861 - val_loss: 149.2257\n",
            "Epoch 9/300\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 145.6477 - val_loss: 147.8922\n",
            "Epoch 10/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 144.8259 - val_loss: 149.1187\n",
            "Epoch 11/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 143.8451 - val_loss: 148.1776\n",
            "Epoch 12/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 143.8691 - val_loss: 147.8637\n",
            "Epoch 13/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 143.7117 - val_loss: 152.7000\n",
            "Epoch 14/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 144.6915 - val_loss: 148.9514\n",
            "Epoch 15/300\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 144.5185 - val_loss: 148.7069\n",
            "Epoch 16/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 145.2456 - val_loss: 147.9432\n",
            "Epoch 17/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 144.3386 - val_loss: 147.8765\n",
            "Epoch 18/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 144.3767 - val_loss: 149.1369\n",
            "Epoch 19/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 144.5348 - val_loss: 150.7860\n",
            "Epoch 20/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 144.7091 - val_loss: 148.7520\n",
            "Epoch 21/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 144.2939 - val_loss: 150.2724\n",
            "Epoch 22/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 144.5883 - val_loss: 147.8806\n",
            "Epoch 23/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 144.1407 - val_loss: 147.9113\n",
            "Epoch 24/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 143.7928 - val_loss: 148.3052\n",
            "Epoch 25/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 144.2060 - val_loss: 148.1311\n",
            "Epoch 26/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 144.3186 - val_loss: 149.7260\n",
            "Epoch 27/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 143.1844 - val_loss: 155.5880\n",
            "Epoch 28/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 145.8592 - val_loss: 148.0468\n",
            "Epoch 29/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 144.3195 - val_loss: 148.5227\n",
            "Epoch 30/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 143.9440 - val_loss: 149.8805\n",
            "Epoch 31/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 144.5110 - val_loss: 148.1192\n",
            "Epoch 32/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 144.1072 - val_loss: 148.6575\n",
            "Epoch 33/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 144.3507 - val_loss: 147.9719\n",
            "Epoch 34/300\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 143.7677 - val_loss: 148.0760\n",
            "Epoch 35/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 144.0653 - val_loss: 148.0396\n",
            "Epoch 36/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 144.7718 - val_loss: 149.1727\n",
            "Epoch 37/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 144.0871 - val_loss: 149.3762\n",
            "Epoch 38/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 144.0972 - val_loss: 147.9206\n",
            "Epoch 39/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 143.8582 - val_loss: 148.1894\n",
            "Epoch 40/300\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 144.1694 - val_loss: 149.1033\n",
            "Epoch 41/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 144.9881 - val_loss: 148.7222\n",
            "Epoch 42/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 144.7948 - val_loss: 151.8136\n",
            "Epoch 43/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 145.1259 - val_loss: 151.2471\n",
            "Epoch 44/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 144.6340 - val_loss: 147.8798\n",
            "Epoch 45/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 144.6093 - val_loss: 150.0766\n",
            "Epoch 46/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 144.4060 - val_loss: 148.3401\n",
            "Epoch 47/300\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 144.2452 - val_loss: 148.3297\n",
            "Epoch 48/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 144.3899 - val_loss: 148.5134\n",
            "Epoch 49/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 145.2381 - val_loss: 147.9147\n",
            "Epoch 50/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 144.1895 - val_loss: 153.5879\n",
            "Epoch 51/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 145.0746 - val_loss: 147.8609\n",
            "Epoch 52/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 144.2439 - val_loss: 149.0337\n",
            "Epoch 53/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 144.7163 - val_loss: 148.3538\n",
            "Epoch 54/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 144.2380 - val_loss: 147.8640\n",
            "Epoch 55/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 144.8772 - val_loss: 147.8885\n",
            "Epoch 56/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 144.4524 - val_loss: 149.2728\n",
            "Epoch 57/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 145.2115 - val_loss: 148.8857\n",
            "Epoch 58/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 144.1463 - val_loss: 150.2171\n",
            "Epoch 59/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 144.6336 - val_loss: 148.0195\n",
            "Epoch 60/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 144.4953 - val_loss: 148.9252\n",
            "Epoch 61/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 144.3068 - val_loss: 149.6836\n",
            "Epoch 62/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 144.0729 - val_loss: 148.1785\n",
            "Epoch 63/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 144.3951 - val_loss: 147.8797\n",
            "Epoch 64/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 143.9805 - val_loss: 147.9984\n",
            "Epoch 65/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 144.3580 - val_loss: 147.8948\n",
            "Epoch 66/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 144.3038 - val_loss: 148.5057\n",
            "Epoch 67/300\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 144.2316 - val_loss: 150.3764\n",
            "Epoch 68/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 144.7569 - val_loss: 152.1419\n",
            "Epoch 69/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 145.9410 - val_loss: 149.9507\n",
            "Epoch 70/300\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 144.1360 - val_loss: 148.0850\n",
            "Epoch 71/300\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 143.9295 - val_loss: 156.0503\n",
            "Epoch 72/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 145.6799 - val_loss: 148.4840\n",
            "Epoch 73/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 145.0393 - val_loss: 147.9032\n",
            "Epoch 74/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 143.8956 - val_loss: 148.2153\n",
            "Epoch 75/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 144.1859 - val_loss: 153.8425\n",
            "Epoch 76/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 145.2402 - val_loss: 149.0900\n",
            "Epoch 77/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 144.6532 - val_loss: 148.2448\n",
            "Epoch 78/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 144.2935 - val_loss: 148.9329\n",
            "Epoch 79/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 144.5090 - val_loss: 147.8833\n",
            "Epoch 80/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 144.3358 - val_loss: 148.2843\n",
            "Epoch 81/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 144.1778 - val_loss: 147.8726\n",
            "Epoch 82/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 144.5236 - val_loss: 148.0320\n",
            "Epoch 83/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 144.4082 - val_loss: 148.2572\n",
            "Epoch 84/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 144.2977 - val_loss: 150.8942\n",
            "Epoch 85/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 145.0247 - val_loss: 149.2908\n",
            "Epoch 86/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 144.2173 - val_loss: 152.0213\n",
            "Epoch 87/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 144.3050 - val_loss: 148.1621\n",
            "Epoch 88/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 144.3294 - val_loss: 148.0220\n",
            "Epoch 89/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 144.0008 - val_loss: 150.8584\n",
            "Epoch 90/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 145.0676 - val_loss: 147.9043\n",
            "Epoch 91/300\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 144.1913 - val_loss: 148.0731\n",
            "Epoch 92/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 144.9265 - val_loss: 149.3622\n",
            "Epoch 93/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 145.1012 - val_loss: 149.0493\n",
            "Epoch 94/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 144.8116 - val_loss: 147.8713\n",
            "Epoch 95/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 144.9669 - val_loss: 149.8677\n",
            "Epoch 96/300\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 144.8356 - val_loss: 148.0013\n",
            "Epoch 97/300\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 144.8452 - val_loss: 161.2709\n",
            "Epoch 98/300\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 146.6602 - val_loss: 154.1012\n",
            "Epoch 99/300\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 144.5069 - val_loss: 148.9172\n",
            "Epoch 100/300\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 144.2193 - val_loss: 147.8623\n",
            "Epoch 101/300\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 144.0621 - val_loss: 147.8645\n",
            "Epoch 102/300\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 144.3925 - val_loss: 147.9780\n",
            "Epoch 103/300\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 144.3499 - val_loss: 148.0351\n",
            "Epoch 104/300\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 144.3633 - val_loss: 147.9434\n",
            "Epoch 105/300\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 144.2526 - val_loss: 149.5097\n",
            "Epoch 106/300\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 144.3629 - val_loss: 147.8686\n",
            "Epoch 107/300\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 144.2149 - val_loss: 148.8979\n",
            "Epoch 108/300\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 144.8597 - val_loss: 151.9206\n",
            "Epoch 109/300\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 145.4271 - val_loss: 150.7647\n",
            "Epoch 110/300\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 144.4002 - val_loss: 149.4642\n",
            "Epoch 111/300\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 144.4094 - val_loss: 149.5291\n",
            "Epoch 112/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 144.9275 - val_loss: 148.6899\n",
            "Epoch 113/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 144.5534 - val_loss: 147.9255\n",
            "Epoch 114/300\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 143.8752 - val_loss: 151.6474\n",
            "Epoch 115/300\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 145.3818 - val_loss: 147.8949\n",
            "Epoch 116/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 144.2938 - val_loss: 150.7050\n",
            "Epoch 117/300\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 144.9615 - val_loss: 149.0006\n",
            "Epoch 118/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 144.3744 - val_loss: 149.2650\n",
            "Epoch 119/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 144.4758 - val_loss: 147.9371\n",
            "Epoch 120/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 144.9512 - val_loss: 147.9128\n",
            "Epoch 121/300\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 144.0582 - val_loss: 151.1472\n",
            "Epoch 122/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 145.8743 - val_loss: 148.9970\n",
            "Epoch 123/300\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 144.5165 - val_loss: 148.0672\n",
            "Epoch 124/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 144.7579 - val_loss: 149.7812\n",
            "Epoch 125/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 145.1584 - val_loss: 147.9376\n",
            "Epoch 126/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 144.2902 - val_loss: 150.6310\n",
            "Epoch 127/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 144.9294 - val_loss: 153.6791\n",
            "Epoch 128/300\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 145.3676 - val_loss: 147.9209\n",
            "Epoch 129/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 144.0638 - val_loss: 148.6038\n",
            "Epoch 130/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 144.3361 - val_loss: 148.5318\n",
            "Epoch 131/300\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 144.5660 - val_loss: 148.0461\n",
            "Epoch 132/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 144.4783 - val_loss: 149.0488\n",
            "Epoch 133/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 144.3732 - val_loss: 148.9685\n",
            "Epoch 134/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 144.6017 - val_loss: 148.8337\n",
            "Epoch 135/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 144.2883 - val_loss: 148.2252\n",
            "Epoch 136/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 143.8635 - val_loss: 148.0860\n",
            "Epoch 137/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 144.6838 - val_loss: 148.3531\n",
            "Epoch 138/300\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 145.0020 - val_loss: 150.8412\n",
            "Epoch 139/300\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 145.1579 - val_loss: 147.8820\n",
            "Epoch 140/300\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 144.4681 - val_loss: 148.1124\n",
            "Epoch 141/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 144.6667 - val_loss: 147.9238\n",
            "Epoch 142/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 144.6864 - val_loss: 149.0559\n",
            "Epoch 143/300\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 144.4263 - val_loss: 148.6388\n",
            "Epoch 144/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 144.7124 - val_loss: 148.5885\n",
            "Epoch 145/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 144.4370 - val_loss: 149.9602\n",
            "Epoch 146/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 145.0440 - val_loss: 149.6571\n",
            "Epoch 147/300\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 144.3739 - val_loss: 147.8748\n",
            "Epoch 148/300\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 144.4896 - val_loss: 147.9336\n",
            "Epoch 149/300\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 144.4491 - val_loss: 147.8796\n",
            "Epoch 150/300\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 144.0352 - val_loss: 150.0011\n",
            "Epoch 151/300\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 144.5547 - val_loss: 152.1176\n",
            "Epoch 152/300\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 144.8968 - val_loss: 147.9460\n",
            "Epoch 153/300\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 144.8912 - val_loss: 147.8961\n",
            "Epoch 154/300\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 144.2550 - val_loss: 153.8765\n",
            "Epoch 155/300\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 145.1355 - val_loss: 153.1746\n",
            "Epoch 156/300\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 144.9649 - val_loss: 154.5481\n",
            "Epoch 157/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 145.1613 - val_loss: 150.2193\n",
            "Epoch 158/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 144.5905 - val_loss: 148.7026\n",
            "Epoch 159/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 144.7100 - val_loss: 152.5691\n",
            "Epoch 160/300\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 144.9015 - val_loss: 148.0094\n",
            "Epoch 161/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 144.4114 - val_loss: 148.3179\n",
            "Epoch 162/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 144.4428 - val_loss: 147.9228\n",
            "Epoch 163/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 143.7644 - val_loss: 148.6915\n",
            "Epoch 164/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 145.2617 - val_loss: 148.7113\n",
            "Epoch 165/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 144.4885 - val_loss: 151.2666\n",
            "Epoch 166/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 144.5556 - val_loss: 148.9535\n",
            "Epoch 167/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 144.2417 - val_loss: 149.2293\n",
            "Epoch 168/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 145.3271 - val_loss: 147.8617\n",
            "Epoch 169/300\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 143.8185 - val_loss: 150.1516\n",
            "Epoch 170/300\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 144.6210 - val_loss: 151.0290\n",
            "Epoch 171/300\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 144.4863 - val_loss: 150.8361\n",
            "Epoch 172/300\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 144.4830 - val_loss: 147.8686\n",
            "Epoch 173/300\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 144.6755 - val_loss: 148.1721\n",
            "Epoch 174/300\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 144.2012 - val_loss: 149.4847\n",
            "Epoch 175/300\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 144.5817 - val_loss: 148.4138\n",
            "Epoch 176/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 144.3618 - val_loss: 147.9896\n",
            "Epoch 177/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 144.3709 - val_loss: 148.4482\n",
            "Epoch 178/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 144.3373 - val_loss: 147.9131\n",
            "Epoch 179/300\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 143.9926 - val_loss: 147.8653\n",
            "Epoch 180/300\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 144.3797 - val_loss: 150.5808\n",
            "Epoch 181/300\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 145.1712 - val_loss: 147.9291\n",
            "Epoch 182/300\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 145.1516 - val_loss: 148.7979\n",
            "Epoch 183/300\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 144.1632 - val_loss: 148.1423\n",
            "Epoch 184/300\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 144.2093 - val_loss: 147.9505\n",
            "Epoch 185/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 144.4877 - val_loss: 147.9368\n",
            "Epoch 186/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 144.4286 - val_loss: 153.8026\n",
            "Epoch 187/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 144.6075 - val_loss: 149.3711\n",
            "Epoch 188/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 143.9472 - val_loss: 158.8373\n",
            "Epoch 189/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 146.0796 - val_loss: 150.1633\n",
            "Epoch 190/300\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 144.6162 - val_loss: 148.4436\n",
            "Epoch 191/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 144.1186 - val_loss: 148.4446\n",
            "Epoch 192/300\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 144.4619 - val_loss: 148.1913\n",
            "Epoch 193/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 144.1515 - val_loss: 148.0031\n",
            "Epoch 194/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 144.6213 - val_loss: 152.6502\n",
            "Epoch 195/300\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 145.6223 - val_loss: 149.0669\n",
            "Epoch 196/300\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 143.9873 - val_loss: 147.8696\n",
            "Epoch 197/300\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 144.3444 - val_loss: 148.9907\n",
            "Epoch 198/300\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 144.4859 - val_loss: 148.2890\n",
            "Epoch 199/300\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 143.9758 - val_loss: 150.2541\n",
            "Epoch 200/300\n",
            "17/17 [==============================] - 0s 15ms/step - loss: 144.4485 - val_loss: 147.8729\n",
            "Epoch 201/300\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 143.8481 - val_loss: 147.9601\n",
            "Epoch 202/300\n",
            "17/17 [==============================] - 0s 15ms/step - loss: 144.0738 - val_loss: 150.3866\n",
            "Epoch 203/300\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 145.4314 - val_loss: 147.8982\n",
            "Epoch 204/300\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 144.0906 - val_loss: 153.6730\n",
            "Epoch 205/300\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 145.1298 - val_loss: 147.9362\n",
            "Epoch 206/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 144.4625 - val_loss: 148.2615\n",
            "Epoch 207/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 144.3348 - val_loss: 148.4111\n",
            "Epoch 208/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 144.1027 - val_loss: 150.1814\n",
            "Epoch 209/300\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 144.2989 - val_loss: 148.3440\n",
            "Epoch 210/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 144.1071 - val_loss: 152.6185\n",
            "Epoch 211/300\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 144.6774 - val_loss: 148.4965\n",
            "Epoch 212/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 144.9003 - val_loss: 151.5755\n",
            "Epoch 213/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 145.3800 - val_loss: 147.8609\n",
            "Epoch 214/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 144.5041 - val_loss: 148.4079\n",
            "Epoch 215/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 144.5041 - val_loss: 147.8620\n",
            "Epoch 216/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 144.2902 - val_loss: 148.5967\n",
            "Epoch 217/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 144.7747 - val_loss: 147.8706\n",
            "Epoch 218/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 144.1407 - val_loss: 147.8618\n",
            "Epoch 219/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 143.5559 - val_loss: 149.1943\n",
            "Epoch 220/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 143.9336 - val_loss: 150.5635\n",
            "Epoch 221/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 144.5988 - val_loss: 148.1927\n",
            "Epoch 222/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 144.3873 - val_loss: 153.6633\n",
            "Epoch 223/300\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 144.2018 - val_loss: 150.5136\n",
            "Epoch 224/300\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 144.8242 - val_loss: 149.1107\n",
            "Epoch 225/300\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 144.4342 - val_loss: 148.0618\n",
            "Epoch 226/300\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 143.9217 - val_loss: 149.3294\n",
            "Epoch 227/300\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 144.1042 - val_loss: 151.5112\n",
            "Epoch 228/300\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 145.0398 - val_loss: 148.1193\n",
            "Epoch 229/300\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 144.0655 - val_loss: 149.1517\n",
            "Epoch 230/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 143.8332 - val_loss: 149.6443\n",
            "Epoch 231/300\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 144.7727 - val_loss: 148.0892\n",
            "Epoch 232/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 144.8357 - val_loss: 150.5162\n",
            "Epoch 233/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 145.1295 - val_loss: 148.2811\n",
            "Epoch 234/300\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 144.2289 - val_loss: 148.2862\n",
            "Epoch 235/300\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 143.6973 - val_loss: 147.9791\n",
            "Epoch 236/300\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 144.2279 - val_loss: 149.0464\n",
            "Epoch 237/300\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 144.1903 - val_loss: 152.3345\n",
            "Epoch 238/300\n",
            "17/17 [==============================] - 0s 15ms/step - loss: 144.2069 - val_loss: 148.9940\n",
            "Epoch 239/300\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 144.5572 - val_loss: 148.8148\n",
            "Epoch 240/300\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 144.3547 - val_loss: 152.8326\n",
            "Epoch 241/300\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 144.4980 - val_loss: 148.5357\n",
            "Epoch 242/300\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 144.6331 - val_loss: 147.8617\n",
            "Epoch 243/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 144.5395 - val_loss: 149.0896\n",
            "Epoch 244/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 144.9083 - val_loss: 150.3468\n",
            "Epoch 245/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 144.7642 - val_loss: 147.8786\n",
            "Epoch 246/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 144.1198 - val_loss: 147.9675\n",
            "Epoch 247/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 144.3760 - val_loss: 147.8902\n",
            "Epoch 248/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 144.0543 - val_loss: 153.6034\n",
            "Epoch 249/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 145.6889 - val_loss: 148.9268\n",
            "Epoch 250/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 144.5613 - val_loss: 147.9371\n",
            "Epoch 251/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 144.5251 - val_loss: 147.8672\n",
            "Epoch 252/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 144.0368 - val_loss: 151.1549\n",
            "Epoch 253/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 145.2868 - val_loss: 152.7696\n",
            "Epoch 254/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 144.7299 - val_loss: 147.8670\n",
            "Epoch 255/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 144.7006 - val_loss: 154.4731\n",
            "Epoch 256/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 143.4502 - val_loss: 148.0325\n",
            "Epoch 257/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 144.4993 - val_loss: 149.1788\n",
            "Epoch 258/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 144.6271 - val_loss: 148.1015\n",
            "Epoch 259/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 144.2195 - val_loss: 148.3062\n",
            "Epoch 260/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 145.5838 - val_loss: 148.1678\n",
            "Epoch 261/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 144.4606 - val_loss: 147.8798\n",
            "Epoch 262/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 144.0656 - val_loss: 149.3506\n",
            "Epoch 263/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 144.3283 - val_loss: 147.9628\n",
            "Epoch 264/300\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 144.4302 - val_loss: 149.6384\n",
            "Epoch 265/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 144.4222 - val_loss: 152.4805\n",
            "Epoch 266/300\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 145.1867 - val_loss: 148.5123\n",
            "Epoch 267/300\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 143.9453 - val_loss: 147.8999\n",
            "Epoch 268/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 144.1743 - val_loss: 148.5800\n",
            "Epoch 269/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 144.7209 - val_loss: 151.7580\n",
            "Epoch 270/300\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 144.6088 - val_loss: 150.9012\n",
            "Epoch 271/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 145.8508 - val_loss: 147.8773\n",
            "Epoch 272/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 144.2366 - val_loss: 148.3713\n",
            "Epoch 273/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 145.2496 - val_loss: 148.0676\n",
            "Epoch 274/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 143.9244 - val_loss: 147.9048\n",
            "Epoch 275/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 144.3664 - val_loss: 155.8570\n",
            "Epoch 276/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 145.2727 - val_loss: 148.0062\n",
            "Epoch 277/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 144.3118 - val_loss: 149.1876\n",
            "Epoch 278/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 144.1463 - val_loss: 147.9238\n",
            "Epoch 279/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 144.0691 - val_loss: 147.8694\n",
            "Epoch 280/300\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 144.3082 - val_loss: 153.0818\n",
            "Epoch 281/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 144.7074 - val_loss: 149.3153\n",
            "Epoch 282/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 144.6761 - val_loss: 148.0767\n",
            "Epoch 283/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 144.2107 - val_loss: 149.8899\n",
            "Epoch 284/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 145.2898 - val_loss: 148.5619\n",
            "Epoch 285/300\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 144.0147 - val_loss: 148.1547\n",
            "Epoch 286/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 144.2778 - val_loss: 147.9018\n",
            "Epoch 287/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 144.3722 - val_loss: 147.8964\n",
            "Epoch 288/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 144.3610 - val_loss: 150.6754\n",
            "Epoch 289/300\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 144.8941 - val_loss: 149.0694\n",
            "Epoch 290/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 144.9922 - val_loss: 149.1667\n",
            "Epoch 291/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 143.8456 - val_loss: 147.9967\n",
            "Epoch 292/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 144.1126 - val_loss: 148.0701\n",
            "Epoch 293/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 144.0991 - val_loss: 151.4413\n",
            "Epoch 294/300\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 144.3073 - val_loss: 148.1585\n",
            "Epoch 295/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 144.0061 - val_loss: 148.0436\n",
            "Epoch 296/300\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 144.3397 - val_loss: 147.9974\n",
            "Epoch 297/300\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 144.7919 - val_loss: 148.2325\n",
            "Epoch 298/300\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 144.4839 - val_loss: 147.8663\n",
            "Epoch 299/300\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 144.3910 - val_loss: 152.6455\n",
            "Epoch 300/300\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 145.1935 - val_loss: 150.2506\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 150.1891\n",
            "Epoch 1/300\n",
            "17/17 [==============================] - 1s 17ms/step - loss: 180.4004 - val_loss: 148.2406\n",
            "Epoch 2/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 144.5670 - val_loss: 148.0079\n",
            "Epoch 3/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 144.7753 - val_loss: 147.8989\n",
            "Epoch 4/300\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 145.0296 - val_loss: 147.9759\n",
            "Epoch 5/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 144.5403 - val_loss: 147.8740\n",
            "Epoch 6/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 145.1298 - val_loss: 148.3246\n",
            "Epoch 7/300\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 145.1169 - val_loss: 148.0278\n",
            "Epoch 8/300\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 144.4470 - val_loss: 148.1499\n",
            "Epoch 9/300\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 144.9513 - val_loss: 151.0193\n",
            "Epoch 10/300\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 145.2786 - val_loss: 150.3820\n",
            "Epoch 11/300\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 145.5235 - val_loss: 148.7310\n",
            "Epoch 12/300\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 144.4579 - val_loss: 147.8678\n",
            "Epoch 13/300\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 145.0692 - val_loss: 148.5207\n",
            "Epoch 14/300\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 145.3009 - val_loss: 148.1722\n",
            "Epoch 15/300\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 144.9720 - val_loss: 148.1746\n",
            "Epoch 16/300\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 145.0539 - val_loss: 148.1724\n",
            "Epoch 17/300\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 145.7690 - val_loss: 149.3917\n",
            "Epoch 18/300\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 145.3182 - val_loss: 152.2781\n",
            "Epoch 19/300\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 145.7238 - val_loss: 147.9169\n",
            "Epoch 20/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 144.6569 - val_loss: 147.9292\n",
            "Epoch 21/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 145.0574 - val_loss: 147.8804\n",
            "Epoch 22/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 144.8275 - val_loss: 147.9624\n",
            "Epoch 23/300\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 144.7253 - val_loss: 149.2498\n",
            "Epoch 24/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 145.0712 - val_loss: 150.1046\n",
            "Epoch 25/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 145.7610 - val_loss: 148.5343\n",
            "Epoch 26/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 145.1798 - val_loss: 148.1590\n",
            "Epoch 27/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 145.1925 - val_loss: 148.0454\n",
            "Epoch 28/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 144.8985 - val_loss: 151.6189\n",
            "Epoch 29/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 145.4099 - val_loss: 147.9077\n",
            "Epoch 30/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 144.3211 - val_loss: 150.5092\n",
            "Epoch 31/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 145.6797 - val_loss: 150.0282\n",
            "Epoch 32/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 145.6907 - val_loss: 149.7591\n",
            "Epoch 33/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 144.7923 - val_loss: 148.1236\n",
            "Epoch 34/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 144.9267 - val_loss: 148.8424\n",
            "Epoch 35/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 144.6882 - val_loss: 149.1407\n",
            "Epoch 36/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 144.7843 - val_loss: 149.2068\n",
            "Epoch 37/300\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 144.4238 - val_loss: 148.2598\n",
            "Epoch 38/300\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 144.8581 - val_loss: 151.3230\n",
            "Epoch 39/300\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 145.6951 - val_loss: 149.6827\n",
            "Epoch 40/300\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 145.2537 - val_loss: 147.9420\n",
            "Epoch 41/300\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 144.9445 - val_loss: 149.0362\n",
            "Epoch 42/300\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 144.7708 - val_loss: 148.2728\n",
            "Epoch 43/300\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 145.0724 - val_loss: 148.1355\n",
            "Epoch 44/300\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 144.5375 - val_loss: 148.4544\n",
            "Epoch 45/300\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 144.8141 - val_loss: 148.0292\n",
            "Epoch 46/300\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 144.3630 - val_loss: 147.8620\n",
            "Epoch 47/300\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 145.5459 - val_loss: 147.8695\n",
            "Epoch 48/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 144.2279 - val_loss: 149.0227\n",
            "Epoch 49/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 145.2871 - val_loss: 147.8612\n",
            "Epoch 50/300\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 144.9398 - val_loss: 148.8326\n",
            "Epoch 51/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 145.0855 - val_loss: 148.5756\n",
            "Epoch 52/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 145.5098 - val_loss: 147.9847\n",
            "Epoch 53/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 145.3488 - val_loss: 147.9075\n",
            "Epoch 54/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 144.9195 - val_loss: 147.9787\n",
            "Epoch 55/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 145.2367 - val_loss: 147.9275\n",
            "Epoch 56/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 144.5425 - val_loss: 148.4227\n",
            "Epoch 57/300\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 145.0823 - val_loss: 147.9213\n",
            "Epoch 58/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 144.6742 - val_loss: 148.3165\n",
            "Epoch 59/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 143.4465 - val_loss: 151.9615\n",
            "Epoch 60/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 145.5441 - val_loss: 148.0006\n",
            "Epoch 61/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 145.2362 - val_loss: 147.8960\n",
            "Epoch 62/300\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 144.9813 - val_loss: 148.1290\n",
            "Epoch 63/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 144.7253 - val_loss: 148.4423\n",
            "Epoch 64/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 145.1489 - val_loss: 147.8608\n",
            "Epoch 65/300\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 144.9525 - val_loss: 147.9784\n",
            "Epoch 66/300\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 145.0515 - val_loss: 149.8345\n",
            "Epoch 67/300\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 145.0230 - val_loss: 148.2639\n",
            "Epoch 68/300\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 144.9717 - val_loss: 148.8453\n",
            "Epoch 69/300\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 144.6953 - val_loss: 147.9188\n",
            "Epoch 70/300\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 145.1945 - val_loss: 147.9430\n",
            "Epoch 71/300\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 145.0079 - val_loss: 148.6932\n",
            "Epoch 72/300\n",
            "17/17 [==============================] - 0s 15ms/step - loss: 144.9544 - val_loss: 147.9094\n",
            "Epoch 73/300\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 145.1305 - val_loss: 148.3505\n",
            "Epoch 74/300\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 145.2731 - val_loss: 148.0505\n",
            "Epoch 75/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 145.4520 - val_loss: 159.5120\n",
            "Epoch 76/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 146.9535 - val_loss: 148.7892\n",
            "Epoch 77/300\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 145.8266 - val_loss: 147.9500\n",
            "Epoch 78/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 144.8334 - val_loss: 147.8897\n",
            "Epoch 79/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 145.3172 - val_loss: 148.1545\n",
            "Epoch 80/300\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 145.2449 - val_loss: 148.1491\n",
            "Epoch 81/300\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 145.6337 - val_loss: 150.2840\n",
            "Epoch 82/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 145.5342 - val_loss: 147.8707\n",
            "Epoch 83/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 144.8100 - val_loss: 148.1369\n",
            "Epoch 84/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 144.6447 - val_loss: 151.5584\n",
            "Epoch 85/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 145.2390 - val_loss: 147.9467\n",
            "Epoch 86/300\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 143.8155 - val_loss: 149.8533\n",
            "Epoch 87/300\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 145.3029 - val_loss: 149.7808\n",
            "Epoch 88/300\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 144.8681 - val_loss: 148.7563\n",
            "Epoch 89/300\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 145.0392 - val_loss: 148.3479\n",
            "Epoch 90/300\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 144.8904 - val_loss: 149.5746\n",
            "Epoch 91/300\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 145.6080 - val_loss: 147.8660\n",
            "Epoch 92/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 144.7212 - val_loss: 148.2530\n",
            "Epoch 93/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 144.1348 - val_loss: 149.2184\n",
            "Epoch 94/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 144.8252 - val_loss: 147.9068\n",
            "Epoch 95/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 144.6306 - val_loss: 148.2797\n",
            "Epoch 96/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 144.9198 - val_loss: 149.4036\n",
            "Epoch 97/300\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 145.3012 - val_loss: 147.8873\n",
            "Epoch 98/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 144.9558 - val_loss: 147.8921\n",
            "Epoch 99/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 144.4554 - val_loss: 148.4375\n",
            "Epoch 100/300\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 145.0163 - val_loss: 148.5820\n",
            "Epoch 101/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 145.3621 - val_loss: 148.6943\n",
            "Epoch 102/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 144.9877 - val_loss: 148.2156\n",
            "Epoch 103/300\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 144.6430 - val_loss: 147.9278\n",
            "Epoch 104/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 144.5644 - val_loss: 147.8750\n",
            "Epoch 105/300\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 144.7527 - val_loss: 148.9849\n",
            "Epoch 106/300\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 144.7250 - val_loss: 149.8253\n",
            "Epoch 107/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 144.5710 - val_loss: 147.9400\n",
            "Epoch 108/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 145.5921 - val_loss: 148.3132\n",
            "Epoch 109/300\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 145.2328 - val_loss: 148.3307\n",
            "Epoch 110/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 145.1520 - val_loss: 149.1927\n",
            "Epoch 111/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 145.4874 - val_loss: 147.8911\n",
            "Epoch 112/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 145.1152 - val_loss: 147.8888\n",
            "Epoch 113/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 144.4588 - val_loss: 154.4453\n",
            "Epoch 114/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 146.1567 - val_loss: 148.3257\n",
            "Epoch 115/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 145.2197 - val_loss: 148.1424\n",
            "Epoch 116/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 144.8666 - val_loss: 147.9486\n",
            "Epoch 117/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 144.9811 - val_loss: 151.1853\n",
            "Epoch 118/300\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 145.3981 - val_loss: 148.5201\n",
            "Epoch 119/300\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 145.0337 - val_loss: 152.1016\n",
            "Epoch 120/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 145.2847 - val_loss: 149.4587\n",
            "Epoch 121/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 144.7974 - val_loss: 150.9776\n",
            "Epoch 122/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 145.9001 - val_loss: 151.2531\n",
            "Epoch 123/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 145.0636 - val_loss: 148.3416\n",
            "Epoch 124/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 145.6244 - val_loss: 148.2344\n",
            "Epoch 125/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 145.4430 - val_loss: 151.0533\n",
            "Epoch 126/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 145.8869 - val_loss: 149.6363\n",
            "Epoch 127/300\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 144.8821 - val_loss: 148.2706\n",
            "Epoch 128/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 146.1780 - val_loss: 148.3438\n",
            "Epoch 129/300\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 144.5335 - val_loss: 148.5079\n",
            "Epoch 130/300\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 144.7167 - val_loss: 147.8732\n",
            "Epoch 131/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 145.0321 - val_loss: 149.6075\n",
            "Epoch 132/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 145.3452 - val_loss: 147.8757\n",
            "Epoch 133/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 145.2098 - val_loss: 147.9867\n",
            "Epoch 134/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 145.2284 - val_loss: 147.9550\n",
            "Epoch 135/300\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 144.4935 - val_loss: 147.9903\n",
            "Epoch 136/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 144.9786 - val_loss: 148.9286\n",
            "Epoch 137/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 144.6710 - val_loss: 149.4729\n",
            "Epoch 138/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 144.6497 - val_loss: 147.8689\n",
            "Epoch 139/300\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 144.9003 - val_loss: 147.8951\n",
            "Epoch 140/300\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 144.7597 - val_loss: 148.5234\n",
            "Epoch 141/300\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 145.6922 - val_loss: 149.9574\n",
            "Epoch 142/300\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 144.8367 - val_loss: 149.0353\n",
            "Epoch 143/300\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 145.4331 - val_loss: 147.9794\n",
            "Epoch 144/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 144.6391 - val_loss: 148.0833\n",
            "Epoch 145/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 144.6620 - val_loss: 149.1547\n",
            "Epoch 146/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 145.0105 - val_loss: 148.6606\n",
            "Epoch 147/300\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 144.6661 - val_loss: 150.7866\n",
            "Epoch 148/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 145.0508 - val_loss: 154.4620\n",
            "Epoch 149/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 146.3623 - val_loss: 148.3177\n",
            "Epoch 150/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 144.8430 - val_loss: 147.9476\n",
            "Epoch 151/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 144.3369 - val_loss: 148.0498\n",
            "Epoch 152/300\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 145.3822 - val_loss: 149.9987\n",
            "Epoch 153/300\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 145.2178 - val_loss: 148.1771\n",
            "Epoch 154/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 144.6886 - val_loss: 148.1017\n",
            "Epoch 155/300\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 145.0428 - val_loss: 148.5069\n",
            "Epoch 156/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 144.7147 - val_loss: 149.1772\n",
            "Epoch 157/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 145.0302 - val_loss: 147.9454\n",
            "Epoch 158/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 145.1788 - val_loss: 147.8611\n",
            "Epoch 159/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 144.8552 - val_loss: 148.5946\n",
            "Epoch 160/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 144.3014 - val_loss: 152.3088\n",
            "Epoch 161/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 145.7352 - val_loss: 148.5466\n",
            "Epoch 162/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 145.1359 - val_loss: 149.9410\n",
            "Epoch 163/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 145.0998 - val_loss: 150.4266\n",
            "Epoch 164/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 145.1142 - val_loss: 148.1536\n",
            "Epoch 165/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 144.8317 - val_loss: 147.9991\n",
            "Epoch 166/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 144.6872 - val_loss: 147.8774\n",
            "Epoch 167/300\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 144.7242 - val_loss: 150.0659\n",
            "Epoch 168/300\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 145.1516 - val_loss: 148.2902\n",
            "Epoch 169/300\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 144.3944 - val_loss: 147.9293\n",
            "Epoch 170/300\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 144.6720 - val_loss: 148.4747\n",
            "Epoch 171/300\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 144.7683 - val_loss: 148.0769\n",
            "Epoch 172/300\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 145.0553 - val_loss: 153.9635\n",
            "Epoch 173/300\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 146.1982 - val_loss: 148.1542\n",
            "Epoch 174/300\n",
            "17/17 [==============================] - 0s 15ms/step - loss: 144.7526 - val_loss: 147.9001\n",
            "Epoch 175/300\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 144.3952 - val_loss: 147.9173\n",
            "Epoch 176/300\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 144.5953 - val_loss: 148.5291\n",
            "Epoch 177/300\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 144.9949 - val_loss: 148.0335\n",
            "Epoch 178/300\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 144.5033 - val_loss: 147.9299\n",
            "Epoch 179/300\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 144.9394 - val_loss: 148.9988\n",
            "Epoch 180/300\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 144.9842 - val_loss: 148.5488\n",
            "Epoch 181/300\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 145.0643 - val_loss: 148.8400\n",
            "Epoch 182/300\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 145.0296 - val_loss: 148.9725\n",
            "Epoch 183/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 145.0246 - val_loss: 149.9966\n",
            "Epoch 184/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 144.8641 - val_loss: 147.9201\n",
            "Epoch 185/300\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 144.5070 - val_loss: 149.1322\n",
            "Epoch 186/300\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 144.8656 - val_loss: 147.9008\n",
            "Epoch 187/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 144.8731 - val_loss: 149.1079\n",
            "Epoch 188/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 145.0668 - val_loss: 147.8784\n",
            "Epoch 189/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 144.8710 - val_loss: 147.9171\n",
            "Epoch 190/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 145.5217 - val_loss: 148.4217\n",
            "Epoch 191/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 144.7863 - val_loss: 148.0026\n",
            "Epoch 192/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 145.5515 - val_loss: 147.8620\n",
            "Epoch 193/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 144.7992 - val_loss: 149.6796\n",
            "Epoch 194/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 145.2917 - val_loss: 147.8946\n",
            "Epoch 195/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 144.7953 - val_loss: 149.8088\n",
            "Epoch 196/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 145.0311 - val_loss: 148.0381\n",
            "Epoch 197/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 145.2840 - val_loss: 147.8665\n",
            "Epoch 198/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 144.6530 - val_loss: 148.0845\n",
            "Epoch 199/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 144.7910 - val_loss: 147.8659\n",
            "Epoch 200/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 144.6199 - val_loss: 150.0157\n",
            "Epoch 201/300\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 145.0488 - val_loss: 147.9926\n",
            "Epoch 202/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 145.0058 - val_loss: 149.5459\n",
            "Epoch 203/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 145.8462 - val_loss: 149.4697\n",
            "Epoch 204/300\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 145.5373 - val_loss: 149.1122\n",
            "Epoch 205/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 144.8749 - val_loss: 152.0993\n",
            "Epoch 206/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 145.2771 - val_loss: 148.2225\n",
            "Epoch 207/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 145.2615 - val_loss: 148.7202\n",
            "Epoch 208/300\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 145.7338 - val_loss: 148.1476\n",
            "Epoch 209/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 144.7122 - val_loss: 148.0043\n",
            "Epoch 210/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 145.0067 - val_loss: 151.4096\n",
            "Epoch 211/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 144.4198 - val_loss: 148.4038\n",
            "Epoch 212/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 144.7398 - val_loss: 147.9408\n",
            "Epoch 213/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 144.4080 - val_loss: 147.9203\n",
            "Epoch 214/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 144.5814 - val_loss: 151.2784\n",
            "Epoch 215/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 145.9816 - val_loss: 148.4462\n",
            "Epoch 216/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 145.2903 - val_loss: 148.3190\n",
            "Epoch 217/300\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 144.8581 - val_loss: 148.3121\n",
            "Epoch 218/300\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 144.9140 - val_loss: 147.8652\n",
            "Epoch 219/300\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 145.0982 - val_loss: 149.1207\n",
            "Epoch 220/300\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 144.7676 - val_loss: 148.1022\n",
            "Epoch 221/300\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 144.9814 - val_loss: 149.5235\n",
            "Epoch 222/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 145.0152 - val_loss: 149.3212\n",
            "Epoch 223/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 144.3597 - val_loss: 148.0787\n",
            "Epoch 224/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 144.8555 - val_loss: 149.5268\n",
            "Epoch 225/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 145.0600 - val_loss: 148.7856\n",
            "Epoch 226/300\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 144.9476 - val_loss: 148.4083\n",
            "Epoch 227/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 145.5009 - val_loss: 152.5391\n",
            "Epoch 228/300\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 145.8812 - val_loss: 147.9941\n",
            "Epoch 229/300\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 144.6673 - val_loss: 147.8681\n",
            "Epoch 230/300\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 144.6588 - val_loss: 148.8094\n",
            "Epoch 231/300\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 145.3888 - val_loss: 147.8611\n",
            "Epoch 232/300\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 144.6427 - val_loss: 147.8693\n",
            "Epoch 233/300\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 144.5796 - val_loss: 147.9730\n",
            "Epoch 234/300\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 144.7092 - val_loss: 148.0235\n",
            "Epoch 235/300\n",
            "17/17 [==============================] - 0s 15ms/step - loss: 144.5015 - val_loss: 147.8608\n",
            "Epoch 236/300\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 145.0009 - val_loss: 147.9006\n",
            "Epoch 237/300\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 144.7223 - val_loss: 149.5543\n",
            "Epoch 238/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 144.8935 - val_loss: 148.1278\n",
            "Epoch 239/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 144.6406 - val_loss: 159.7146\n",
            "Epoch 240/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 144.2305 - val_loss: 148.2507\n",
            "Epoch 241/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 145.0487 - val_loss: 149.1004\n",
            "Epoch 242/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 144.7251 - val_loss: 151.7077\n",
            "Epoch 243/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 145.6441 - val_loss: 151.0988\n",
            "Epoch 244/300\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 145.3426 - val_loss: 147.9027\n",
            "Epoch 245/300\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 144.9748 - val_loss: 147.9888\n",
            "Epoch 246/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 145.4751 - val_loss: 148.0189\n",
            "Epoch 247/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 144.4672 - val_loss: 149.6879\n",
            "Epoch 248/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 144.8753 - val_loss: 147.8668\n",
            "Epoch 249/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 145.8662 - val_loss: 150.6720\n",
            "Epoch 250/300\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 145.0283 - val_loss: 149.6556\n",
            "Epoch 251/300\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 144.7747 - val_loss: 149.1506\n",
            "Epoch 252/300\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 145.8271 - val_loss: 147.9509\n",
            "Epoch 253/300\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 144.4392 - val_loss: 148.1359\n",
            "Epoch 254/300\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 144.8308 - val_loss: 147.9142\n",
            "Epoch 255/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 144.6240 - val_loss: 151.3270\n",
            "Epoch 256/300\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 145.3450 - val_loss: 148.1495\n",
            "Epoch 257/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 144.4535 - val_loss: 148.5558\n",
            "Epoch 258/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 144.6664 - val_loss: 148.4171\n",
            "Epoch 259/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 145.0593 - val_loss: 148.0668\n",
            "Epoch 260/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 144.4833 - val_loss: 147.8773\n",
            "Epoch 261/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 145.0502 - val_loss: 147.8858\n",
            "Epoch 262/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 144.5497 - val_loss: 148.5063\n",
            "Epoch 263/300\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 144.8526 - val_loss: 147.9999\n",
            "Epoch 264/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 145.2305 - val_loss: 147.9608\n",
            "Epoch 265/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 145.0376 - val_loss: 148.6688\n",
            "Epoch 266/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 145.0412 - val_loss: 148.1012\n",
            "Epoch 267/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 145.4739 - val_loss: 147.8620\n",
            "Epoch 268/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 145.1279 - val_loss: 148.7048\n",
            "Epoch 269/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 145.3975 - val_loss: 156.1227\n",
            "Epoch 270/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 146.6870 - val_loss: 155.2561\n",
            "Epoch 271/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 145.7846 - val_loss: 147.9016\n",
            "Epoch 272/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 144.8539 - val_loss: 148.0192\n",
            "Epoch 273/300\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 144.5310 - val_loss: 149.9115\n",
            "Epoch 274/300\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 144.9328 - val_loss: 147.8799\n",
            "Epoch 275/300\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 145.6280 - val_loss: 148.0794\n",
            "Epoch 276/300\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 145.5191 - val_loss: 147.8970\n",
            "Epoch 277/300\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 145.3524 - val_loss: 147.9304\n",
            "Epoch 278/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 145.6344 - val_loss: 148.5370\n",
            "Epoch 279/300\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 145.5383 - val_loss: 149.0639\n",
            "Epoch 280/300\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 145.3133 - val_loss: 147.9710\n",
            "Epoch 281/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 144.7513 - val_loss: 149.6167\n",
            "Epoch 282/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 144.5416 - val_loss: 148.3406\n",
            "Epoch 283/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 144.7732 - val_loss: 147.8885\n",
            "Epoch 284/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 144.8732 - val_loss: 148.0133\n",
            "Epoch 285/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 144.4682 - val_loss: 149.4993\n",
            "Epoch 286/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 144.9761 - val_loss: 148.3902\n",
            "Epoch 287/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 144.9799 - val_loss: 149.4368\n",
            "Epoch 288/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 145.0524 - val_loss: 148.2196\n",
            "Epoch 289/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 144.9920 - val_loss: 148.2842\n",
            "Epoch 290/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 144.5788 - val_loss: 149.2507\n",
            "Epoch 291/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 144.5143 - val_loss: 148.1181\n",
            "Epoch 292/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 145.0239 - val_loss: 148.5953\n",
            "Epoch 293/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 145.8367 - val_loss: 149.3061\n",
            "Epoch 294/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 144.9166 - val_loss: 147.8823\n",
            "Epoch 295/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 144.5596 - val_loss: 147.8618\n",
            "Epoch 296/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 144.8053 - val_loss: 149.6638\n",
            "Epoch 297/300\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 144.5276 - val_loss: 149.7432\n",
            "Epoch 298/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 145.0478 - val_loss: 147.8669\n",
            "Epoch 299/300\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 145.9857 - val_loss: 148.3423\n",
            "Epoch 300/300\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 145.1649 - val_loss: 148.8739\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 147.6390\n",
            "Epoch 1/300\n",
            "25/25 [==============================] - 1s 9ms/step - loss: 291.5319 - val_loss: 218.2878\n",
            "Epoch 2/300\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 193.3324 - val_loss: 169.6207\n",
            "Epoch 3/300\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 161.0657 - val_loss: 153.8383\n",
            "Epoch 4/300\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 150.4053 - val_loss: 149.3280\n",
            "Epoch 5/300\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 146.9187 - val_loss: 147.9954\n",
            "Epoch 6/300\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 145.8470 - val_loss: 147.8545\n",
            "Epoch 7/300\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 145.5999 - val_loss: 147.8735\n",
            "Epoch 8/300\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 145.4906 - val_loss: 147.8844\n",
            "Epoch 9/300\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 145.5097 - val_loss: 147.9106\n",
            "Epoch 10/300\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 145.5350 - val_loss: 147.9785\n",
            "Epoch 11/300\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 145.4519 - val_loss: 148.1440\n",
            "Epoch 12/300\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 145.4497 - val_loss: 147.9542\n",
            "Epoch 13/300\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 145.5325 - val_loss: 148.0597\n",
            "Epoch 14/300\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 145.4588 - val_loss: 148.0598\n",
            "Epoch 15/300\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 145.5277 - val_loss: 148.0094\n",
            "Epoch 16/300\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 145.4290 - val_loss: 148.0600\n",
            "Epoch 17/300\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 145.4294 - val_loss: 147.9663\n",
            "Epoch 18/300\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 145.4940 - val_loss: 147.8909\n",
            "Epoch 19/300\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 145.4796 - val_loss: 147.8985\n",
            "Epoch 20/300\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 145.4682 - val_loss: 147.9582\n",
            "Epoch 21/300\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 145.5340 - val_loss: 147.9098\n",
            "Epoch 22/300\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 145.4822 - val_loss: 148.0512\n",
            "Epoch 23/300\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 145.4459 - val_loss: 147.9963\n",
            "Epoch 24/300\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 145.4483 - val_loss: 148.0137\n",
            "Epoch 25/300\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 145.3796 - val_loss: 147.9307\n",
            "Epoch 26/300\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 145.4200 - val_loss: 147.9047\n",
            "Epoch 27/300\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 145.4296 - val_loss: 147.8426\n",
            "Epoch 28/300\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 145.4312 - val_loss: 147.8941\n",
            "Epoch 29/300\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 145.4719 - val_loss: 147.9154\n",
            "Epoch 30/300\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 145.4475 - val_loss: 147.8935\n",
            "Epoch 31/300\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 145.3901 - val_loss: 148.0264\n",
            "Epoch 32/300\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 145.3590 - val_loss: 147.9493\n",
            "Epoch 33/300\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 145.3834 - val_loss: 147.9796\n",
            "Epoch 34/300\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 145.3899 - val_loss: 147.9771\n",
            "Epoch 35/300\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 145.4931 - val_loss: 147.8291\n",
            "Epoch 36/300\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 145.3764 - val_loss: 147.8656\n",
            "Epoch 37/300\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 145.3621 - val_loss: 147.8173\n",
            "Epoch 38/300\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 145.3630 - val_loss: 147.8729\n",
            "Epoch 39/300\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 145.3092 - val_loss: 147.7996\n",
            "Epoch 40/300\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 145.3002 - val_loss: 147.9565\n",
            "Epoch 41/300\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 145.2914 - val_loss: 147.8792\n",
            "Epoch 42/300\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 145.2359 - val_loss: 147.7811\n",
            "Epoch 43/300\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 145.2534 - val_loss: 147.7828\n",
            "Epoch 44/300\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 145.2459 - val_loss: 147.7093\n",
            "Epoch 45/300\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 145.1642 - val_loss: 147.8123\n",
            "Epoch 46/300\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 145.1893 - val_loss: 147.6455\n",
            "Epoch 47/300\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 145.1710 - val_loss: 147.6643\n",
            "Epoch 48/300\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 145.0629 - val_loss: 147.5661\n",
            "Epoch 49/300\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 145.1463 - val_loss: 147.5303\n",
            "Epoch 50/300\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 144.9797 - val_loss: 147.3516\n",
            "Epoch 51/300\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 144.9663 - val_loss: 147.4095\n",
            "Epoch 52/300\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 144.8761 - val_loss: 147.4115\n",
            "Epoch 53/300\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 144.7489 - val_loss: 147.0828\n",
            "Epoch 54/300\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 144.5464 - val_loss: 147.2041\n",
            "Epoch 55/300\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 144.3818 - val_loss: 147.3164\n",
            "Epoch 56/300\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 144.1396 - val_loss: 146.4221\n",
            "Epoch 57/300\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 143.7740 - val_loss: 146.1711\n",
            "Epoch 58/300\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 143.3285 - val_loss: 145.7033\n",
            "Epoch 59/300\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 142.7223 - val_loss: 144.9455\n",
            "Epoch 60/300\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 141.9407 - val_loss: 144.0031\n",
            "Epoch 61/300\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 140.5368 - val_loss: 142.3284\n",
            "Epoch 62/300\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 138.4629 - val_loss: 139.7628\n",
            "Epoch 63/300\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 135.2305 - val_loss: 136.7748\n",
            "Epoch 64/300\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 129.7579 - val_loss: 128.6321\n",
            "Epoch 65/300\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 121.2595 - val_loss: 120.1403\n",
            "Epoch 66/300\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 111.6139 - val_loss: 111.2749\n",
            "Epoch 67/300\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 101.2720 - val_loss: 102.1203\n",
            "Epoch 68/300\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 92.2544 - val_loss: 94.4764\n",
            "Epoch 69/300\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 89.5286 - val_loss: 84.5134\n",
            "Epoch 70/300\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 78.4713 - val_loss: 84.0236\n",
            "Epoch 71/300\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 72.7325 - val_loss: 72.8976\n",
            "Epoch 72/300\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 68.1015 - val_loss: 71.5284\n",
            "Epoch 73/300\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 63.5837 - val_loss: 85.9537\n",
            "Epoch 74/300\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 61.7364 - val_loss: 77.9983\n",
            "Epoch 75/300\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 66.3548 - val_loss: 103.7683\n",
            "Epoch 76/300\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 77.1314 - val_loss: 75.8172\n",
            "Epoch 77/300\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 62.9774 - val_loss: 63.4917\n",
            "Epoch 78/300\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 54.1269 - val_loss: 63.0887\n",
            "Epoch 79/300\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 58.7095 - val_loss: 72.8851\n",
            "Epoch 80/300\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 60.3494 - val_loss: 62.2051\n",
            "Epoch 81/300\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 59.2950 - val_loss: 349.1432\n",
            "Epoch 82/300\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 231.4632 - val_loss: 175.9118\n",
            "Epoch 83/300\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 155.9821 - val_loss: 152.1077\n",
            "Epoch 84/300\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 146.7470 - val_loss: 148.6001\n",
            "Epoch 85/300\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 145.6436 - val_loss: 148.0999\n",
            "Epoch 86/300\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 145.4700 - val_loss: 147.9110\n",
            "Epoch 87/300\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 145.5447 - val_loss: 148.0649\n",
            "Epoch 88/300\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 145.4661 - val_loss: 148.0295\n",
            "Epoch 89/300\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 145.5409 - val_loss: 148.0973\n",
            "Epoch 90/300\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 145.5175 - val_loss: 148.1186\n",
            "Epoch 91/300\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 145.5339 - val_loss: 148.1056\n",
            "Epoch 92/300\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 145.4877 - val_loss: 148.1159\n",
            "Epoch 93/300\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 145.4998 - val_loss: 148.2995\n",
            "Epoch 94/300\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 145.5402 - val_loss: 148.2544\n",
            "Epoch 95/300\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 145.4745 - val_loss: 147.9211\n",
            "Epoch 96/300\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 145.4697 - val_loss: 148.0095\n",
            "Epoch 97/300\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 145.4801 - val_loss: 148.0979\n",
            "Epoch 98/300\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 145.5488 - val_loss: 148.2113\n",
            "Epoch 99/300\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 145.5029 - val_loss: 147.9628\n",
            "Epoch 100/300\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 145.5071 - val_loss: 147.7529\n",
            "Epoch 101/300\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 145.3827 - val_loss: 147.6479\n",
            "Epoch 102/300\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 145.3092 - val_loss: 147.4897\n",
            "Epoch 103/300\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 144.1773 - val_loss: 133.4555\n",
            "Epoch 104/300\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 102.8635 - val_loss: 84.0244\n",
            "Epoch 105/300\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 75.4153 - val_loss: 71.6906\n",
            "Epoch 106/300\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 62.7553 - val_loss: 64.3935\n",
            "Epoch 107/300\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 55.4656 - val_loss: 66.3291\n",
            "Epoch 108/300\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 51.8300 - val_loss: 66.3305\n",
            "Epoch 109/300\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 50.7015 - val_loss: 59.4518\n",
            "Epoch 110/300\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 51.3638 - val_loss: 56.5201\n",
            "Epoch 111/300\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 49.0923 - val_loss: 56.1373\n",
            "Epoch 112/300\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 51.5820 - val_loss: 55.4319\n",
            "Epoch 113/300\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 49.9012 - val_loss: 94.5634\n",
            "Epoch 114/300\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 49.5644 - val_loss: 55.7792\n",
            "Epoch 115/300\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 50.0066 - val_loss: 79.8782\n",
            "Epoch 116/300\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 46.2816 - val_loss: 51.4876\n",
            "Epoch 117/300\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 41.8653 - val_loss: 88.7966\n",
            "Epoch 118/300\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 40.4975 - val_loss: 66.2975\n",
            "Epoch 119/300\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 41.6524 - val_loss: 64.4604\n",
            "Epoch 120/300\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 43.3480 - val_loss: 46.7463\n",
            "Epoch 121/300\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 42.0235 - val_loss: 101.7396\n",
            "Epoch 122/300\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 41.2891 - val_loss: 47.3108\n",
            "Epoch 123/300\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 41.2702 - val_loss: 54.9507\n",
            "Epoch 124/300\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 35.1624 - val_loss: 44.7258\n",
            "Epoch 125/300\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 33.9544 - val_loss: 76.4197\n",
            "Epoch 126/300\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 39.2101 - val_loss: 61.5482\n",
            "Epoch 127/300\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 35.8639 - val_loss: 46.5242\n",
            "Epoch 128/300\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 37.6870 - val_loss: 65.4085\n",
            "Epoch 129/300\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 30.8496 - val_loss: 58.6588\n",
            "Epoch 130/300\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 30.2526 - val_loss: 43.6354\n",
            "Epoch 131/300\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 39.6926 - val_loss: 39.6943\n",
            "Epoch 132/300\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 32.7045 - val_loss: 40.9763\n",
            "Epoch 133/300\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 35.4791 - val_loss: 38.1957\n",
            "Epoch 134/300\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 31.4270 - val_loss: 37.6121\n",
            "Epoch 135/300\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 28.4018 - val_loss: 36.9816\n",
            "Epoch 136/300\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 28.4370 - val_loss: 36.2842\n",
            "Epoch 137/300\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 28.9533 - val_loss: 40.2814\n",
            "Epoch 138/300\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 30.2212 - val_loss: 48.3211\n",
            "Epoch 139/300\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 29.6532 - val_loss: 63.9628\n",
            "Epoch 140/300\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 26.1427 - val_loss: 37.3823\n",
            "Epoch 141/300\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 27.4090 - val_loss: 46.9574\n",
            "Epoch 142/300\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 29.5747 - val_loss: 40.3933\n",
            "Epoch 143/300\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 27.6629 - val_loss: 35.1931\n",
            "Epoch 144/300\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 31.3419 - val_loss: 48.2697\n",
            "Epoch 145/300\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 29.0478 - val_loss: 38.5458\n",
            "Epoch 146/300\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 23.6597 - val_loss: 34.8683\n",
            "Epoch 147/300\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 26.7964 - val_loss: 33.3911\n",
            "Epoch 148/300\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 24.1013 - val_loss: 214.1968\n",
            "Epoch 149/300\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 33.9014 - val_loss: 34.6955\n",
            "Epoch 150/300\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 27.2927 - val_loss: 40.5328\n",
            "Epoch 151/300\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 29.2831 - val_loss: 36.1690\n",
            "Epoch 152/300\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 25.8860 - val_loss: 33.8939\n",
            "Epoch 153/300\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 25.6117 - val_loss: 45.8802\n",
            "Epoch 154/300\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 25.7008 - val_loss: 79.1430\n",
            "Epoch 155/300\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 25.4592 - val_loss: 101.7584\n",
            "Epoch 156/300\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 29.0108 - val_loss: 46.4376\n",
            "Epoch 157/300\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 21.8620 - val_loss: 33.6946\n",
            "Epoch 158/300\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 22.3516 - val_loss: 38.4539\n",
            "Epoch 159/300\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 25.3128 - val_loss: 32.4410\n",
            "Epoch 160/300\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 21.5118 - val_loss: 31.7820\n",
            "Epoch 161/300\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 20.9480 - val_loss: 32.1822\n",
            "Epoch 162/300\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 19.7998 - val_loss: 35.3049\n",
            "Epoch 163/300\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 22.4330 - val_loss: 41.1570\n",
            "Epoch 164/300\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 23.4608 - val_loss: 169.4995\n",
            "Epoch 165/300\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 29.0758 - val_loss: 47.4833\n",
            "Epoch 166/300\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 22.3099 - val_loss: 39.0109\n",
            "Epoch 167/300\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 26.8320 - val_loss: 32.3952\n",
            "Epoch 168/300\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 22.0304 - val_loss: 30.7308\n",
            "Epoch 169/300\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 21.8724 - val_loss: 46.1078\n",
            "Epoch 170/300\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 29.7817 - val_loss: 144.9977\n",
            "Epoch 171/300\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 26.0393 - val_loss: 43.8143\n",
            "Epoch 172/300\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 23.3695 - val_loss: 29.7859\n",
            "Epoch 173/300\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 22.2342 - val_loss: 32.3343\n",
            "Epoch 174/300\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 18.5186 - val_loss: 33.5224\n",
            "Epoch 175/300\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 19.7171 - val_loss: 30.3704\n",
            "Epoch 176/300\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 23.1854 - val_loss: 38.2249\n",
            "Epoch 177/300\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 22.4102 - val_loss: 41.5245\n",
            "Epoch 178/300\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 25.0575 - val_loss: 44.4203\n",
            "Epoch 179/300\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 26.4840 - val_loss: 29.3741\n",
            "Epoch 180/300\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 20.6917 - val_loss: 28.4247\n",
            "Epoch 181/300\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 19.4911 - val_loss: 30.4456\n",
            "Epoch 182/300\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 17.1869 - val_loss: 32.1232\n",
            "Epoch 183/300\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 18.9493 - val_loss: 29.4866\n",
            "Epoch 184/300\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 24.3205 - val_loss: 93.6737\n",
            "Epoch 185/300\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 20.9002 - val_loss: 30.8759\n",
            "Epoch 186/300\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 20.1586 - val_loss: 29.6237\n",
            "Epoch 187/300\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 19.8433 - val_loss: 27.6945\n",
            "Epoch 188/300\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 20.0992 - val_loss: 26.8017\n",
            "Epoch 189/300\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 19.2307 - val_loss: 36.1201\n",
            "Epoch 190/300\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 16.3104 - val_loss: 99.1495\n",
            "Epoch 191/300\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 18.7279 - val_loss: 26.7265\n",
            "Epoch 192/300\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 19.9887 - val_loss: 41.0000\n",
            "Epoch 193/300\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 19.4199 - val_loss: 26.2960\n",
            "Epoch 194/300\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 17.6643 - val_loss: 128.2146\n",
            "Epoch 195/300\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 21.4851 - val_loss: 363.6224\n",
            "Epoch 196/300\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 37.1493 - val_loss: 29.2632\n",
            "Epoch 197/300\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 20.6642 - val_loss: 28.9933\n",
            "Epoch 198/300\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 17.6407 - val_loss: 101.9118\n",
            "Epoch 199/300\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 25.3665 - val_loss: 30.8698\n",
            "Epoch 200/300\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 17.2808 - val_loss: 25.3875\n",
            "Epoch 201/300\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 16.5564 - val_loss: 26.5760\n",
            "Epoch 202/300\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 15.7000 - val_loss: 25.1474\n",
            "Epoch 203/300\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 17.6319 - val_loss: 27.0647\n",
            "Epoch 204/300\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 19.7397 - val_loss: 25.1523\n",
            "Epoch 205/300\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 19.0921 - val_loss: 26.1615\n",
            "Epoch 206/300\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 14.7358 - val_loss: 31.8607\n",
            "Epoch 207/300\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 15.9467 - val_loss: 37.9112\n",
            "Epoch 208/300\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 13.5700 - val_loss: 29.1190\n",
            "Epoch 209/300\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 16.7174 - val_loss: 36.3369\n",
            "Epoch 210/300\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 23.8114 - val_loss: 78.6935\n",
            "Epoch 211/300\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 21.3552 - val_loss: 24.9276\n",
            "Epoch 212/300\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 13.9798 - val_loss: 39.0229\n",
            "Epoch 213/300\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 16.9297 - val_loss: 28.5667\n",
            "Epoch 214/300\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 12.6774 - val_loss: 23.7725\n",
            "Epoch 215/300\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 13.6516 - val_loss: 22.5770\n",
            "Epoch 216/300\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 27.4517 - val_loss: 23.2949\n",
            "Epoch 217/300\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 18.4614 - val_loss: 22.3917\n",
            "Epoch 218/300\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 15.0818 - val_loss: 61.7170\n",
            "Epoch 219/300\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 17.8111 - val_loss: 22.4464\n",
            "Epoch 220/300\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 15.7528 - val_loss: 23.8455\n",
            "Epoch 221/300\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 16.7781 - val_loss: 28.7915\n",
            "Epoch 222/300\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 12.1912 - val_loss: 29.0420\n",
            "Epoch 223/300\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 16.4046 - val_loss: 22.5537\n",
            "Epoch 224/300\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 11.2391 - val_loss: 21.7853\n",
            "Epoch 225/300\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 17.6897 - val_loss: 21.0950\n",
            "Epoch 226/300\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 12.2590 - val_loss: 38.5755\n",
            "Epoch 227/300\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 15.6206 - val_loss: 25.2742\n",
            "Epoch 228/300\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 17.0016 - val_loss: 23.8433\n",
            "Epoch 229/300\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 12.2239 - val_loss: 20.9154\n",
            "Epoch 230/300\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 12.6865 - val_loss: 21.3667\n",
            "Epoch 231/300\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 10.7617 - val_loss: 21.8467\n",
            "Epoch 232/300\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 11.3540 - val_loss: 58.3150\n",
            "Epoch 233/300\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 29.1790 - val_loss: 40.4181\n",
            "Epoch 234/300\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 13.3182 - val_loss: 24.3882\n",
            "Epoch 235/300\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 11.4244 - val_loss: 21.0048\n",
            "Epoch 236/300\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 10.9218 - val_loss: 21.8539\n",
            "Epoch 237/300\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 11.0998 - val_loss: 20.3563\n",
            "Epoch 238/300\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 10.1625 - val_loss: 28.3170\n",
            "Epoch 239/300\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 14.2671 - val_loss: 22.0330\n",
            "Epoch 240/300\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 11.3239 - val_loss: 21.0212\n",
            "Epoch 241/300\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 9.5579 - val_loss: 20.7743\n",
            "Epoch 242/300\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 10.5912 - val_loss: 21.4603\n",
            "Epoch 243/300\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 22.6639 - val_loss: 22.5684\n",
            "Epoch 244/300\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 18.2969 - val_loss: 20.3972\n",
            "Epoch 245/300\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 11.3244 - val_loss: 24.1043\n",
            "Epoch 246/300\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 13.7684 - val_loss: 25.6106\n",
            "Epoch 247/300\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 12.8238 - val_loss: 19.6834\n",
            "Epoch 248/300\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 10.6102 - val_loss: 21.3222\n",
            "Epoch 249/300\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 10.1226 - val_loss: 30.6374\n",
            "Epoch 250/300\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 10.0505 - val_loss: 22.6294\n",
            "Epoch 251/300\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 9.3711 - val_loss: 32.5211\n",
            "Epoch 252/300\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 16.7917 - val_loss: 20.5023\n",
            "Epoch 253/300\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 9.2987 - val_loss: 98.7698\n",
            "Epoch 254/300\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 26.3212 - val_loss: 25.3061\n",
            "Epoch 255/300\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 11.1139 - val_loss: 19.3134\n",
            "Epoch 256/300\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 8.7214 - val_loss: 19.6595\n",
            "Epoch 257/300\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 10.6244 - val_loss: 18.6890\n",
            "Epoch 258/300\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 13.0987 - val_loss: 20.2932\n",
            "Epoch 259/300\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 8.9558 - val_loss: 20.4246\n",
            "Epoch 260/300\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 8.3723 - val_loss: 20.6707\n",
            "Epoch 261/300\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 9.5385 - val_loss: 21.0936\n",
            "Epoch 262/300\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 11.4246 - val_loss: 27.7897\n",
            "Epoch 263/300\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 8.7919 - val_loss: 22.0061\n",
            "Epoch 264/300\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 12.7047 - val_loss: 21.5227\n",
            "Epoch 265/300\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 16.6090 - val_loss: 28.6007\n",
            "Epoch 266/300\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 9.8765 - val_loss: 19.5790\n",
            "Epoch 267/300\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 9.0095 - val_loss: 18.5143\n",
            "Epoch 268/300\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 9.2550 - val_loss: 19.7786\n",
            "Epoch 269/300\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 8.1952 - val_loss: 24.4260\n",
            "Epoch 270/300\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 8.1904 - val_loss: 41.4164\n",
            "Epoch 271/300\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 10.4680 - val_loss: 27.7679\n",
            "Epoch 272/300\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 15.4410 - val_loss: 20.3472\n",
            "Epoch 273/300\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 9.1491 - val_loss: 21.1466\n",
            "Epoch 274/300\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 8.7269 - val_loss: 17.8188\n",
            "Epoch 275/300\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 10.5472 - val_loss: 17.9707\n",
            "Epoch 276/300\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 11.7915 - val_loss: 20.4078\n",
            "Epoch 277/300\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 7.5254 - val_loss: 19.3895\n",
            "Epoch 278/300\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 8.5403 - val_loss: 25.3836\n",
            "Epoch 279/300\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 8.1799 - val_loss: 21.1042\n",
            "Epoch 280/300\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 8.2315 - val_loss: 19.6179\n",
            "Epoch 281/300\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 7.7261 - val_loss: 21.3566\n",
            "Epoch 282/300\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 8.9617 - val_loss: 26.3192\n",
            "Epoch 283/300\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 7.7386 - val_loss: 20.3243\n",
            "Epoch 284/300\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 12.9536 - val_loss: 21.9183\n",
            "Epoch 285/300\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 8.9902 - val_loss: 17.5876\n",
            "Epoch 286/300\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 8.5543 - val_loss: 19.2036\n",
            "Epoch 287/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 8.3789 - val_loss: 21.9951\n",
            "Epoch 288/300\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 7.4365 - val_loss: 21.1175\n",
            "Epoch 289/300\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 11.6821 - val_loss: 17.2907\n",
            "Epoch 290/300\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 7.8571 - val_loss: 18.4398\n",
            "Epoch 291/300\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 9.2426 - val_loss: 17.2541\n",
            "Epoch 292/300\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 6.6713 - val_loss: 18.7793\n",
            "Epoch 293/300\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 7.8253 - val_loss: 22.7944\n",
            "Epoch 294/300\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 9.6210 - val_loss: 19.1720\n",
            "Epoch 295/300\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 12.8567 - val_loss: 25.7068\n",
            "Epoch 296/300\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 7.3034 - val_loss: 67.8006\n",
            "Epoch 297/300\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 10.5506 - val_loss: 21.7940\n",
            "Epoch 298/300\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 9.3551 - val_loss: 17.9388\n",
            "Epoch 299/300\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 7.9948 - val_loss: 61.9830\n",
            "Epoch 300/300\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 8.0398 - val_loss: 24.1753\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=3,\n",
              "                   estimator=<keras.wrappers.scikit_learn.KerasRegressor object at 0x7f8a72e4c290>,\n",
              "                   param_distributions={'learning_rate': [0.1, 0.01, 0.003],\n",
              "                                        'n_hidden': [2, 4],\n",
              "                                        'n_neurons': [10, 100, 300]})"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rnd_search_cv = RandomizedSearchCV(keras_reg, param_distribs, n_iter=10, cv=3)\n",
        "rnd_search_cv.fit(X_train_flat_2, Y_train_flat_2, epochs=300,validation_data=(X_val_flat,Y_val_flat))\n",
        "                  #callbacks=[keras.callbacks.EarlyStopping()] \n",
        "  \n"
      ],
      "id": "mwoPp9G0j0ss"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qVS3inMLhxLO"
      },
      "outputs": [],
      "source": [
        "print('Best parameters found:\\n', clf.best_params_)"
      ],
      "id": "qVS3inMLhxLO"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qAxuTl2knZ6x"
      },
      "source": [
        "{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (20,), 'learning_rate': 'adaptive', 'solver': 'adam'}"
      ],
      "id": "qAxuTl2knZ6x"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EKjtDeQbh3Qi"
      },
      "outputs": [],
      "source": [
        "means = clf.cv_results_['mean_test_score']\n",
        "stds = clf.cv_results_['std_test_score']\n",
        "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
        "    print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))"
      ],
      "id": "EKjtDeQbh3Qi"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RMyZcvcF7J6Q"
      },
      "outputs": [],
      "source": [
        ""
      ],
      "id": "RMyZcvcF7J6Q"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vgj6F1pTh7h0"
      },
      "outputs": [],
      "source": [
        "y_true, y_pred = Y_test_flat , clf.predict(X_test_flat)\n",
        "from sklearn.metrics import classification_report\n",
        "print('Results on the test set:')\n",
        "print(classification_report(y_true, y_pred))"
      ],
      "id": "vgj6F1pTh7h0"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6JmHOx3DnoM_"
      },
      "source": [
        "Results on the test set:\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "           1       0.70      0.88      0.78        16\n",
        "           2       0.74      0.88      0.80        16\n",
        "           3       0.50      0.50      0.50         6\n",
        "           4       1.00      0.87      0.93        15\n",
        "           5       0.78      0.50      0.61        14\n",
        "           6       0.86      1.00      0.92         6\n",
        "           7       0.89      0.89      0.89         9\n",
        "           8       0.86      0.86      0.86        14\n",
        "           9       1.00      1.00      1.00        11\n",
        "          10       0.94      1.00      0.97        16\n",
        "          11       0.85      0.92      0.88        12\n",
        "          12       0.90      1.00      0.95        18\n",
        "          13       1.00      1.00      1.00        15\n",
        "          14       1.00      1.00      1.00         6\n",
        "          15       1.00      1.00      1.00         1\n",
        "          16       1.00      1.00      1.00         1\n",
        "          17       1.00      1.00      1.00         4\n",
        "          18       0.67      1.00      0.80         6\n",
        "          20       0.00      0.00      0.00         2\n",
        "          21       0.00      0.00      0.00         3\n",
        "          22       1.00      1.00      1.00         4\n",
        "          23       0.40      0.50      0.44         4\n",
        "          24       0.00      0.00      0.00         2\n",
        "          25       0.67      0.80      0.73         5\n",
        "          26       0.33      0.25      0.29         4\n",
        "          28       0.67      1.00      0.80         2\n",
        "          29       0.00      0.00      0.00         2\n",
        "          30       1.00      1.00      1.00         2\n",
        "          32       0.00      0.00      0.00         2\n",
        "          33       1.00      1.00      1.00         3\n",
        "          34       1.00      1.00      1.00         1\n",
        "          35       0.88      1.00      0.93         7\n",
        "          36       0.00      0.00      0.00         1\n",
        "          38       0.90      1.00      0.95         9\n",
        "          41       0.00      0.00      0.00         1\n",
        "          42       0.67      0.67      0.67         3\n",
        "\n",
        "    accuracy                           0.84       243\n",
        "   macro avg       0.67      0.71      0.69       243\n",
        "weighted avg       0.80      0.84      0.81       243"
      ],
      "id": "6JmHOx3DnoM_"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "911d0a39"
      },
      "source": [
        "#### Try the different algorithms and compare the results with MLP classifier"
      ],
      "id": "911d0a39"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a86RpHkoiJ2i"
      },
      "source": [
        "### SVM Model Experiments"
      ],
      "id": "a86RpHkoiJ2i"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7m1_SuejM9Dw"
      },
      "outputs": [],
      "source": [
        "from sklearn import svm\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "param_grid={'C':[0.1,1,10,100],'gamma':[0.0001,0.001,0.1,1],'kernel':['rbf','poly']}\n",
        "svc=svm.SVC(probability=True)\n",
        "model=GridSearchCV(svc,param_grid)"
      ],
      "id": "7m1_SuejM9Dw"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6H_Kiu4kNmGy"
      },
      "outputs": [],
      "source": [
        "model.fit(X_train_flat,Y_train_flat)\n"
      ],
      "id": "6H_Kiu4kNmGy"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EY-bwQmHPlyZ"
      },
      "outputs": [],
      "source": [
        "model.best_params_"
      ],
      "id": "EY-bwQmHPlyZ"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ael8FTkdaCx"
      },
      "source": [
        "{'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}"
      ],
      "id": "1ael8FTkdaCx"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "69I8lIIIcMP5"
      },
      "outputs": [],
      "source": [
        "svc = svm.SVC(C=100,gamma=0.001,kernel='rbf')"
      ],
      "id": "69I8lIIIcMP5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5QYngyozczt-"
      },
      "outputs": [],
      "source": [
        "model.fit(X_train_flat,Y_train_flat)\n"
      ],
      "id": "5QYngyozczt-"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MHIMbFc2c99J"
      },
      "outputs": [],
      "source": [
        "Y_pred_svc=model.predict(X_test_flat)\n",
        "print('Accuracy Score-',accuracy_score(Y_pred_svc,Y_test))\n"
      ],
      "id": "MHIMbFc2c99J"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "af9cd34e"
      },
      "source": [
        "### Implement simple Neural Networks using keras \n",
        "\n",
        "* Define the keras model and initialize the layers\n",
        "  - Ensure the input layer has the right number of input features. This can be specified when creating the first layer with the input_dim argument.\n",
        "* Compile the model\n",
        "  - Specify the loss function (to evaluate a set of weights), the optimizer (is used to search through different weights for the network) and any optional metrics to collect and report during training.\n",
        "* Fit and Evaluate the model\n",
        "  - Fit the data by specifying epochs and evaluate the model"
      ],
      "id": "af9cd34e"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7f952950"
      },
      "outputs": [],
      "source": [
        "\n",
        "from tensorflow.keras.layers import Flatten, Dense\n",
        "model = Sequential([\n",
        "                    Flatten(input_shape=[30, 30,3]),\n",
        "                    Dense(300, activation=\"relu\"),\n",
        "                    Dense(100, activation=\"relu\"),\n",
        "                    Dense(43, activation=\"softmax\")\n",
        "                    ])"
      ],
      "id": "7f952950"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hx7w5JPgX5uV"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ],
      "id": "Hx7w5JPgX5uV"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wFX9S5WMYG4y"
      },
      "outputs": [],
      "source": [
        "# Compile model\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "              optimizer=\"adam\",\n",
        "              metrics=[\"accuracy\"]\n",
        "              )"
      ],
      "id": "wFX9S5WMYG4y"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FFoRZVzVYINj"
      },
      "outputs": [],
      "source": [
        "history = model.fit(X_train, Y_train, epochs=30, validation_data = (X_test, Y_test))"
      ],
      "id": "FFoRZVzVYINj"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HANCnVD_DdAl"
      },
      "outputs": [],
      "source": [
        "# Visualize training and validation metrics\n",
        "df = pd.DataFrame(history.history)\n",
        "df.plot(figsize=(8, 5))\n",
        "plt.grid(True)\n",
        "# set the vertical range to [0-1]\n",
        "plt.gca().set_ylim(0, 1) \n",
        "plt.show()"
      ],
      "id": "HANCnVD_DdAl"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m2t7Nov0oiVG"
      },
      "outputs": [],
      "source": [
        "# predict the outcomes\n",
        "y_predict = model.predict(X_test)\n",
        "loss,score = model.evaluate(X_test, Y_test)\n",
        "# displaying the score\n",
        "print(score)"
      ],
      "id": "m2t7Nov0oiVG"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cSUDO2lLmQJO"
      },
      "source": [
        "#### Try the same parameters used for MLP Classifier and build the keras model"
      ],
      "id": "cSUDO2lLmQJO"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1zNp5w4bvFz9"
      },
      "outputs": [],
      "source": [
        "# {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (20,), 'learning_rate': 'adaptive',\n",
        "# 'solver': 'adam'}"
      ],
      "id": "1zNp5w4bvFz9"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RInPFwq-4Xtf"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Flatten, Dense\n",
        "model_MLP = Sequential([\n",
        "                    Flatten(input_shape=[30, 30,3]),\n",
        "                    Dense(20, activation=\"tanh\"),\n",
        "                    Dense(20, activation=\"tanh\"),\n",
        "                    Dense(43, activation=\"softmax\")\n",
        "                    ])"
      ],
      "id": "RInPFwq-4Xtf"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TV6cOYoQ4qm-"
      },
      "outputs": [],
      "source": [
        "model_MLP.summary()"
      ],
      "id": "TV6cOYoQ4qm-"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2nktmaax4yDQ"
      },
      "outputs": [],
      "source": [
        "# Compile model\n",
        "model_MLP.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "              optimizer=\"adam\",\n",
        "              metrics=[\"accuracy\"]\n",
        "              )"
      ],
      "id": "2nktmaax4yDQ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nqYeqsBp481F"
      },
      "outputs": [],
      "source": [
        "history = model_MLP.fit(X_train, Y_train, epochs=30, validation_data = (X_test, Y_test))"
      ],
      "id": "nqYeqsBp481F"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ohQAJQc5BPC"
      },
      "outputs": [],
      "source": [
        "# predict the outcomes\n",
        "y_predict = model_MLP.predict(X_test)\n",
        "loss,score = model_MLP.evaluate(X_test, Y_test)\n",
        "# displaying the score\n",
        "print(score)"
      ],
      "id": "0ohQAJQc5BPC"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IAHzeVx_tImO"
      },
      "source": [
        "#### Experiment using Dropout, Regularization and Batch Normalization"
      ],
      "id": "IAHzeVx_tImO"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w34gbejXvLUs"
      },
      "outputs": [],
      "source": [
        "model = keras.models.Sequential([\n",
        "      keras.layers.Conv2D(filters=32, kernel_size=(5,5), activation='relu', input_shape=[30,30,3]),\n",
        "      keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "      keras.layers.Flatten(input_shape=(33,33)),\n",
        "      keras.layers.Dense(units=256, activation='relu'),\n",
        "      keras.layers.Dropout(0.2),\n",
        "      keras.layers.Dense(units=43, activation='softmax')\n",
        "])"
      ],
      "id": "w34gbejXvLUs"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qVnQZ8U1owd0"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "id": "qVnQZ8U1owd0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b71SE_Yqo0Mo"
      },
      "outputs": [],
      "source": [
        "history = model.fit(X_train, Y_train, epochs=30, validation_data = (X_test, Y_test))"
      ],
      "id": "b71SE_Yqo0Mo"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ht54n7GO7LI-"
      },
      "outputs": [],
      "source": [
        "# predict the outcomes\n",
        "y_predict = model.predict(X_test)\n",
        "loss,score = model.evaluate(X_test, Y_test)\n",
        "# displaying the score\n",
        "print(score)"
      ],
      "id": "ht54n7GO7LI-"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1fw325Or-RJf"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(Y_test, y_predict)"
      ],
      "id": "1fw325Or-RJf"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PvQ2vA-ILaUV"
      },
      "outputs": [],
      "source": [
        "y_predict"
      ],
      "id": "PvQ2vA-ILaUV"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U778gRlA7h_z"
      },
      "outputs": [],
      "source": [
        "def predict_samples(model,X_test,X_test_flat,classes):\n",
        "    pred_sample=[]\n",
        "    for i in range(0,10):\n",
        "        pred_temp = model.predict(np.expand_dims(testing_data[i],axis=0)).round(2)\n",
        "        pred_temp = np.argmax(pred_temp, axis = 1)\n",
        "        pred_sample.append(pred_temp)\n",
        "    \n",
        "    # Visualizing our predicted samples\n",
        "    print(\"Visualizing our predicted samples:\")\n",
        "    plt.figure(figsize=(20,9))\n",
        "    j=1\n",
        "    for img in range(0,10):\n",
        "        plt.subplot(2,5,j)\n",
        "        eachImg = cv2.imread(test_df['Path'][img])\n",
        "        eachImg = cv2.cvtColor(eachImg,cv2.COLOR_BGR2GRAY)\n",
        "        eachImg = eachImg/255\n",
        "        plt.imshow(eachImg)\n",
        "        plt.axis('off')\n",
        "        plt.title('Actual:({}){} \\nPredicted:({}){}'.format( test_df['Labels'][img],classes[test_df['Labels'][img]], pred_sample[img][0],classes[pred_sample[img][0]] ))\n",
        "        j+=1\n",
        "        \n"
      ],
      "id": "U778gRlA7h_z"
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Image_Classification_MLP-M4-01-Pallavi.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}